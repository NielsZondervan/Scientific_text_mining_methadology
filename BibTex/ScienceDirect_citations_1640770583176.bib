@article{VAKHARIA2020S210,
title = {P134. Higher rates of medical complications and costs of care following delayed surgical intervention for cauda equina syndrome: a matched-control analysis},
journal = {The Spine Journal},
volume = {20},
number = {9, Supplement },
pages = {S210},
year = {2020},
issn = {1529-9430},
doi = {https://doi.org/10.1016/j.spinee.2020.05.532},
url = {https://www.sciencedirect.com/science/article/pii/S1529943020307531},
author = {Ajit Vakharia and Walter B. Klyce and Yazdan Raji and Jerry Y. Du and Nicholas U. Ahn},
abstract = {BACKGROUND CONTEXT
Studies have stressed the importance of timely surgical intervention for patients with cauda equina syndrome (CES); however, studies investigating outcomes between acute (within 48-hours) and delayed (after 48 hours) surgical intervention following CES while controlling for multiple confounders are limited.
PURPOSE
The purpose of this study was to determine whether delayed intervention has worse outcomes compared to acute intervention. Specifically, we investigated: (1) in-hospital lengths of stay (LOS); (2) medical complications; (3) readmission rates; and 4) costs of care.
STUDY DESIGN/SETTING
Retrospective review of 100% Medicare claims database from 2005 to 2014.
PATIENT SAMPLE
The query yielded 17,177 patients undergoing surgical decompression for CES within (n = 14,310) or after (n = 2,867) 48 hours.
OUTCOME MEASURES
Primary outcomes analyzed included in-hospital LOS, 90-day medical complications, 90-day readmission rates, and 90-day costs of care.
METHODS
Patients with CES undergoing surgical decompression were identified and matched to controls in a 1:5 ratio by age, sex, and medical comorbidities. Logistics regression analyses were used to calculate odds-ratios (OR) for medical complications and readmissions. Welch's t-tests were used to test for significance in LOS and costs of care between the cohorts. A p-value less than 0.01 was considered statistically significant.
RESULTS
The study demonstrated the delayed cohort had significantly longer in-hospital LOS (10-days vs 9-days, p=0.758), but failed to reach statistical significance. The delayed cohort had significantly higher incidence and odds of 90-day medical complications (85.3 vs 62.9%; OR: 3.43, 95%CI: 3.08 – 3.83, p<0.0001) than the acute cohort. Study group patients had significantly higher incidence and odds of myocardial infarction (1.60 vs 0.90; OR: 1.79, p=0.0007), cerebrovascular accidents (3.60 vs 2.30%; OR: 1.61, p<0.0001), renal failure (6.31 vs 4.11%; OR: 1.56, p<0.0001), pneumonia (5.47 vs 4.42; OR: 1.25, p=0.01), paralytic ileus (1.98 vs 1.02; OR: 1.96, p<0.0001), dural tears (29.08 vs 20.83; OR: 1.55, p<0.0001), and neurological deficits (29.08 vs 20.83%; OR: 1.55, p<0.0001); in addition to other medical complications. Ninety-day readmission rates were similar between the cohorts (29.36 vs 33.77%; OR: 0.81, p<0.0001). Ninety-day costs of care were significantly higher in patients undergoing delayed surgical intervention compared to acute intervention ($17,831.07 vs $14,272.90, p<0.0001).
CONCLUSIONS
After matching for age, sex, and medical comorbidities, our study of over 17,000 patients demonstrated patients with delayed surgical intervention for CES have longer in-hospital LOS and higher rates of medical complications and costs of care. The study can be utilized by orthopedic surgeons to educate the importance of immediate surgical intervention in patients with CES.
FDA DEVICE/DRUG STATUS
This abstract does not discuss or include any applicable devices or drugs.}
}
@article{BAER2020S380,
title = {Connecting on a Cellular Level},
journal = {Biology of Blood and Marrow Transplantation},
volume = {26},
number = {3, Supplement },
pages = {S380},
year = {2020},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2019.12.171},
url = {https://www.sciencedirect.com/science/article/pii/S108387911931033X},
author = {Brittney Baer and Channing Vail Dudley},
abstract = {Topic Significance & Study Purpose/Background/Rationale
• With the increase in Immune Effector Cell (IEC) technology in both research and clinical settings, clinicians are challenged with the task of treating acute known adverse events, including cytokine release syndrome (CRS) and IEC-associated neurotoxicity syndrome (ICANS), along with the determining and managing long-term complications of IEC therapies, many of which are unknown.
Methods, Intervention, & Analysis
• Initiate a standardized protocol for early intervention of treatment for CRS and ICANS with recommendations by the ASTCT (American Society of Transplant and Cellular Therapy). • Create an institutional framework for an IEC therapy long-term follow up clinic for. • Collect data on long-term adverse events post-IEC therapy and subsequently develop a standardized approach to appropriately diagnose and treat this patient population.
Findings & Interpretation
• The logistics of treating a patient with IEC therapy through clinical trials has helped standardize the process with commercial therapies. • Through IEC clinical research, acute care of adverse events has informed clinical care with commercial products and these lessons will inform long-term follow up care of this patient population. • The need for a dedicated long-term IEC follow up clinic, with specialized clinicians, has been identified to appropriately follow and treat side effects as needed. • The ever-increasing amount of data on patients that have received IEC therapies will continue to shape how these patients are followed in the future. • Focus on the long-term needs of IEC therapy patients will include: immunizations, hypogammaglobulinemia, HIV/other viral reactivation, increased infections, etc.
Discussion & Implications
• The vision of creating a long-term follow up clinic with dedicated clinicians to help create a standardized approach to surveillance of IEC patients post-therapy is undergoing feasibility assessment. • The integrated approach to implementing clinical trials processes within the commercial IEC environment has helped shape the way we treat and follow up with this patient population. With the lack of long-term data on late breaking side effects that may arise, these IEC patients should be followed by a specialized team/clinic to increase positive patient outcomes.}
}
@article{ENIGL2019178,
title = {Derivation of canonical total-sequences triggering landslides and floodings in complex terrain},
journal = {Advances in Water Resources},
volume = {129},
pages = {178-188},
year = {2019},
issn = {0309-1708},
doi = {https://doi.org/10.1016/j.advwatres.2019.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0309170818308406},
author = {Katharina Enigl and Christoph Matulla and Matthias Schlögl and Franz Schmid},
keywords = {Precipitation-totals, Weather-sequences, Hazard-processes, Objectively determined climate indices, Event space, Austria},
abstract = {Floodings and landslides are amongst the most devastating damage-processes worldwide. Associated risk levels are particularly high in topographically complex terrain. Along with the increase in climate-change induced extreme events, research devoted to the identification of so-called Climate Indices (CIs) describing weather phenomena triggering hazard-occurrences and -intensities gains rising emphasis. In this study we accomplish the first-time unification of the three most comprehensive cadastres on weather-induced hazard-processes, compiled and maintained by federal authorities. The therefrom resulting ‟event spaceˮ stretches seven decades from 1950 onwards and contains more than 20 000 hazard-occurrences, classified into different process-categories. Event data are analyzed together with a high-quality, daily-based dataset providing temperatures and precipitation-totals on a 1 km grid across the Austrian part of the European Alps. On the resulting unprecedented extent of extreme-weather triggered hazard-processes and gridded weather observations we are able to examine the hypothesis that daily sequences of precipitation-totals preceding damage-events allow for the detection of temporal weather-sequences uniquely allocatable to various hazard-categories in three orographically distinct regions in the European Alps. We pursue this research aim by analyzing for each hazard-category its quadratic form representing the physics contained in the observations. Resulting eigen-directions, invariant under its inherent second order tensor, are the sought-for total-sequences (CIs) and hence reject the alternative hypothesis. Therefore, precipitation total-sequences can be uniquely assigned to hazard-categories within each region. It is important to note that findings based on this novel, objective approach do not contradict, but rather add to attained research achievements by introducing this new perspective on the subject. Obtained CIs have substantial potential in research and applications. In civil defense, safeguarding critical infrastructure, early warning systems and the development of sustainable protection strategies, findings are in implementation by responsible decision-makers and in intense discussion with the European Freight and Logistics Leaders’ Forum.}
}
@article{TAN2020682.e1,
title = {Comparative study of surgical orchidectomy and medical castration in treatment efficacy, adverse effects and cost based on a large prospective metastatic prostate cancer registry},
journal = {Urologic Oncology: Seminars and Original Investigations},
volume = {38},
number = {8},
pages = {682.e1-682.e9},
year = {2020},
issn = {1078-1439},
doi = {https://doi.org/10.1016/j.urolonc.2020.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S1078143920302003},
author = {Yu Guang Tan and Randy JY Poon and Leonard JW Pang and Andre Villanueva and Hong Hong Huang and Kenneth Chen and Tze Kiat Ng and Kae Jack Tay and Henry SS Ho and John SP Yuen},
keywords = {Adverse effects, Medical Castration, Bilateral Orchidectomy, Cost, Oncological outcomes, Metastatic prostate cancer, Androgen deprivation therapy},
abstract = {Introduction
Androgen deprivation therapy (ADT) remains the mainstay of treatment for metastatic prostate cancer (mPCa) but is associated with significant morbidities. Comparisons of medical castration (MC) and surgical orchidectomy (SO) have yielded varied results. We aimed to evaluate the oncological outcomes, adverse effect (AE) profiles and costs of MC and SO in patients with mPCa.
Methods and materials
We reviewed 523 patients who presented with de novo mPCa from a prospectively maintained prostate cancer database over 15 years (2001–2015). All patients received ADT (either MC or SO) within 3 months of diagnosis. The data were analyzed with chi-square, binary and logistics regression models.
Results
One hundred and fifty one (28.9%) patients received SO while 372 (71.1%) patients had MC. The median age of presentation was 73 [67 –79] years old. The median prostate-specific antigen (PSA) was 280ng/ml [82.4–958]. Three hundred and thirty one patients (66.3%) had high volume bone metastasis and 57 patients (10.9%) had visceral metastasis. Clinical demographics and clinicopathological were similar across both groups. Similar oncological outcomes were observed in both groups. The proportion of PSA response (PSA <1ng/ml) was 65.6% for SO and 67.2% for MC (P = 0.212). Both therapies achieve >95% of effective androgen suppression (testosterone <50ng/dL). Time to castrate-resistance was similar (18 vs 16 months, P = 0.097), with comparative overall survival (42 vs. 38.5 months, P = 0.058) and prostate cancer mortality (80.1 vs. 75.9%, P = 0.328). Similarly, no difference was observed for the 4 AE profiles between SO and MC respectively; change in Haemoglobin (-0.75 vs. -1.0g/dL, P = 0.302), newly diagnosed Diabetes mellitus (4.6 vs. 2.9%, P = 0.281), control measured by HbA1c (0.2 vs. 0.25%, P = 0.769), coronary artery disease events (9.9 vs. 12.9%, P = 0.376) and skeletal-related fractures (9.3 vs. 7.3%, P = 0.476). After adjusting for varying governmental subsidies and inflation rates, the median cost of SO was $5275, compared to MC of $9185.80.
Conclusion
Both SO and MC have similar oncological outcomes and AE profiles. However, SO remains a much more cost-effective form of ADT for the long-term treatment of mPCa patients.}
}
@article{CHEN2019112833,
title = {Neural-like encoding particle swarm optimization for periodic vehicle routing problems},
journal = {Expert Systems with Applications},
volume = {138},
pages = {112833},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112833},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419305354},
author = {Ruey-Maw Chen and Yin-Mou Shen and Wei-Zhi Hong},
keywords = {Scheduling, Optimization, Periodic vehicle routing problem, Particle swarm optimization, Neural-like discrete PSO, Alternative depot savings algorithm},
abstract = {The periodic vehicle routing problem (PVRP) is an important problem in the logistics field and involves finding the solutions to two sub-problems, namely (1) determining the optimal customer service mode; and (2) establishing the optimal vehicle routing schedule in accordance with the pre-determined customer service mode. However, existing solutions for the PVRP consider only the vehicle routing problem. In other words, they simply assume that the optimal customer service mode is known in advance. Accordingly, the present study proposes a dual particle swarm optimization (PSO) framework for solving both sub-problems simultaneously. In particular, a discrete PSO (DPSO) algorithm is applied on the first level, in the outer layer, to establish the optimal service mode for each customer, and a neural-like DPSO (NDPSO) is then applied in the inner layer to determine (1) the optimal assignment of the depot vehicles to the customers which are to be serviced each day based on the customer service mode established in the outer layer (i.e., the “customer-vehicle correspondence” problem), and (2) the sequence of customer visits to be paid by each vehicle each day (i.e., the “optimal vehicle routing” problem). For both PSOs, a sweep heuristic is applied to generate diverse initial solutions for the particle search process. In addition, an alternative depot savings algorithm is proposed to avoid the route crossing phenomenon inherent in conventional vehicle routing algorithms. The performance of the inner layer NDPSO is evaluated by comparing the solutions for six common PVRPs with the best known solutions (BKS) presented in the literature given a prior knowledge of the optimal customer service mode in every case. The performance of the NDPSO is further investigated with and without the alternative depot savings algorithm and with and without the use of a local search mechanism to enhance the quality of the PSO solutions, respectively. Finally, the feasibility of the full DPSO and NDPSO framework is confirmed by comparing the PVRP solutions with the BKS reported in previous studies. In general, the results confirm the validity of the proposed dual-PSO framework as a tool for finding optimal solutions to both the customer service mode problem and the optimal vehicle routing problem in typical PVRPs.}
}
@article{OKAMOTO2020S373,
title = {Single Center Experience of Clinical Ex Vivo Lung Perfusion},
journal = {The Journal of Heart and Lung Transplantation},
volume = {39},
number = {4, Supplement },
pages = {S373},
year = {2020},
issn = {1053-2498},
doi = {https://doi.org/10.1016/j.healun.2020.01.468},
url = {https://www.sciencedirect.com/science/article/pii/S105324982030485X},
author = {T. Okamoto and I. Sakanoue and K.S. Ayyat and H. Niikawa and U. Ahmad and J.J. Yun and A. Bribriesco and S. Unai and A. Zeeshan and D. Johnston and M. Tong and M. Budev and K.R. McCurry},
abstract = {Purpose
Ex vivo lung perfusion (EVLP) is a technology to evaluate marginal lungs or to preserve standard lungs for logistical reasons. However, the recovery rate for the various indications for EVLP is unknown. The aim of this study is to examine the recovery rate when EVLP is performed for various indications and to evaluate outcomes following transplantation.
Methods
From Feb 2016 to Sep 2019, 441 lung transplants were performed. During this time, 61 pairs of lungs were perfused using the Toronto-EVLP protocol with intent to transplant. EVLP was broadly utilized for 1) Concerns with lung quality or 2) Logistical restrictions with the transplant. Donation after cardiac death (DCD) lungs were perfused when PaO2/FiO2 (P/F) ratio was less than 300 mmHg or agonal time was 60-120 min. Recovery rate was defined as EVLP cases with lung transplant/ all EVLP cases. Post-operative outcomes of EVLP group were compared to those of recipients receiving lungs meeting standard criteria.
Results
In the EVLP obtained organs, donor age was median 35 (Interquartile range 26-45) years with 50.8% of lungs from DCD. P/F ratio in intensive care unit was 329 (259-391) mmHg. The indications for EVLP included most commonly a low PF ratio <300 mmHg prior to procurement (44%), logistical reasons (23%), prolonged agonal time >60 min (18%), the presence of edematous lungs (14%) and question of contusion or pulmonary embolism/infarction (13%). Of the 61 perfused lungs, 39 lungs were clinically utilized in 40 lung transplants (recovery rate = 39/61, 63.9%). The recovery rate varied by indication for EVLP with the highest rate occurring when logistics were the reason for EVLP (92%); followed by extended agonal time >60 min (90%), and then when the extent of contusion or pulmonary embolism was in question (62%). Lower recovery rates from EVLP were found when EVLP was used for P/F ratio <300 mmHg (55%) and when the lungs were edematous (25%); Post transplant, primary graft dysfunction Grade 3 was present in 4 cases (10%) at 72 hours. There was no significant difference in survival between EVLP and control groups (30 days, 100 vs. 97%, p = 0.60; 1 year, 92 vs. 88%, p = 0.60).
Conclusion
These data demonstrate that EVLP for marginal or logistical indications can result in a recovery rate of 63% with comparable outcomes to transplants with standard lungs. The data also suggest that the indication for EVLP is an important factor in the recovery rate.}
}
@incollection{MANZINI2019201,
title = {Chapter 14 - Quality assessment of temperature-sensitive high-value food products: An application to Italian fine chocolate distribution},
editor = {Riccardo Accorsi and Riccardo Manzini},
booktitle = {Sustainable Food Supply Chains},
publisher = {Academic Press},
pages = {201-217},
year = {2019},
isbn = {978-0-12-813411-5},
doi = {https://doi.org/10.1016/B978-0-12-813411-5.00014-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128134115000144},
author = {Riccardo Manzini and Riccardo Accorsi and Marco Bortolini and Andrea Gallo},
keywords = {Close-loop simulation, Quality assessment, Food supply chain control, Temperature-sensitive products, Chocolate distribution},
abstract = {Modern supply chains collect and deliver products worldwide and link manufacturers and consumers over thousands of miles. In the food industry, the safety and quality of products is affected by manufacturing/processing and logistics activities, such as transportation and packaging. Transportation is likely the most critical step throughout the “food journey” from “farm-to-fork” because of the potential stresses that affect the products during shipment and storage activities. When the value and the perceived quality of products is high, the impact of such stresses can be significant and can reasonably affect the economic value of those items, as well as the experience of consumers. Among high-value and temperature-sensitive food, chocolate is a product that is loved by many because of its desirable qualities, which include a shiny gloss on the surface, snap when the chocolate is broken, and a smooth texture that becomes apparent only when the chocolate melts in the mouth. The aim of this chapter is the application of a two-step quality assessment methodology to the case of distribution of fine chocolate products, e.g., the well-known Italian Cremino and Gianduiotto. The first step consists of monitoring the temperature fluctuation during the distribution from the production plant to the point of demand, usually a candy shop. The second step deals with the simulation of the monitored shipment in a temperature- and humidity-controlled system. The simulation of the physical and environmental conditions generated during the real shipment is followed by chemical analysis and sensitivity analysis conducted separately on nonstressed products (the so-called “time zero products”) and stressed products. The effects of temperature are evaluated by comparing stressed and time zero products belonging to the same production batch. The analyses are repeated after 6 months in order to evaluate the effects due to time and shelf-life erosion. The obtained results validate the proposed quality assessment methodology and demonstrate the importance and criticality of packaging and container solutions to face unexpected temperature variations during logistic operations.}
}
@article{NEVRLY2019118003,
title = {Location of mixed municipal waste treatment facilities: Cost of reducing greenhouse gas emissions},
journal = {Journal of Cleaner Production},
volume = {239},
pages = {118003},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118003},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619328732},
author = {Vlastimír Nevrlý and Radovan Šomplák and Ondřej Putna and Martin Pavlas},
keywords = {Emission cost, Greenhouse gas, Optimisation, Waste treatment, Facility location, Greenhouse gas reduction},
abstract = {Municipal solid waste treatment leads to the production of a considerable amount of mixed municipal waste, in case of which material recovery is difficult. Its treatment represents a worldwide challenge since landfilling is still a major treatment method and the respective emissions of greenhouse gases are significant. Approximately 126 Mt of municipal solid waste were landfilled or incinerated within the EU-28 in 2017, while the waste management sector produced 3% of the overall greenhouse gases emissions. Regarding mixed municipal waste, Waste-to-Energy plants seem to be a suitable disposal option as they substitute both landfills and energy production from fossil fuels in combined heat and power plants. However, new treatment facilities of this type need to take into account also the heat and electricity demands in their vicinity to ensure economic stability. This paper therefore analyses the relationship between greenhouse gases emissions and the cost of mixed municipal waste treatment, while considering environmental impact of different treatment options. A reverse logistic (mixed integer programming) model has been developed to optimise future strategies of mixed municipal waste treatment in a large geographical area. The model is nonlinear because of the nonlinear nature of the cost of mixed municipal waste treatment as well as the economic incentive associated with the avoided greenhouse gases emissions. These, in turn, are influenced by plant capacities, locations, and other location-specific parameters (such as the yearly heat demand profile) that must be considered during the integration of a future plant into the existing district heating systems. The results are presented through a case study for the Czech Republic, with 206 micro-regions (waste producers), 148 landfills, 113 potential mechanical-biological treatment plants, 24 potential locations for plants utilising refuse-derived fuels, 4 existing Waste-to-Energy plants, and 32 candidate locations for new Waste-to-Energy plants have been considered. The proposed future concepts involving various processing chains (small Waste-to-Energy plant, large Waste-to-Energy plant with the necessary complex logistics, mechanical biological treatment prior to incineration), are compared with the current (2016) waste treatment strategy, in which 73% of mixed municipal waste is landfilled. The trade-off between economically viable and environmentally acceptable solution is also targeted. The obtained data suggest a possible reduction in greenhouse gases emissions by almost 150% with the cost of waste treatment being increased only by approx. 2.5 EUR/t.}
}
@article{MAREI202165.e1,
title = {Intravesical gentamicin instillation for the treatment and prevention of urinary tract infections in complex paediatric urology patients: evidence for safety and efficacy},
journal = {Journal of Pediatric Urology},
volume = {17},
number = {1},
pages = {65.e1-65.e11},
year = {2021},
issn = {1477-5131},
doi = {https://doi.org/10.1016/j.jpurol.2020.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S1477513120304964},
author = {Mahmoud Marei Marei and Raef Jackson and David J.B. Keene},
keywords = {Urinary tract infection, Lower urinary tract dysfunction (LUTD), Clean intermittent catheterization, Intravesical instillations, Bladder washouts, Bladder irrigation},
abstract = {Summary
Background
Little has been reported to date on the instillation of antimicrobials directly into the bladder in children. Children with complex urinary tract anomalies struggle frequently with recurrent urinary tract infections (UTI), with frequent emergence of antibiotic resistance. Gentamicin bladder instillation to treat and prevent UTI was described in children since 2006.
Objective
We adopted gentamicin bladder instillation in 2016 and evaluate herein our intermediate-term experience with it.
Study design and Methods
This study is a retrospective review of a prospectively initiated database and a clinical audit of our practice. The gentamicin bladder instillation was employed in 24 cases. A treatment regime was initiated for symptomatic documented UTI when resistance patterns precluded an oral alternative (14 cases), avoiding hospitalisation for parenteral antibiotics. A prophylaxis regime (19 cases–including 9 of the 14 who received an initial treatment regime) followed at least one breakthrough UTI while receiving oral prophylactic antibiotics. Two instillation volumes (8 mg gentamicin in 20 mL 0.9% NaCl or 20 mg gentamicin in 50 mL 0.9% NaCl) were used to suit different bladder capacities. The irrigation is given twice a day for 7 days in the treatment regime or once a day, every other day, in the prophylactic regime. Gentamicin serum levels (all cases) and audiology/audiometry testing (17/24 cases) were checked to assess the safety of this method.
Results
The median age when either the treatment course or prophylaxis regime was started was 3.8 years. The treatment regime was 86% successful (12/14) to suppress an acute UTI. The mean duration of prophylaxis was 252 days (median: 256 days). The percentage of patients on the prophylactic regime who had no breakthrough UTI was 58%. No serum gentamicin was detectable secondary to the intravesical instillation. No attributable cases of sensorineural hearing loss were detected. Gentamicin resistance emerged in one case (4.16%).
Discussion
Intravesical administration was feasible via various routes for a spectrum of complex lower urinary tract abnormalities (see Summary Figure). Concerns regarding systemic absorption, nephrotoxicity or ototoxicity were investigated and safety ensured. Limitations include being a small series of non-identical pathologies, albeit categorically similar and being a single-arm study, however, statistical significance was proven descriptively and analytically.
Conclusion
In selected cases and with the appropriate specialist support and logistics, intravesical gentamicin instillation is well-tolerated and safe to treat and/or prevent urinary tract infections in pateints with complex bladder conditions and lower urinary tract pathologies.Summary FigureUnderlying pathologies, bladder reconstruction, routes and regimes (protocols) used.Summary Figure}
}
@article{MALGRAS20191133,
title = {Deployment of the Surgical Life-saving Module (SLM) in 2017: Lessons learned in setting up and training operational surgical units},
journal = {Injury},
volume = {50},
number = {5},
pages = {1133-1137},
year = {2019},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0020138319300981},
author = {Brice Malgras and Olivier Aoun and Ghislain Pauleau and Guillaume Boddaert and Emmanuel Hornez and Renaud Dulou and Jean-Marc Delmas and Pierre Haen and Sophie Laversanne and Anna Crambert and Paul Balandraud},
keywords = {Miltary, Deployment, Surgery, Training},
abstract = {Introduction
The military operations carried out by the French armed forces, occasionally require the use of the Surgical Life-saving Module (SLM), to ensure the surgical support of its soldiers. Due to its extreme mobility and capacity of fast deployment, SLM is particularly useful in small-scale military operations, such as Special Forces missions. In 2017, the French SLM was for the first time used to ensure surgical support of allied forces, which were lacking forward surgical capabilities.
Materials and Methods
the SLM is a mobile, heliborne, airborne, surgical structure with parachuting capability onto land or sea, therefore essentially focused on life-saving procedures, also known as "damage control" surgery. Due to the need for mobility and rapid implementation, the SLM is limited to a maximum of 5 interventions or, in terms of injuries, to 1 or 2 seriously injured patients.
Results
Over a period of 2 months, 5 medical teams were successively deployed with the SLM. A total of 157 casualties were treated. The most common injuries were caused by shrapnel 561%), followed by firearms (36%), and blunt trauma (2.5%). Injuries included the limbs (56%), thorax (18%), abdomen (13%), head (11%), and neck (2%). The average ISS was 8.5 (1–25) with 26 patients presenting with an ISS greater than or equal to 15. The average NISS was 10.8 (1–75) with 34 casualties having an NISS equal to or greater than 15. The surgical procedures were broken down as follows: 126 dressings, 16 laparotomies, 7 thoracotomies, 12 isolated thoracic drains (without thoracotomy), 1 cervicotomy, 12 amputations, 7 limb splints, 2 limb fasciotomies, 2 external fixators and 1 femoral fracture traction.
Conclusions
The numerous SLM deployments in larger operations highlighted its ability to adapt both in terms of equipment and personnel. Continuous management of equipment logistics, robust personnel training, and appropriate organization of the evacuation procedures, were the key elements for optimizing combat casualty care. As a consequence, the SLM appears to be an operational surgical unit of choice during deployments.}
}
@article{FRENET2020S154,
title = {Cord Blood Unit (CBU) search and distribution to Transplant Centers (TC): real-life experience from the National Cord Blood Program (NCBP)},
journal = {Cytotherapy},
volume = {22},
number = {5, Supplement },
pages = {S154},
year = {2020},
issn = {1465-3249},
doi = {https://doi.org/10.1016/j.jcyt.2020.03.319},
url = {https://www.sciencedirect.com/science/article/pii/S1465324920303832},
author = {E. Masson Frenet and L. Dobrila and M.S. Albano and M. Tarnawski and D. Zamfir and C. Romeo and D.W. Sung and P. Rubinstein and A. Scaradavou},
abstract = {Background & Aim
One of the most important attributes of cord blood is the prompt availability of high quality cell therapy products for clinical use. To achieve this, the NCBP has implemented a strong infrastructure supporting CBU search, selection, review and release. The key components include: - Fully integrated IT system for running searches in real-time, generating reports, receiving/sharing results and documents - Streamlined procedures for management of search requests - Expert review and search flexibility - Verification of product quality - Timely CBU release to TC - Expertise in regulatory requirements and shipment logistics
Methods, Results & Conclusion
We describe our recent clinical activity (period: 04/2016-12/2019) following this strategy. Our dedicated website, WebSearch, is used for CBU reservations directly by TC or requests received via registries (National Marrow Donor Program [NMDP] or International Registries). During the study period, 3943 CBU were reserved for 2831 patients from 153 TC. All reservations trigger full review of CBU information as well as confirmatory HLA typing (CT), effectively preparing the reserved CBU for shipment. Each patient's search is reviewed by a medical and an HLA expert within 48 hours to identify the best CBU and share recommendations with the TC. Further, the system is flexible, allowing “customized” searches that include TC's own selection criteria such as high CD34 counts, HLA requirements (allele level matching, patient's anti-HLA antibodies, maternal HLA), eligibility, CBU storage time, and various clinical study specifications. High resolution CT results are obtained routinely within 6 business days. All units with available segments are evaluated for potency (CD34/CD45 counts and viability and CFU) at reservation and/or shipment. During this period, 514 CBU were shipped for 501 patients to 91 TC; 53% were facilitated by the NMDP and the remaining were direct shipments. 170 CBU went to 23 International TC in 20 countries. Average time between shipment request and shipment was 5 business days (Figure 1). TC's shipment schedule requirements were met in all cases. With over 60,000 CBU available, the NCBP Inventory holds almost 8% of the world's unrelated CBU, including 11,100 FDA licensed products (HEMACORD®). The flexibility and efficiency of the search and review procedures, as well as the fact that 10% of the CBU have CT already performed and are “ready to ship”, enable us to process routine or emergency shipment requests expeditiously.}
}
@article{GRAIN2020234,
title = {CAR-T cells et leucémies aiguës lymphoblastiques : avancées et questionnements},
journal = {Bulletin du Cancer},
volume = {107},
number = {2},
pages = {234-243},
year = {2020},
issn = {0007-4551},
doi = {https://doi.org/10.1016/j.bulcan.2020.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0007455120300321},
author = {Audrey Grain and Marie-Emilie Dourthe and André Baruchel},
keywords = {Leucémie aiguë lymphoblastique, « CAR-T cells », Tisagenlecleucel, Acute lymphoblastique Leukemia, CAR-T cells, Tisagenlecleucel},
abstract = {Résumé
L’approbation du tisagenlecleucel dans les leucémies aiguës lymphoblastiques B, en 2017 aux États-Unis et en 2018 en Europe, a non seulement ouvert de nouveaux espoirs, mais a obligé à repenser les organisations hospitalières autour de cette innovation. En effet si ces traitements sont très efficaces à court terme, la logistique complexe nécessaire implique une parfaite collaboration intercentre et intracentre. Les services d’hématologie, de réanimation, de neurologie, de radiologie, d’aphérèse, les laboratoires de thérapie cellulaire et de biologie, doivent ainsi agir de manière coordonnée. Un suivi spécialisé pour le moyen et long terme doit lui aussi être mis en place. De nombreuses questions persistent qui concernent le profil des patients éligibles, la tolérance, l’efficacité à plus long terme, l’amélioration de la persistance des  CAR-T cells , le contrôle du risque d’échappement tumoral, l’utilisation de  CAR-T cells  allogéniques ou l’application de ce concept aux LAL-T. L’évaluation précise des coûts induits et du rapport coût-efficacité de ces thérapeutiques sera aussi l’objet des études à venir.
Summary
The approval of tisagenlecleucel in B-lineage acute lymphoblastic leukemias in 2017 in the USA and in 2018 in Europe not only opened new hopes but forced to rethink the hospital organizations around this innovation. Indeed, if these treatments are very effective in the short term, the complex logistics required imply high quality inter-center and intra-center collaboration. Hematology, intensive care unit, apheresis, neurology, cell therapy and biology laboratories, and radiology services must therefore act in a coordinated manner. A specialized monitoring for the mid and long term must also be implemented. Many questions remain concerning the profile of eligible patients, the short and long-term safety, the longer-term efficacy, improving the persistence of CAR-T cells, controlling the risk of tumor escape, the use of allogenic CAR-T cells, or the application of this concept to T-cell ALL. The precise evaluation of the involved costs and the cost-effectiveness of these therapies will also be the subject of future studies.}
}
@article{PANOWSKI20195157,
title = {Investigation of Allocar TTM Targeting CD70 As a Potential Therapy for an Array of Hematological Malignancies},
journal = {Blood},
volume = {134},
pages = {5157},
year = {2019},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2019-128808},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118630836},
author = {Siler Panowski and Surabhi Srinivasan and Thomas {Van Blarcom} and Cesar Sommer and Hsin-Yuan Cheng and Thomas Pertel and Marianne A Santaguida and Roman Galetto and Alan Dunlop and Reuben Benjamin and Barbra Sasu},
abstract = {Adoptive transfer of T cells expressing chimeric antigen receptors (CARs) is an exciting new therapy showing great promise in hematologic malignancies. Recent approval of two CD19-targeting CAR Ts, Kymriah® and Yescarta®, has been followed with promising results from BCMA clinical trials, showing that activity can extend to other targets. While these treatments show excellent potential for patients with an otherwise poor prognosis, a number of patients are still subject to relapse. These data suggest the potential utility of expanding the number of targets available for hematological malignancies. Autologous chimeric antigen receptor (CAR) T therapies use a patient's own T cells to produce the therapy. This approach has inherent challenges, including requiring significant time for production, complex supply chain logistics, separate GMP manufacturing for each patient, and variability in performance of patient-derived cells. Given rapid disease progression, combined with limitations associated with the autologous approach, many patients may not be able to receive CAR T therapy. Allogeneic CAR T (AlloCAR T) cell therapy, or “off-the-shelf” therapy which utilizes cells from healthy donors, may provide greater convenience with readily available CAR T therapy on-demand, reliable product consistency, and accessibility at greater scale for more patients. To create an allogeneic product, mRNAs encoding Transcription Activator-Like Effector Nucleases (TALEN®) designed to specifically disrupt the TRAC and CD52 genes are introduced to CAR Ts. These modifications are intended to minimize the risk of graft-versus-host disease and to confer resistance to ALLO-647, an anti-CD52 antibody that can be used as part of the conditioning regimen to deplete host alloreactive immune cells potentially leading to increased persistence and efficacy of the infused allogeneic cells. CD70 is a TNF superfamily member expressed on subsets of activated lymphocytes and is being explored as a CAR T target for renal cell carcinoma but may also be suitable for targeting hematological malignancies. To evaluate the potential of CD70 as a heme target, expression of CD70 RNA was compared to that of three known targets, CD19, BCMA, and FLT3, across a range of hematological malignancies by interrogating The Cancer Genome Atlas (TCGA) database. CD19 was expressed in lymphomas and leukemias, BCMA was expressed primarily in MM, and FLT3 expression was largely limited to AML. CD70 expression was observed across all 4 cancer types, indicating the potential broad utility CD70 CAR T cells. To determine cell-surface expression of these four targets, flow cytometry and receptor quantification was performed on a panel of heme cell lines. Good correlation was seen between RNA and the cell-surface protein expression of CD70. CAR T cells against each of the 4 targets were generated and evaluated in vitro. All CAR T cells exhibited robust specific activity against cells expressing their corresponding antigens. To ensure clinical relevance of results with cell lines, studies are currently ongoing to evaluate CD70 expression on primary patient samples and activity of CD70 CAR T cells against these same samples. Based on our studies, CD70 has a broad expression profile across a range of hematological malignancies and potent and selective CD70 CAR T activity has been demonstrated. Given these results, an allogeneic CD70 CAR T is expected to be clinically useful against a range of hematological tumor types either as a single agent or in combination with other CAR Ts.
Disclosures
Panowski: Allogene Therapeutics: Employment, Equity Ownership. Srinivasan: Allogene Therapeutics: Employment, Equity Ownership. Van Blarcom: Allogene Therapeutics, Inc.: Employment, Equity Ownership. Sommer: Allogene Therapeutics, Inc.: Employment, Equity Ownership. Cheng: Allogene Therapeutics, Inc.: Employment, Equity Ownership. Pertel: Allogene Therapeutics: Employment, Equity Ownership. Santaguida: Notable Labs: Employment. Galetto: Cellectis Inc: Employment. Sasu: Allogene Therapeutics, Inc.: Employment, Equity Ownership.}
}
@article{DEVINE20212846,
title = {Cryopreservation of Allogeneic Hematopoietic Cell Grafts Did Not Adversely Affect Early Post-Transplant Survival during the First Six Months of the COVID-19 Pandemic},
journal = {Blood},
volume = {138},
pages = {2846},
year = {2021},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2021-151445},
url = {https://www.sciencedirect.com/science/article/pii/S0006497121047856},
author = {Steven Devine and Michelle Kuxhausen and Stephen R. Spellman and Caitrin Fretham and Kwang {Woo Ahn} and Heather E. Stefanski and Jeffery J. Auletta and Brent R. Logan and Bronwen E. Shaw},
abstract = { Introduction: During the COVID-19 pandemic, concerns regarding travel logistics and donor safety necessitated a substantial increase in the use of cryopreserved hematopoietic stem cell (HSC) grafts from both related (RD) and unrelated donors (URD) to ensure patients have a graft available prior to the start of conditioning for hematopoietic cell transplantation (HCT). However, pre-pandemic data beyond single center or small multi-center reports are lacking to reassure clinicians that cryopreservation of allogeneic grafts does not adversely impact post-HCT outcomes including hematopoietic engraftment and overall survival (OS). The Center for International Blood and Marrow Transplant Research (CIBMTR) has recently published three retrospective analyses of outcomes in recipients of cryopreserved compared to fresh grafts administered prior to the pandemic. Results have been conflicting and reasons for receipt of cryopreserved grafts were not routinely collected, rendering interpretation of the impact of cryopreservation on clinical outcomes problematic. Since the pandemic provided a unifying rationale (including mandatory cryopreservation required by the National Marrow Donor Program (NMDP) and other major registries) for the majority of patients to receive cryopreserved allografts, we sought to evaluate early post-HCT clinical outcomes in patients reported to the CIBMTR database who received a first allogeneic HCT using cryopreserved grafts from March through August 2020. Methods: Key study endpoints were hematopoietic engraftment and overall survival (OS). We compared these outcomes to those in patients allografted using fresh products transplanted between March through August 2019. Additional patient selection criteria included: 1) recipients in US only, 2) peripheral blood stem cell (PBSC) or bone marrow (BM) grafts, 3) consented to research, and 4) availability of both CIBMTR product infusion and post-HCT day 100 (D100) follow-up form. The Pearson chi-square test was used for comparing discrete variables; the Kruskal-Wallis test was used for comparing continuous variables. Multivariate analysis (MVA) using a Cox proportional hazards model was performed for OS after adjusting for confounders and testing the proportional hazards assumption. Neutrophil engraftment by D28 and platelet engraftment by D100 were analyzed using multivariate logistic regression. Results: This study included 959 and 2,499 recipients of cryopreserved and fresh products, respectively. Patient characteristics are presented in Table 1. Recipients of cryopreserved grafts were older, more likely to receive URD grafts, PBSC as the graft source and post-transplant cyclophosphamide (PTCy) for graft versus host disease (GVHD) prophylaxis. They received lower infused PBSC and BM cell doses. Due to differences in duration of follow-up between the cohorts, follow up for the OS analysis was censored at Days 100 and 180. MVA results are presented in Table 2. No impact of cryopreservation on OS at either D100 (HR 0.93, p=0.72) or D180 (HR 1.10, p=0.34) post HCT was detected (see also Figure 1). When we performed the MVA for OS limiting the analysis to URD recipients only, the results were unchanged. Median time to neutrophil and platelet engraftment were both delayed by 1 day in recipients of cryopreserved grafts (16 vs. 15 days and 21 vs. 20 days, respectively) but there was no difference in the risk of primary graft failure by D28 (OR 1.38, p=0.96). Some delay in D100 platelet engraftment was observed in recipients of cryopreserved grafts (OR 0.67, p<0.005). There were no interactions identified between donor or graft type for OS or engraftment. Other important clinical outcomes such as secondary graft failure, acute GVHD, and early relapse are being analyzed and will be included at the time of abstract presentation. Conclusion: The shift in clinical practice to cryopreserved products necessitated during the pandemic did not adversely impact early post HCT OS or risk of primary graft failure. We caution that follow up is short and it will be critical to follow this cohort and subsequent recipients of cryopreserved grafts for much longer periods to determine the ultimate impact of cryopreservation on outcomes. Nevertheless, this large multi-center study will be useful to inform clinical decision making both during and following the pandemic. Figure 1
Disclosures
Devine: Sanofi: Consultancy, Research Funding; Magenta Therapeutics: Current Employment, Research Funding; Tmunity: Current Employment, Research Funding; Vor Bio: Research Funding; Kiadis: Consultancy, Research Funding; Johnsonand Johnson: Consultancy, Research Funding; Orca Bio: Consultancy, Research Funding; Be the Match: Current Employment. Stefanski: Novartis: Honoraria. Shaw: mallinkrodt: Other: payments; Orca bio: Consultancy.}
}
@article{ALI2020S147,
title = {Revisiting an Old Concept in a New Era: 36 Hour Lung Preservation Using 10ºC Static Cold Storage},
journal = {The Journal of Heart and Lung Transplantation},
volume = {39},
number = {4, Supplement },
pages = {S147},
year = {2020},
issn = {1053-2498},
doi = {https://doi.org/10.1016/j.healun.2020.01.1074},
url = {https://www.sciencedirect.com/science/article/pii/S1053249820310913},
author = {A. Ali and B. Gomes and A. Wang and R. Ribeiro and M. Galasso and O. Hough and E.L. Beronical and T.K. Waddell and M. Liu and A.C. Andreazza and S. Keshavjee and M. Cypel},
abstract = {Purpose
Despite remote reports indicating 10°C to be the optimal temperature for cold static organ preservation (CSP), preservation of lungs in an ice cooler at 4°C remains the standard strategy in clinical transplantation. Here, we used a commercially available device that can keep a donor lung at 10°C conveniently and compared 10°C vs. 4°C during a prolonged period of CSP followed by functional and biological assessment of lung grafts.
Methods
Lungs were procured from Yorkshire pigs (28-35kg), flushed with a low-potassium dextran solution and randomized into two groups (n=5 each): CSP at 4°C vs. CSP at 10°C (MyTemp Mini Incubator, Benchmark Scientific). After 36h of CSP, lungs were subjected to 12h of normothermic ex vivo lung perfusion (EVLP) with hourly functional assessment. Lung biopsies and perfusate samples were taken for biological and metabolic evaluation.
Results
During 12h of EVLP, lungs stored at 10°C presented superior physiological parameters compared to 4°C (Fig 1A). Reduced edema formation was seen as represented by a lower lung weight gain during EVLP (30 ± 34.1 vs. 201 ± 33.2 g, p = 0.0159). Metabolic profiles of the EVLP perfusate were significantly more favorable in the 10°C group compared to 4°C (Fig 1B). Furthermore, the 10°C group had significantly less inflammation demonstrated by lower levels of pro-inflammatory cytokines IL-1β (p = <0.0001, Fig 1C), and IL-8 (p = <0.0001, Fig 1C) in the EVLP perfusate. The levels of IL-6 were significantly lower in both EVLP perfusate (p = <0.0001, Fig 1C) and post-perfusion lung tissue (p = 0.0317). Immunohistochemical analysis for 8-Hydroxyguanosine demonstrated that lungs stored at 10°C tended to have less oxidative stress during CSP (p = 0.0952).
Conclusion
With simple controllable refrigerators, 10°C preservation is easily achievable and provides significantly superior CSP in comparison to conventional 4°C storage. This could potentially remarkably improve the clinical and transportation logistics in lung transplantation.}
}
@article{YUNUSA2020S37,
title = {Uptake of tuberculosis prevention therapy in people living with HIV/AIDS in northern Nigeria: a programme to increase use of isoniazid preventive therapy},
journal = {The Lancet Global Health},
volume = {8},
pages = {S37},
year = {2020},
note = {CUGH 11th annual conference},
issn = {2214-109X},
doi = {https://doi.org/10.1016/S2214-109X(20)30178-9},
url = {https://www.sciencedirect.com/science/article/pii/S2214109X20301789},
author = {Fadimatu Yunusa and Maryam Bello and Gbenga A Kayode and Adeoye Adegboye and Geraldine Abone and Fati Murtala-Ibrahim and Martha Okposo and Atinuke Anjorin and Saswata Dutt and Oche Yusuf and Nadia Sam-Agudu and Patrick Dakum},
abstract = {Background
Tuberculosis is a main cause of death in people living with HIV and results in around 39 000 deaths every year in Nigeria. Isoniazid preventive therapy (IPT), the standard tuberculosis preventive therapy used in Nigeria, has been shown to significantly reduce mortality and prevent tuberculosis in people with HIV. Despite efforts and strategies to scale up this treatment in Nigeria, the process has remained very slow. Here we describe a programme to increase IPT uptake in health facilities in four states in northern Nigeria, while also monitoring trends in IPT use with the aim of increasing access for people with HIV.
Methods
Data were collected at 90 health facilities in Nasarawa, Kano, and Katsina states and the Federal Capital Territory (FCT), Nigeria, between Oct 1, 2017, and March 31, 2019. A monitoring tool was used to track clinic attendance, IPT eligibility status, and percentage uptake of isoniazid (the proportion of people with HIV starting a 6 month course of isoniazid) in patients with HIV at these health facilities. Baseline data were collected between Oct 1, 2017, and Feb 28, 2018, and identified reasons for low IPT uptake included: stockout of isoniazid, documentation gaps, improper filling of the relevant source documents, and poor clinician awareness of use of IPT. In response to these barriers to uptake, interventions such as folder tagging and electronic prompts of eligible clients prior to clinic visits, clinician sensitisations through training and retraining to raise the awareness of IPT, and active tracking of eligible clients were implemented. We collected post-intervention data from March 1, 2018, to March 31, 2019. Analysis was done using Excel and STATA.
Findings
During the 6 month pre-intervention period, 3659 (14%) patients were commenced on isoniazid out of 26 136 eligible patients. In the initial 6 months post-intervention, 18 367 (80%) patients were started on isoniazid out of 22 020 eligible patients. Uptake dropped suddenly in October, 2018, due to stockout of isoniazid. Remedial stock redistribution resulted in a steady increase of isoniazid uptake and a total number of 43 075 patients out of 50 050 patients (86%) commenced isoniazid within the 12 month review period.
Interpretation
Capacity building of health-care workers on isoniazid through training and retraining resulted in marked improvements in IPT uptake through: increased health-care worker knowledge about IPT; proper documentation on the relevant source documents and the electronic medical records; and availability, and use of, isoniazid electronic prompts to highlight clients who were eligible for IPT. However, there is a need to strengthen drug logistics, especially in guaranteeing a consistent and adequate supply of isoniazid in all facilities to avoid stockouts, thus ensuring optimum IPT uptake or access for people living with HIV in Nigeria.
Funding
Institute of Human Virology, Nigeria}
}
@article{UNDURRAGA20206162,
title = {Costs and effectiveness of alternative dog vaccination strategies to improve dog population coverage in rural and urban settings during a rabies outbreak},
journal = {Vaccine},
volume = {38},
number = {39},
pages = {6162-6173},
year = {2020},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2020.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X20307672},
author = {Eduardo A. Undurraga and Max F. Millien and Kasim Allel and Melissa D. Etheart and Julie Cleaton and Yasmeen Ross and Kelly Crowdis and Alexandra Medley and Ad Vos and Emmanuel Maciel and Benjamin Monroe and Amber Dismer and Jesse D. Blanton and Cuc H. Tran and Richard Chipman and Pierre Dilius and Fleurinord Ludder and Ryan M. Wallace},
keywords = {Health economics, Infectious disease, Rabies, Vaccination, Zoonotic diseases, One health, Global health},
abstract = {Dog-rabies elimination programs have typically relied upon parenteral vaccination at central-point locations; however, dog-ownership practices, accessibility to hard-to-reach sub-populations, resource limitations, and logistics may impact a country’s ability to reach the 70% coverage goal recommended by the World Organization for Animal Health (OIE) and World Health Organization (WHO). Here we report the cost-effectiveness of different dog-vaccination strategies during a dog-rabies outbreak in urban and peri-urban sections of Croix-des-Bouquets commune of the West Department, Haiti, in 2016. Three strategies, mobile static point (MSP), mobile static point with capture-vaccinate-release (MSP + CVR), and door-to-door vaccination with oral vaccination (DDV + ORV), were applied at five randomly assigned sites and assessed for free-roaming dog vaccination coverage and total population coverage. A total of 7065 dogs were vaccinated against rabies during the vaccination campaign. Overall, free-roaming dog vaccination coverage was estimated at 52% (47%-56%) for MSP, 53% (47%-60%) for DDV + ORV, and 65% (61%-69%) for MSP + CVR (differences with MSP and DDV + ORV significant at p < 0.01). Total dog vaccination coverage was 33% (95% CI: 26%-43%) for MSP, 49% (95% CI: 40%-61%) for MSP + CVR and 78% (77%-80%) for DDV + ORV (differences significant at p < 0.001). Overall, the least expensive campaign was MSP, with an estimated cost of about $2039 per day ($4078 total), and the most expensive was DDV + ORV with a cost of $3246 per day ($6492 total). Despite the relative high cost of an ORV bait, combining DDV and ORV was the most cost-effective strategy in our study ($1.97 per vaccinated dog), largely due to increased efficiency of the vaccinators to target less accessible dogs. Costs per vaccinated dog were $2.20 for MSP and $2.28 for MSP + CVR. We hope the results from this study will support the design and implementation of effective dog vaccination campaigns to achieve the goal of eliminating dog-mediated human rabies deaths by 2030.}
}
@article{KERUAKOUS20195864,
title = {Key Barriers to Clinical Trial Enrolment: A Survey of Clinical Trial Staff at an NCI Designated Cancer Center},
journal = {Blood},
volume = {134},
pages = {5864},
year = {2019},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2019-126257},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118637905},
author = {Amany R. Keruakous and Adam S. Asch},
abstract = {Background: Clinical trials, key elements of the processes that account for many of the recent advances in cancer care, are becoming more complex and challenging to conduct. The Stephenson Cancer Center (SCC) has been the lead accruer to NCI-LAP trials over the past three years, and in addition, fields investigator initiated and industry sponsored trials. To identify opportunities for continued improvement in clinical trial enrolment, we sought to identify the obstacles encountered by our clinical trial staff in these activities. Method: We conducted a survey of our research staff including all research nurses and disease site coordinators who participate in recruitment, screening, consenting, data collection and compliance. The survey, sent by email to the clinical trial list-serve at SCC (90 staff member), invited respondents to enumerate obstacles to patient participation in clinical trials. We then performed a follow up meeting with our research coordinators to clarify responses. A total of 26 responses from 90 respondents were received and tabulated by disease site. Results: The most commonly reported obstacles to enrolment were, in descending order: communication/language barriers, cultural bias, time/procedure commitment, and complexity of the trial protocol, financial logistics, comorbidities, and stringent trial criteria. Respondents identified 83 obstacles as frequently encountered obstacles to enrolment. The 83 reported obstacles were classified into 9 categories and organized by disease site as presented in tabular format (below). The most commonly identified obstacles to patient enrolment were communication and language barriers. In patients for whom Spanish is the primary language this was a universal obstacle, as there is a lack of consistent Spanish consents across the clinical trial portfolio. Cultural bias, as an obstacle was manifested as a general mistrust by prospective trial participants of experimental therapies and clinical trials. After communication and cultural bias as barriers, travel requirements and the associated expenses playing a role in patients from rural areas were identified as the most commonly encountered barrier. The complexity of trial protocols and the associated large number of clinic visits, frequent laboratory and imaging tests were also identified as common obstacles. Clinical trial complexity with strict inclusion and exclusion criteria and trial-specified biopsies were frequently cited. Implications: In this descriptive study, common barriers to patient enrolment in clinical trials were identified by clinical trial staff. Assessing barriers encountered by clinical trial staff is infrequently used as a metric for improving clinical trial enrolment, but provides important perspective. In our study, some obstacles are inherent in our patient populations, others appear to be actionable. Development of Spanish language consents and specific programs to overcome negative bias regarding clinical trials are potential areas for improvement. The complexity of clinical trial protocols and the increasingly strict inclusion/exclusion criteria, are issues that will require consideration and action at the level of the cooperative groups and industry. 
Disclosures
No relevant conflicts of interest to declare.}
}
@article{GALANOLLEROS2021,
title = {Planificar fracturas es sencillo: desarrollo de un método básico de planificación digital basado en la técnica tradicional con lápiz y papel},
journal = {Revista Española de Cirugía Ortopédica y Traumatología},
year = {2021},
issn = {1888-4415},
doi = {https://doi.org/10.1016/j.recot.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1888441521000904},
author = {M. Galán-Olleros and J. García-Coiradas and S. Llanos and J.A. Valle-Cruz and F. Marco},
keywords = {Planificación preoperatoria, Planificación digital, Programa informático, Fracturas, Reducción y osteosíntesis, Formación, Preoperative planning, Digital templating, Computer software, Fracture, Reduction and osteosynthesis, Training},
abstract = {Resumen
Introducción
La planificación preoperatoria constituye una herramienta fundamental en el manejo de fracturas; sin embargo, su aplicación práctica dista de lo deseado, quizá debido a la ausencia de un método básico y sencillo, adaptado a los tiempos actuales. Describimos un método de planificación digital, entre lo tradicional y lo tecnológico, que conserva su esencia educativa, permite comprender la fractura e individualizar la osteosíntesis.
Material y métodos
Tras el análisis inicial de la fractura y características del paciente, se realizan diferentes mediciones en las imágenes de Rx y TC con un programa de imagen médica digital. Estas imágenes se copian en un programa de presentación (Microsoft® PowerPoint o Keynote ©Apple Inc.), en el que se reproducen con el puntero del ordenador los principales fragmentos y líneas de fractura. A continuación, estos se mueven a una posición reducida y se representan gráficamente los implantes para la fijación interna junto con un guion de la estrategia quirúrgica.
Resultados
Mostramos 4 casos de diferentes tipos de fracturas intervenidas mediante reducción y osteosíntesis tras una planificación preoperatoria según el método descrito. Se detallan los puntos básicos para la planificación quirúrgica, logística, táctica y los resultados radiológicos postoperatorios de cada caso.
Conclusiones
A pesar del auge de programas informáticos avanzados de planificación, los métodos tradicionales con lápiz y papel siguen siendo fundamentales, más aún para el traumatólogo en formación. El método de planificación digital descrito resulta muy adecuado para este objetivo, al aunar las ventajas de ambos métodos: sencillez, accesibilidad, rapidez, bajo coste, reproducibilidad, carácter formativo y eficacia y por posibilitar la simulación, correcciones y la reutilización de casos.
Introduction
Preoperative planning constitutes a fundamental tool in the management of fractures; however, its practical application is far from the desired, perhaps due to the absence of a basic and simple method, adapted to the current times. We describe a digital planning method, halfway between the traditional and the technological, which preserves its educational essence, allows the understanding of the fracture and the individualization of the osteosynthesis.
Material and methods
After the initial analysis of the fracture and the patient's characteristics, different measurements are made on X-ray and CT images with a digital medical imaging software. These images are then copied into a presentation program (Microsoft® PowerPoint or Keynote ©Apple Inc.), in which the main fragments and fracture lines are traced with the computer pointer. These are subsequently moved into a reduced position and the implants for internal fixation are graphically represented together with a guide of the surgical strategy.
Results
We show 4 cases of different types of fractures operated through reduction and osteosynthesis after preoperative planning according to the described method. The basic points for the surgical planning, logistics, tactics and postoperative radiological results of each case are detailed.
Conclusions
Despite rise of advanced planning software, traditional paper and pencil methods are still fundamental, even more so for the trauma surgeon in training. The digital planning method described is very appropriate for this purpose, as it combines the advantages of both methods: simplicity, accessibility, quickness, low-cost, reproducibility, educational character, efficiency and possibility of simulation, corrections and reuse of cases.}
}
@article{AMPARORE20201032,
title = {Forecasting the Future of Urology Practice: A Comprehensive Review of the Recommendations by International and European Associations on Priority Procedures During the COVID-19 Pandemic},
journal = {European Urology Focus},
volume = {6},
number = {5},
pages = {1032-1048},
year = {2020},
issn = {2405-4569},
doi = {https://doi.org/10.1016/j.euf.2020.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2405456920301425},
author = {Daniele Amparore and Riccardo Campi and Enrico Checcucci and Francesco Sessa and Angela Pecoraro and Andrea Minervini and Cristian Fiori and Vincenzo Ficarra and Giacomo Novara and Sergio Serni and Francesco Porpiglia},
keywords = {Association, Coronavirus, COVID-19, Priority, Society, Urology},
abstract = {Context
The unprecedented health care scenario caused by the coronavirus disease 2019 (COVID-19) pandemic has revolutionized urology practice worldwide.
Objective
To review the recommendations by the international and European national urological associations/societies (UASs) on prioritization strategies for both oncological and nononcological procedures released during the current emergency scenario.
Evidence acquisition
Each UAS official website was searched between April 8 and 18, 2020, to retrieve any document, publication, or position paper on prioritization strategies regarding both diagnostic and therapeutic urological procedures, and any recommendations on the use of telemedicine and minimally invasive surgery. We collected detailed information on all urological procedures, stratified by disease, priority (higher vs lower), and patient setting (outpatient vs inpatient). Then, we critically discussed the implications of such recommendations for urology practice in both the forthcoming “adaptive” and the future “chronic” phase of the COVID-19 pandemic.
Evidence synthesis
Overall, we analyzed the recommendations from 13 UASs, of which four were international (American Urological Association, Confederation Americana de Urologia, European Association of Urology, and Urological Society of Australia and New Zealand) and nine national (from Belgium, France, Germany, Italy, Poland, Portugal, The Netherlands, and the UK). In the outpatient setting, the procedures that are likely to impact the future burden of urologists’ workload most are prostate biopsies and elective procedures for benign conditions. In the inpatient setting, the most relevant contributors to this burden are represented by elective surgeries for lower-risk prostate and renal cancers, nonobstructing stone disease, and benign prostatic hyperplasia. Finally, some UASs recommended special precautions to perform minimally invasive surgery, while others outlined the potential role of telemedicine to optimize resources in the current and future scenarios.
Conclusions
The expected changes will put significant strain on urological units worldwide regarding the overall workload of urologists, internal logistics, inflow of surgical patients, and waiting lists. In light of these predictions, urologists should strive to leverage this emergency period to reshape their role in the future.
Patient summary
Overall, there was a large consensus among different urological associations/societies regarding the prioritization of most urological procedures, including those in the outpatient setting, urological emergencies, and many inpatient surgeries for both oncological and nononcological conditions. On the contrary, some differences were found regarding specific cancer surgeries (ie, radical cystectomy for higher-risk bladder cancer and nephrectomy for larger organ-confined renal masses), potentially due to different prioritization criteria and/or health care contexts. In the future, the outpatient procedures that are likely to impact the burden of urologists’ workload most are prostate biopsies and elective procedures for benign conditions. In the inpatient setting, the most relevant contributors to this burden are represented by elective surgeries for lower-risk prostate and renal cancers, nonobstructing stone disease, and benign prostatic hyperplasia.}
}
@article{GARWOOD202035,
title = {Air Ambulance and Emergency Retrieval Services in Western Australia: Caseload Analysis Over 5 Years},
journal = {Air Medical Journal},
volume = {39},
number = {1},
pages = {35-43},
year = {2020},
issn = {1067-991X},
doi = {https://doi.org/10.1016/j.amj.2019.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S1067991X1930197X},
author = {James Garwood and Brian Wilkinson and Helen Bartholomew and Stephen A. Langford and Angela O'Connell},
abstract = {Objective
The Royal Flying Doctor Service Western Operations (RFDSWO) provides critical care transfer and retrieval services across 2.5 million km2 to a population of 2.58 million people, providing both primary and secondary retrievals across Western Australia. Flying on average 26 million km/y, retrievals are undertaken with the use of rotary and fixed wing aircraft. Our current fleet includes 16 Pilatus PC-12NGs turboprops, 2 Pilatus PC-24 jets, and access to 1 helicopter (Bell 412). A Hawker XP800 Jet was retired in 2019 after 10 years of service. Our retrieval teams are formed of either a doctor and a nurse or a nurse only on fixed wing missions and a doctor and critical care paramedic for helicopter emergency medical services missions. We present our experiences and caseload statistics over the past 5 years.
Methods
We performed an analysis of our retrieval database looking at the workload from January 1, 2012, to December 31, 2016. This included the number of patients, age, ethnicity, type of retrieval, priority, diagnosis, and distances covered.
Results
Forty-three thousand forty-one patients underwent Royal Flying Doctor Service air transfer over a 5-year period. Aboriginal patients comprise around 3.1% of the Western Australian population but accounted for 33% of RFDSWO retrieval missions. There was a mean transfer rate of 8,608 patients per year, which was relatively consistent across the study period. The modal age was 55 to 59 years, but Aboriginal patients were younger with a mean age of 36.5 years (Aboriginal) versus 49.7 years (non-Aboriginal). The types of retrieval undertaken were as follows: primary (17.3%), secondary (81%), and repatriation (1.7%). The urgency/priority of missions was as follows: immediate (7.3%), urgent (54.5%), and semiurgent (38.1%). The 3 most common diagnosis (International Statistical Classification of Diseases, 10th Revision) categories were trauma/injury (22.9%), cardiovascular (22.3%), and gastrointestinal (10.5%). The modal distance flown was 700 km per mission.
Conclusion
RFDSWO has 1 of the largest retrieval workloads in the world, covering a landmass comparable with Western Europe. This brings with it a variety of challenging cases and complex logistics, often in extremely harsh and remote environments. We bring a wide breadth of experience in the area of retrieval medicine, and our aim is to share these experiences with other teams.}
}
@article{MAHMOUDJAFARI2019S279,
title = {Development of Processes to Ensure Timely Administration of Tocilizumab in the Setting of Cytokine Release Syndrome after Administration of Tisagenlecleucel or Axicabtagene Ciloleucel},
journal = {Biology of Blood and Marrow Transplantation},
volume = {25},
number = {3, Supplement },
pages = {S279},
year = {2019},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2018.12.347},
url = {https://www.sciencedirect.com/science/article/pii/S1083879118311698},
author = {Zahra Mahmoudjafari and Tanya Folker and Allyce Schenk Hansford and Katie Griffith and Caroline Strohm and Joseph McGuirk},
abstract = {Introduction
With the commercial approval of tisagenlecleucel and axicabtagene ciloleucel, tocilizumab was concurrently approved by the Food and Drug Administration (FDA) for the management of cytokine release syndrome (CRS).1,2 Per the FDA Risk Evaluation and Mitigation Strategy (REMS) requirements, the pharmacy must stock a minimum of two doses of tocilizumab for each patient, available for administration within two hours.1,2 The complex logistics of the immediate administration of this product in a large academic medical center required coordination of a multidisciplinary team.
Objectives/Methods
Our multidisciplinary team participated in weekly meetings to develop standard policies and treatment algorithms to treat the acute toxicities seen with tisagenlecleucel and axicabtagene ciloleucel. We also created an annual pharmacy competency outside of the REMS requirements for all inpatient pharmacy staff to ensure awareness and emphasize the need for prompt administration of tocilizumab. Our IT team worked to develop electronic solutions including a PRN entry of tocilizumab that would be released concurrently with the cell infusion order and would be readily available on the patient's medication administration record (MAR) for immediate dispensing. As CRS can occur following the initial admission, we created a “prepare and give now” entry for tocilizumab within our toxicity treatment order set in preparation of potential future admissions. The entry includes help text with the dosing information and is capped at 800 mg. For all scenarios in which tocilizumab administration is necessary, the attending on service is required to call the inpatient pharmacy directly to provide the verbal order to dispense a dose. This safety step ensures that the attending on service is knowledgeable of the patient's symptoms and agrees with use.
Results/Conclusion
Of the patients that we have treated to date, our median number of tocilizumab doses is 1 dose (range 0-4). Our median time from dispense to administration is 53.5 minutes (range 23-85 minutes) [Table 1].  This demonstrates that our education efforts and available resources have resulted in our ability to properly manage CRS and to dispense and administer tocilizumab well under the 2-hour time frame dictated by the REMs requirements.}
}
@article{CHEN2019S266,
title = {Analysis of Discrepancy between Expected and Actual Donor-Recipient Matching in Heart Transplantation},
journal = {The Journal of Heart and Lung Transplantation},
volume = {38},
number = {4, Supplement },
pages = {S266},
year = {2019},
issn = {1053-2498},
doi = {https://doi.org/10.1016/j.healun.2019.01.662},
url = {https://www.sciencedirect.com/science/article/pii/S1053249819306643},
author = {C.R. Chen and M. Connellan and E. Granger and Y. Kawanishi and A. Jabbour and P. Macdonald and K. Muthiah and C. Hayward and K. Dhital},
abstract = {Purpose
We hypothesised that for any donor, there is a significant discrepancy, driven by logistical variables, between the expected and actual recipient of a heart transplant (HTx).
Methods
51 deidentified donor information sheets and waiting lists (comprising 1488 entries and 93 patients) from August 2017-2018 at St Vincent's Hospital Sydney (SVHS) were given to HTx surgeons and physicians, who ranked their top 10 recipients for transplant and variables relating to HTx by importance. Two Cardiac Allocation Scores (CASs) were used to rank recipients, filtered by ABO group, then weight/predicted heart mass, and adjusted for immunological cross-matching. Three ranker groups gave “expected” matches and rankings - CASs, surgeons and physicians. Inter-rater reliability on variable and waitlisted candidate rankings was analysed with Krippendorff's α, and pairwise inter-rater agreement on candidate rankings with Rank Biased Overlap (RBO). Logistical factors were correlated to a ranker's top candidate being transplanted with univariate and stepwise multivariate logistic and linear regression. Characteristics of top-ranked and actual recipients were compared with the t, Wilcoxon rank sum and χ2 tests.
Results
Across all rankers, expected and actual recipients matched in 25.66% of cases on average (31.38% for surgeons and physicians). Regarding rankings of HTx candidates and variables of importance in HTx, inter-rater reliability and agreement between rankers, ranged from low to moderate (αvariables=0.22-0.69, RBO=0.23-0.61; 1=total agreement) within and between groups. Flight as mode of transport was consistently significantly correlated with concordance of expected and actual recipient across multiple rankers (p=<0.0001-0.0484), as were operating surgeon seniority (registrar vs consultant) (p=0.0022-0.0479) and distance to donor hospital (p=0.0043-0.0338). Factors differing significantly between actual and expected recipients accorded with the doctors’ variable rankings, especially internal priority (p=0.0024-0.0475), active wait time (p=0.0015-0.0458) and right heart catheter parameters (e.g. MPCWP, p=0.0055-0.0488).
Conclusion
At SVHS, discrepancy exists between actual and expected donor-recipient matching in HTx for doctors and CASs. Transplant logistics and individual practice variations contribute to this.}
}
@article{WANG202010,
title = {Utilization of Telemedicine for Comprehensive Visits in Patients with Inherited Bleeding Disorders during the COVID-19 Pandemic},
journal = {Blood},
volume = {136},
pages = {10-11},
year = {2020},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2020-138424},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118733685},
author = {Cassandra P Wang and Kelly Ann Bush and Rosalie Brooks and Katharine Farrow and Lizandra Gilsdorf and Fernanda Cortez and Courtney D Thornburg},
abstract = {Standard of care for individuals with inherited bleeding disorders includes an annual in person multi-disciplinary comprehensive visit at the Hemophilia Treatment Center (HTC). During the COVID-19 pandemic in person visits were restricted, with mandates to only schedule in person urgent visits and to “stay at home.” In order to provide annual visits to as many patients as possible, we developed a quality improvement (QI) project to conduct annual visits via telemedicine (TM), including nursing (RN), physician (MD), social work (SW), and physical therapy (PT) assessments. Our aim was to increase annual comprehensive clinic visits conducted by TM for eligible patients from 0 to 50% between April 1 and June 30, 2020, extended through July 31, 2020 due to the prolonged pandemic. Patients due for an annual visit were contacted by medical assistants (MA) to schedule either a TM (through EPIC MyChart) or an in person visit. MAs were trained on which patients were eligible for a TM visit and how to set-up MyChart remotely. Prior to the visit patients were provided verbal, written, and video instructions on how to attend the TM visit. Quantitative and qualitative data were collected at the time of scheduling and during the visit. Forty-eight patients were scheduled for an annual visit during the QI timeframe. TM visits were not offered to 28 patients for a variety of reasons (first comprehensive clinic visit, need to re-establish or transfer care, need for required laboratory testing, or joint disease requiring in person PT evaluation). Out of the 20 patients who were eligible for a TM visit, 14 (70%) accepted. The two main reasons for declining TM visits were personal preference for an in person visit and preference to not use/activate MyChart. Table 1 compares the characteristics of patients who completed their annual visit via TM versus in person. Of the 14 patients who accepted TM visits, 11 completed the visit and 3 were no-shows. All four adolescent patients who attended their TM completed their annual transition questionnaire online prior to the visit. Of the 11 patients who completed TM visits, 4 (36.3%) saw the same providers during both their TM visit and in person visit the year prior. Of those who saw fewer providers during the TM visits, the most commonly missed providers were the dietician and genetic counselor. TM visits were primarily conducted through two-way audio and video communication within MyChart, while 1 was through Zoom and the other by audio only. Eight of the 11 (72.7%) TM visits had technical issues, including difficulty connecting to MyChart and poor internet connection requiring the remainder of the visit to be completed by audio only. Despite the technical issues, the majority of patients (81.8%) stated that they would prefer in person visits over TM visits in the future. The most common reasons for preference of TM visits in the future were convenience and ability to avoid the clinic during the pandemic. The HTC team members also perceived that TM visits ran more efficiently than the in person visits despite the technical issues during the visits. For in person visits, families were pre-screened by phone and at the time of arrival for symptoms of COVID-19, exposures, and travel outside of US. Two patients only reported potential exposure/travel to the providers in the HTC clinic, which required isolation and use of additional personal protective equipment (PPE). Overall, we increased the number of annual comprehensive clinic visits conducted by TM from 0 to 70% for eligible patients between April 1 and July 31, 2020 during the COVID-19 pandemic. Although there were technical difficulties with the TM visits, the majority of patients found the TM visit to be convenient and expressed a preference for TM for future visits. TM visits reduced potential exposures and use of PPE. Future interventions to improve TM visits include promoting MyChart utilization, additional education for patients regarding logistics of connecting to a TM visit, and additional education for providers regarding the troubleshooting of technical issues. Future QI measures may include patient satisfaction, duration of TM compared to in person visits, and need for additional care coordination post TM visit. In addition, impact on patient outcomes (such as need for return visits or bleeds) should also be evaluated. 
Disclosures
Thornburg: Bluebird Bio: Consultancy; Biomarin: Consultancy, Speakers Bureau; Genentech: Speakers Bureau; NovoNordisk: Research Funding; Sanofi Genzyme: Consultancy, Other: Data Safety Monitoring Board, Research Funding; Spark Therapeutics: Consultancy; Ironwood Pharmaceuticals: Consultancy, Other: Data Safety Monitoring Board; National Hemophilia Foundation: Membership on an entity's Board of Directors or advisory committees, Research Funding; Bayer Pharmaceuticals: Research Funding; American Thrombosis and Hemostasis Network: Research Funding.}
}
@article{GENTILE2019371,
title = {Using Telehealth to Care for Children with Medical Complexity},
journal = {Journal of Pediatric Health Care},
volume = {33},
number = {4},
pages = {371},
year = {2019},
issn = {0891-5245},
doi = {https://doi.org/10.1016/j.pedhc.2019.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0891524519302172},
author = {Elise Madeck Gentile and Patricia M Notario and Matthew Amidon and Denise Angst and Cheryl Lefaiver and Kathleen Webster},
abstract = {Category/Date
Emerging Knowledge for Clinical Practice Podium Presentations focusing on the Research Agenda Priority of Pediatric Research: Chronic Illness, Presented at NAPNAP's 40th National Conference on Pediatric Health Care, March 8, 2019, New Orleans, LA.
Background
Children with medical complexity (CMC) are high utilizers of health care services. Cost and logistics of transportation may result in delays in seeking care, or seeking care after hours in an emergency department (ED). Telehealth encounters may provide an important means to address unmet health needs, prevent ED and hospital visits, reduce costs, and improve care outcomes for CMC. A pediatric nurse practitioner (PNP) is well-situated to use technology to help families meet goals of keeping their child at home.
Objectives
The purpose of the study was to evaluate the role of a PNP in use of a telehealth device in the care of CMC within an established pediatric complex care program. Specific aims were to assess the feasibility of telehealth in the home environment; evaluate its usability in transmitting real time data; and compare its impact on patient management.
Methods
This IRB approved, industry sponsored pilot study was conducted at a single center and employed a randomized clinical trial design. Participants were randomized 1.5:1 with stratification based on tracheostomy status to either a control group that received usual care or an intervention group that was given a telehealth device for use in the home at the discretion of a provider. All subjects were followed for 4 months (1 technical month, 3 study months) and had 24/7 access to the program providers, which included a PNP and a physician. Data collected included provider encounter surveys; family satisfaction surveys; and resource utilization type, purpose, and outcomes.
Results
Twenty-four patients were enrolled in the study: 9 controls,15 in the intervention group. In the intervention group, telehealth visits were attempted in 73 encounters. Providers reported successful device connectivity 92% of the time. Provider surveys indicated that the majority of encounters focused on respiratory/ENT complaints (66.7%). Based on provider survey results, usability for all device peripherals was acceptable (>90%), except for the otoscope (59%), which was related to patient refusal or parental discomfort. Families and providers expressed overall satisfaction with the device. Device use resulted in management changes such as close follow up by the PNP at home for a ventilated patient with a respiratory illness. Hospitalization rate decreased in the intervention group as compared to the control group (0.77 versus 1.14 PICU days/patient-month). Calculated cost rates (direct cost of encounter multiplied by the visit rate) showed a $44,751.65 ($9,425 per patient) cost savings for the intervention group.
Conclusions
Despite a small sample size and short study period, this pilot study demonstrated the feasibility of a PNP led telehealth program and that use of the telehealth device showed an overall benefit not only improving patient related outcomes but reducing cost of care. This study provides a foundation for examining the value of telehealth in the homes of other populations with special health care needs.}
}
@article{FLYNN2019171,
title = {Comparing algorithms to disaggregate complex soil polygons in contrasting environments},
journal = {Geoderma},
volume = {352},
pages = {171-180},
year = {2019},
issn = {0016-7061},
doi = {https://doi.org/10.1016/j.geoderma.2019.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S001670611930415X},
author = {Trevan Flynn and George {van Zijl} and Johan {van Tol} and Christina Botha and Andrei Rozanov and Benjamin Warr and Cathy Clarke},
keywords = {DSMART, Spatial disaggregation, Machine learning, Model comparison, National inventories},
abstract = {In South Africa, the only soil resource available with full spatial coverage is the national resource inventory. Disaggregating this polygon-based inventory, is thus a logical step to create more detailed soil maps covering the entire country. The polygons are large in area encompassing complex soil-terrain patterns and research into disaggregation techniques has been limited. This study aimed to compare 10 algorithms, implemented through a modified DSMART (“Disaggregating and Harmonizing Soil Map Units Through Resampled Classification Trees”) model, in their ability to disaggregate two polygons into soil associations in two environmentally contrasting locations. One site had high relief and strong catenal sequences (eastern KwaZulu-Natal Province) and the other site had low relief and a strong geological control of soil types (northern Eastern Cape Province). The algorithms compared were based on previous studies which included k-nearest neighbour, nearest shrunken centroid, discriminatory analysis, multinomial logistics regression, linear and radial support vector machines, decision trees, stochastic gradient boosting, random forest, and neural networks. The method involves stratifying the polygons with landform elements, randomly sampling the landform elements, allocating the soil classes based on the resource inventory, and predicting soil associations across a stack of covariates. This was done in an iterative process, creating multiple realisations of the soil distribution. The performance of each algorithm was based on their kappa and uncertainties. It was found that in general, robust linear models which either utilise an embedded feature selection or regularise covariates, performed best. In the area with high relief and clear toposequences, nearest shrunken centroid was the top performing algorithm with a kappa of 0.42 and an average uncertainty of 0.22. In the area with relatively low relief and complex geology, the results were unsatisfactory. However, a regularised multinomial regression was the top performing algorithm, achieving a kappa of 0.17 and an average uncertainty of 0.84. The results of this study highlight the versatility of a technique to disaggregate South Africa's national resource inventory, where algorithms can be chosen on expert knowledge, model averaging can be performed, the top performing algorithm can be chosen, and algorithm parameters can be optimised.}
}
@article{PHILIP202038,
title = {Procedural Pain and Serious Adverse Events with Bone Marrow Aspiration and Biopsy: Real World Experience from India},
journal = {Blood},
volume = {136},
pages = {38},
year = {2020},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2020-142204},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118734496},
author = {Chepsy C Philip and Inderjit Singh and Rachel Thaper and Alice David and Suvir Singh and Amrith Mathew and M. Joseph John},
abstract = {Background: Bone Marrow aspiration and Biopsy (BMAB) is perceived by patients as a painful procedure with fearsome complications. Though informed as safe and well tolerated; there is limited data about the complications and degree of pain experienced by patients undergoing BMAB.[1] Further scarce is data from the developing world where procedural fear discourages patients from pursuing treatment and diagnosis.[2] Methods Aims: To estimate the level of pain and frequency of serious adverse eventsexperienced by patients undergoing BMAB at our center. We also attempted to identify factors associated with increased pain perception. Study setting: This study was conducted at a tertiary level teaching hospital, the Christian Medical College & Hospital, Ludhiana. Ethics approval was obtained from the Institutional research committee (CMC/1495). Study period: 01 April 2015 through 30 Nov 2019 Study Design: This is a comparative cross sectional study where comparison of those with relatively more pain to those with less was done to elicit the factors associated with pain perception. Study Population: All consecutive patients who underwent a BMAB and provided informed consent which was taken pre-procedure, were included. We excluded patients who underwent the procedure under general anesthesia. Logistics of the Study: The BMAB was performed variably by Consultant Physicians, Trainee Physicians and Physician Assistants. All patients were pre-medicated with tramadol intravenous pre-procedure, and the preferred approach was from the posterior superior iliac spine (PSIS) in a left lateral decubitus under local anesthesia with lignocain. Patients were sent home or returned to their ward after upto 60 minutes of observation. A serious adverse event was considered as one requiring a prolonged observation beyond routine practice or extending to an admission to manage adverse events following and related to the BMAB. Data sources and variables Information regarding age at diagnosis, address and sex, indication to perform the BMAB, coded as malignant and non-malignant was collected from each patient. Number of prior procedures and details regarding food intake were collected as recalled by the patient. Level of pain was noted soon after the BMAB using a combined Wong-Baker grimace with numeric pain scale by the patient themselves. Statistical Analysis: Descriptive statistics were used to characterize variables. Univariate and Multivariate Logistic Regression were used to identify factors associated with higher pain severity (Score >2). Results: A total of 942 BMAB procedures were performed in this period. Baseline characteristics as tabulated below (Table1). Although the Mean + SD pain score was only 2.7 + 1.39, fourteen patients (1.48%) reported severe pain (>8). The following risk-factors were associated with increased pain on multivariate analysis: those experiencing their first BMAB procedure had very low odds of pain (OR (95 % CI): 0.23 (0.15-0.37)). However, when more than one attempt of biopsy was made, the odds of pain was much higher (OR (95 % CI): 1.62 (1.29-2.05)). Food and drink intake prior to procedure was associated only at the univariate level. Those who did not take any food prior to procedure had very high odds of pain (odds ratio (OR) 1.81 (95 % CI 1.01-3.22)). However, those who took juice had very low odds (OR (95 % CI): 0.619 (0.43-0.90)). Nine (0.95%) serious adverse events were reported. There were no deaths. The major serious adverse event was hemorrhage resulting from pseudo-aneurysm of the posterior iliac artery, which comprised 2 of the 9 serious adverse events. Other serious adverse events included persistent vomiting and severe aching pain in the ipsilateral leg. Conclusions: In our analysis BMAB is associated with a low level of procedural pain and is safe. The pain perception was not influenced by the operator. Factors associated with decreased pain perception were first procedural BMAB experience and successful completion of the procedure in the first attempt. Having at least a snack or a juice pre-procedure could reduce pain perception. Serious adverse events are rare in our experience. 
Disclosures
No relevant conflicts of interest to declare.}
}
@article{LARSEN2019111576,
title = {Ensiling of the pulp fraction after biorefining of grass into pulp and protein juice},
journal = {Industrial Crops and Products},
volume = {139},
pages = {111576},
year = {2019},
issn = {0926-6690},
doi = {https://doi.org/10.1016/j.indcrop.2019.111576},
url = {https://www.sciencedirect.com/science/article/pii/S0926669019305874},
author = {Søren Ugilt Larsen and Morten Ambye-Jensen and Henning Jørgensen and Uffe Jørgensen},
keywords = {Biomass storage, Silage, True protein, Amino acids, Biochemical methane potential, Effluent run-off},
abstract = {Biorefining of green biomass such as grass and grass-clover is an emerging field with extensive potentials for new value-chains and cascading use of biomasses. Grass biomass can be biorefined into a protein-rich juice fraction for monogastric feed purposes and a fibrous pulp fraction for ruminant feed or biogas production. This study investigated the ensiling of the pulp fraction after extraction of protein juice from two types of grass biomass, namely grass-clover and ryegrass with 28.8 and 33.6% total solid (TS) in the two pulp fractions, respectively. Lab-scale ensiling experiments for 3 to 5 months showed that increased time from processing of grass biomass to initiation of the ensiling of the pulp fraction resulted in higher final pH of the silage, particularly for the ryegrass pulp, and reduced concentration of lactic acid, total solid (TS), total amino acids (AAs) and free AAs. Addition of sucrose could, to some extent, counteract the effect of delayed ensiling on pH. Pilot-scale ensiling experiments for 7–11 months demonstrated limited effluent run-off with 1.8% for grass-clover pulp and 0.0% for ryegrass pulp. The ensiling of pulp had significant impact on a number of chemical constituents, e.g. with a reduction in neutral detergent fibre (NDF), in-vitro digestibility of organic matter (IVOS), total AAs and true protein but with an increase in free AAs. Also, ensiling significantly increased the biochemical methane potential (BMP) for anaerobic digestion durations up to 20 or 30 days but not at longer durations. Mass balances demonstrated a high recovery of volatile solids (97–98%), NDF (92–94%) and methane production potential (98–116%). However, recovery was lower for true protein (67–85%) and total AAs (84–90%), indicating some degradation of protein and AAs during ensiling. In conclusion, ensiling may offer an efficient way of conserving the quality of grass pulp, provided the process and logistics are optimized, particularly with a rapid sealing of the pulp after processing.}
}
@incollection{ACCORSI20191,
title = {Chapter 1 - Modeling inclusive food supply chains toward sustainable ecosystem planning},
editor = {Riccardo Accorsi and Riccardo Manzini},
booktitle = {Sustainable Food Supply Chains},
publisher = {Academic Press},
pages = {1-21},
year = {2019},
isbn = {978-0-12-813411-5},
doi = {https://doi.org/10.1016/B978-0-12-813411-5.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128134115000016},
author = {Riccardo Accorsi and Emilio Ferrari and Riccardo Manzini},
keywords = {Food supply chain, Sustainability, Ecosystem, Agriculture, Food distribution, Energy},
abstract = {The increasing global food demand is forcing the food industry to identify new effective strategies for production and distribution, as was already experienced in the 1960s and 1970s with the birth of green chemistry and the explosion of fossil-fueled agriculture. The globalization of the food trade has bridged the barriers between production and consumption without respecting the balance of natural resources, resulting in enlarged gaps between developed and developing countries. In the food sector many issues affect the three dimensions of sustainability: economic, environmental, and social. These include land-use change and deforestation to widen farms, pastures, and biofuel cultivations, land grabbing to establish intensive agriculture, clean water consumption, soil and air pollution, lack of supply chain infrastructures, volatile prices, and climate change. Together these issues make current food supply chains (FSCs) unsustainable over the long term and challenge the future of the food industries and society as well. Such issues also reveal the lack of connections and coordination among actors involved in FSCs and open debate about the neglected role of the physical and logistic/distribution infrastructures in addressing long-term sustainability targets. This chapter illustrates a hierarchical framework aimed at modeling production and distribution food ecosystems through a set of interdisciplinary parameters and decision variables. The decision levers identified in this framework describe how the food ecosystem behaves according to an input-output flow analysis. The framework formulates a set of planning decision problems via mixed linear programming. The definition of the inclusive food ecosystem inspires collecting multidisciplinary parameters that impose collaboration between decision-makers. Furthermore, as part of the ecosystem, logistics and distribution processes are involved in the planning issues beyond the common perception that sees an FSC as a sequence of independent stages.}
}
@article{NG20192152,
title = {Feasibility of Outpatient High Dose Cytarabine in Patients with Acute Myeloid Leukemia},
journal = {Blood},
volume = {134},
pages = {2152},
year = {2019},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2019-129858},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118600813},
author = {Chin-Hin NG and Xiaojuan Chen and Foong-Gwan Lee and Shi Hui Clarice Choong and Xiao-Shi Saw and Lon-Wann Sai and Michelle Poon and Hian Li Esther Hian Li Chan and Melissa Ooi and Yen Lin Chee and Yee Mei Lee},
abstract = {Background: High dose cytarabine (HiDAC) consolidation in AML is conventionally given in the inpatient setting over approximately 6-7 days. Patients usually tolerate this treatment uneventfully, with occasional cytarabine-related fever or rash. As the demand for limited inpatient healthcare continues to escalate, there is an urgent need to consider transitioning appropriate elective inpatient chemotherapy regimens to the outpatient setting to avoid unnecessary admission and save cost. The aim of our project was to examine the feasibility, safety and efficacy of outpatient administration of HiDAC in our institutional setting. Methods: Consecutive adult patients (>18 years old) with AML who fulfilled the inclusion criteria were recruited from our cancer center. All patients received daily HiDAC for 6 consecutive days (Based on ELN 2017 guideline), prophylactic steroid eyedrops and oral anti-emetic for 7 days. A nursing workflow for inpatient and outpatient to facilitate the transition of care. A patient information sheet was also produced to educate the patient and caregiver. Prior to implementation, outpatient training of nursing staff was conducted to ensure familiarity with administration, blood monitoring and common toxicities for the regimen. Prospective outcomes collected included chemotherapy-related toxicities (graded according to CTCAEv4.0), efficacy (continuous complete remission) of outpatient administration, logistics (including cancellations, delays) and number of admission days saved. Results: Over the period between September 2018 to July 2019, 15 patients were screened for suitability of outpatient HiDAC. 10 were eligible. Of the five ineligible patients, 2 were due to lack of caregiver and the other 3 patients had poor performance status (ECOG 3). 9 patients had at least 1 cycle of outpatient HiDAC. The other patient with single cycle had dose interrupted due to fever and hypotension and was admitted for presumed sepsis. A total of 16 cycles outpatient HiDAC were administered. All except one cycles were completed successfully in the outpatient setting. The adverse events observed during the 6 days treatment were three episodes of cytarabine-related fever, two patients had grade 1 cytarabine-related rash which resolved completely with antihistamine within a week, two patients had Grade 2 vomiting which resolved with additional oral anti-emetics and one with presumed sepsis that require admission. There was no cerebellar toxicity observed during treatment phase. All adverse events were managed in outpatient setting except one case with fever and hypotension resulting in admission. No treatment related mortality associated with the 16 cycles of HiDAC. Median time to neutrophil recovery was 25 days (range: 22-30 days), while median time to platelet count recovery was 32 days (range:21-63 days). All patients remained in complete remission at a median follow-up of 5 months (range: 1-7.5 months). Median time of delay administration was 50 minutes (range: 0-120 mins). 42% of the cycles had delay of <30 minutes. The main causes of delay were due to delay preparation by pharmacist (70%), nursing related (15%) and doctor-related (15%). With an average length of stay of 7 days for inpatient administration of HiDAC, we have saved 112 bed days from this 16 cycles of outpatient HiDAC administration. This would translate into 54% cost saving when compared to inpatient cost. Conclusions: Our results show outpatient administration of HiDAC is feasible and safe. Importantly this results in a significant number of admission days saved with consequent cost savings for the patient while freeing up bed capacity for necessary admissions. Other intangible benefits would include reduced risk of hospital-acquired infection as well as improved psychosocial well-being of patients and their care-givers. On-going challenges include reducing time of delay, outpatient chemotherapy chair availability and transitioning to fully ambulatory chemotherapy infusion pumps.
Disclosures
No relevant conflicts of interest to declare.}
}
@article{ARGYRIADI2021365,
title = {Prognostic Relevance of Protocol Deviations in Children with Relapsed ALL Treated in the ALL-REZ BFM 2002 Trial},
journal = {Blood},
volume = {138},
pages = {365},
year = {2021},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2021-150467},
url = {https://www.sciencedirect.com/science/article/pii/S0006497121023612},
author = {Eleni Argyriadi and Ingo G. Steffen and Guenter Henze and Christiane Chen-Santel and Arend {von Stackelberg}},
abstract = { Introduction: Acute lymphoblastic leukemia (ALL) is the most common cancer affecting children and its cure rates are close to 90%. Nevertheless, relapsed ALL is still a major cause of cancer-associated deaths in children. Therefore, the multicenter trial Acute Lymphoblastic Leukemia-Relapse Study of the Berlin-Frankfurt-Münster Group (ALL-REZ BFM) 2002 was designed to improve the prognosis of children with relapsed ALL by introducing new chemotherapy elements. Little is known though about the prognostic relevance of deviations from the ALL protocols. This study aimed to investigate the characteristics of such protocol deviations and to determine their prognostic relevance for the relapsed disease. Methods: We performed a retrospective analysis of 686 children and adolescents up to 18 years of age with first relapse of ALL who were enrolled between 2002 and 2012 in the ALL-REZ BFM 2002 Study. Deviations were identified in terms of time and type. In order to investigate the prognostic importance of the time delay, the 90th percentile of delays between defined treatment elements (i.e. 15.5 days) was used as a cut-off point. Furthermore, deviations were categorized as avoidable (logistics, family/PI decisions) and non-avoidable (clear medical indication). The protocol deviation occurred during the course of therapy was therefore considered as a time-dependent variable. Disease-free survival, (DFS, induction failures excluded) and OS were analyzed using Kaplan-Meier estimate, log-rank test, Mantel-Byar test and Cox/logistic regression (univariate and multivariate analyses). Results: A total of 587 patients (86%) received the protocol therapy, whereas 99 patients (14%) underwent deviations during their treatment. Baseline characteristics were compared in both groups (Table 1). Deviations were categorized as: change of chemotherapy in 48% of the patients (n=47/99), stop of chemotherapy in 10 % (n=10/99), non-protocol compliant reaction to MRD findings in 28% (n=28/99) and change of radiation treatment in 14% (n=14/99). The cumulative incidence of protocol deviation was 6% and 15.5% at 3 and 9 months, respectively (Figure 1). The remission rate of patients with protocol deviation during induction was slightly lower compared to patients without such deviation (24/29, 83% vs. 579/657, 88%; P=0.38). The estimated 5-year probabilities of DFS and OS between the patients treated according to protocol therapy and those with deviations were significantly different (pDFS, Protocol therapy: 0.61 ± 0.02 vs. Deviation: 0.38 ± 0.05, P < 0.001; pOS, Protocol: 0.70 ± 0.02 vs. Deviation: 0.57 ± 0.05, P < 0.001; Figure 2, 3). In multivariate analyses protocol deviation, time point of relapse and immunophenotype turned out to be independent prognostic factors of the DFS (Table2). The hazard ratio of the protocol deviation was significant only in patients with the late relapse, whereas in patients with early/very early relapse no significant prognostic effect could be found [late (n=40): HR=2.53, 95%CI 1.53-4.21, P<0.001; early (n=29): HR=1.49, 95%CI 0.88-2.51, P=0.13; very early (n=25): HR=1.50, 95%CI 0.84-2.66, P=0.17]. Moreover, DFS probabilities were comparable for avoidable (n=63) and non-avoidable (n=31) deviations (0.43 ± 0.07 vs. 0.40 ± 0.09, P=0.9; Non avoidable: HR=1.19, 95%CI=0.68-2.10, P= 0.53). In terms of the time-related deviations, the extent of the delays between induction and beginning of consolidation therapy was not significantly associated with the DFS [≤90th percentile (n=319/603); pDFS: =0.60 ± 0.02 vs. >90th percentile (n=36/603); pDFS: 0.56 ± 0.08, P=0.3]. Treatment delays during other phases of the protocol were also not related to the outcome. Conclusion: While protocol deviations did not significantly affect remission rates in this study, they were significantly related to inferior DFS. Since a relevant part of the protocol deviations could be classified as avoidable, strict protocol compliance should lead to improved outcomes. The prognostic impact of protocol deviations was in particular relevant in patients with late relapse with generally rather chemosensitive diseases and better prognosis. In this analysis, treatment delays did not influence the outcome. Figure 1
Disclosures
von Stackelberg: Amgen: Consultancy, Honoraria; Novartis: Consultancy, Honoraria; Jazz: Consultancy, Honoraria; Miltenyi: Consultancy, Honoraria.}
}
@article{CHOKSHI2020S148,
title = {Pre-operative Pulmonary Function and Association with Left Ventricular Assist Devices Outcomes},
journal = {Journal of Cardiac Failure},
volume = {26},
number = {10, Supplement },
pages = {S148},
year = {2020},
note = {Abstracts From the Heart Failure Society of America's (HFSA) Annual Scientific Meeting 2020},
issn = {1071-9164},
doi = {https://doi.org/10.1016/j.cardfail.2020.09.426},
url = {https://www.sciencedirect.com/science/article/pii/S1071916420313737},
author = {Anuj K. Chokshi and Kambiz Ghafourian and Hector E. Cajigas and Rebecca Harap and Tingqing Wu and Faraz S. Ahmad and Ike S. Okwuosa and Anjan Tibrewala and Esther Vorovich and Jane Wilcox and Amit Pawale and Duc Thinh Pham and Jonathan D. Rich},
abstract = {Introduction
Comorbidities including pulmonary disease are common in patients undergoing LVAD implantation. The impact of pre-implant pulmonary function on post-implant LVAD outcomes has not been comprehensively explored. In this study, we examined the association between pre-implant pulmonary function on post-implant outcomes.
Methods
A retrospective review of 415 primary LVAD implants at our center between 2008 and 2019 identified 251 patients with pre-implant pulmonary function tests (PFT), of which 248 had pre-implant chest CT scans. PFT results were classified as obstructive or restrictive and were sub-stratified by severity. Chest CT scan findings were assessed for presence of fibrosis or emphysema. Our primary outcome was 1-year mortality. Secondary outcomes included reintubation, days on mechanical ventilation, post-operative pneumonia, ICU length of stay (LOS), hospital LOS and 30-day mortality. Continuous variables were evaluated using two-sample Student's t-test or Wilcoxon test. Categorical variables were evaluated using χ2 test or Fisher's exact test. The group comparison in outcomes were assessed using logistics regression and linear regression.
Results
PFTs and chest CT scans were completed at a median of 42 days (IQR 18-127 days) and 26 days (IQR 10-63 days), respectively, prior to LVAD implantation. 84 patients (35%) had obstructive lung disease (52% moderately severe or severe) and 132 patients (55%) had restrictive lung disease (23% moderately severe or severe). Lung diffusing capacity for carbon monoxide (DLCO) was normal in 23% of patients and reduced in others by mild (29%), moderate (41%) or severe (7%) degrees. Presence or severity of either obstructive or restrictive lung disease on PFTs were not associated with primary or secondary outcomes. Severe reduction in DLCO and presence of fibrosis on chest CT scan were both strongly predictive of mortality at 30 days (OR 10.0, CI 1.52-65.63, p<0.01 and, OR 6.96, CI 1.53-31.64, p=0.01) and at 1-year (OR 6.10, CI 1.11-33.57, p= 0.01 and, OR 4.32, CI 1.78-15.85, p=0.03) after LVAD implantation. Reduction in DLCO or CT scan findings were not otherwise associated with secondary outcomes.
Conclusions
Pulmonary disease is common in patients undergoing LVAD implantation. The presence and severity of obstructive or restrictive lung disease on pre-implant PFTs were not predictive of post LVAD outcomes. However, a severe reduction of DLCO and pulmonary fibrosis on pre-implant chest CT scan were associated with 30-day and 1-year mortality.}
}
@article{MUQUITH20214015,
title = {Evaluating the Impact of Therapy Related Healthcare Team Burden on Selection of Novel Therapies for Chronic Lymphocytic Leukemia and Lymphoid Malignancies},
journal = {Blood},
volume = {138},
pages = {4015},
year = {2021},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2021-154058},
url = {https://www.sciencedirect.com/science/article/pii/S0006497121059292},
author = {Maishara Muquith and Heather Reves and Gurbakhash Kaur and Yazan F. Madanat and Praveen {Ramakrishnan Geethakumari} and Ankit Kansagra and Prapti Patel and Larry D. Anderson and Madhuri Vusirikala and Robert H. Collins and Farrukh T. Awan},
abstract = {Introduction Multiple factors drive specific therapy selection for patients with hematologic malignancies including efficacy, toxicity, patient and physician preferences, comorbid conditions, cost, and logistics. However, the advent of many highly effective and generally well-tolerated targeted therapies for chronic lymphocytic leukemia (CLL) and lymphoid malignancies makes objective distinction between various therapeutic agents more difficult. As a result, the eventual therapy selection is often based on physician preference. Secure electronic communication portals (ECP) are federally mandated and frequently used in health care. Although important, ECPs impose a significant burden on the entire healthcare team. However, the extent of ECP use on healthcare burden is poorly ascertained particularly in hematology. While limited available data suggests that cancer patients are more likely than urology or family medicine patients to use ECP, healthcare utilization studies have historically not included this metric as a measure of therapy-related healthcare team burden (THTB). Our study not only uniquely evaluates the quantitative impact of ECP use on THTB, it also addresses qualitative domains that are used in ECPs to provide a holistic and granular assessment of THTB. Methods Patient and ECP data were retrospectively collected at a comprehensive cancer center after institutional IRB approval. The dataset included 412 patients with CLL and lymphoid malignancies treated with ibrutinib (n=237), acalabrutinib (n=70), and venetoclax (n=105). A subset of these patients with AML treated with venetoclax were also included to address disease and therapy specific issues. By leveraging common taxonomy from published literature, we created multiple domains specific to the evaluable metrics as detailed in the tables and utilized the Naranjo adverse drug reaction probability scale and provider documentation to code each message. Results Patients who had at least one patient-initiated or clinician-initiated ECP message thread were included in the final analysis (n=95, 23.06%). Table 1 shows patient, treatment, and disease characteristics. Ibrutinib was used mostly as initial or second-line therapy, while acalabrutinib and venetoclax were mostly used for later lines. We coded 3338 message threads, comprising 3272 patient-generated messages, and 2050 messages generated by 354 unique clinical staff. Our sampled population generated an average of 25.83 messages per patient and our healthcare clinical staff generated an average of 17.96 messages. Table 2 contains domain specific ECP interactions. Patient and healthcare team-generated messages were highest in the first six months of starting therapy and varied with treatment (p<0.01). Venetoclax use was associated with the highest frequency of interactions during the first 6 months of starting therapy. Both treatment-related and unrelated adverse events domains, as well as administrative and supportive care domains, as coded from the ECP, were highest in patients with CLL treated with venetoclax (p=0.005). This was similar for patients with AML treated with venetoclax (p=0.07), suggesting a drug effect rather than the disease process. Patients on venetoclax were also more likely to discuss supportive care and scheduling issues. Adverse event domain specific qualitative measures included comments like “have a scalloped tongue and metallic taste since starting acalabrutinib”, “diarrhea, nausea, and vomiting persists since starting the ibrutinib”, and “watery diarrhea persists despite the loperamide since starting the venetoclax”. Conclusion Our study highlights an important but poorly described measure of THTB that can significantly impact therapy selection, especially when multiple therapeutic options with comparable outcomes are available. A non-reimbursed increase in ECP utilization poses significant THTB which is not easily offset by increased staffing efforts and might result in under-utilization of potentially effective therapies, especially in resource limited settings. In addition, our domain-specific appraisal of ECP allows for identification for improvements in healthcare delivery and intervention with structured enhancements that can maximize patient-centered care while decreasing THTB. THTB should therefore include ECP use and be evaluated as part of a comprehensive assessment tool. Figure 1
Disclosures
Madanat: Geron Pharmaceutical: Consultancy; Blue Print Pharmaceutical: Honoraria; Stem line pharmaceutical: Honoraria; Onc Live: Honoraria. Patel: PVI: Honoraria; Celgene-BMS: Membership on an entity's Board of Directors or advisory committees; Agios: Membership on an entity's Board of Directors or advisory committees. Anderson: Celgene, BMS, Janssen, GSK, Karyopharm, Oncopeptides, Amgen: Consultancy, Honoraria, Membership on an entity's Board of Directors or advisory committees, Research Funding. Awan: Beigene: Consultancy; Incyte: Consultancy; Celgene: Consultancy; Karyopharm: Consultancy; Kite pharma: Consultancy; Dava Oncology: Consultancy; Johnson and Johnson: Consultancy; Verastem: Consultancy; MEI Pharma: Consultancy; Gilead sciences: Consultancy; Pharmacyclics: Consultancy; Janssen: Consultancy; BMS: Consultancy; Cardinal Health: Consultancy; Merck: Consultancy; ADCT therapeutics: Consultancy; Abbvie: Consultancy; Astrazeneca: Consultancy; Genentech: Consultancy.}
}
@incollection{BRUNO2019734,
title = {63 - Palliation of Malignant Pancreaticobiliary Obstruction},
editor = {Vinay Chandrasekhara and B. Joseph Elmunzer and Mouen A. Khashab and V. Raman Muthusamy},
booktitle = {Clinical Gastrointestinal Endoscopy (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Philadelphia},
pages = {734-747.e4},
year = {2019},
isbn = {978-0-323-41509-5},
doi = {https://doi.org/10.1016/B978-0-323-41509-5.00063-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323415095000633},
author = {Marco J. Bruno and Fauze Maluf-Filho},
keywords = {pancreatic cancer, palliation, biliary stenting, duodenal stenting, jaundice},
abstract = {Pancreaticobiliary malignancies include, but are not limited to, pancreatic cancer, carcinoma of the ampulla of Vater, duodenal carcinoma, gallbladder carcinoma, and cholangiocarcinomas. The overall prognosis of these tumors is dismal. At the time of presentation, more than 80% of patients have local unresectable disease or distant metastases. Chemotherapy and radiotherapy have limited effect on survival, although various multimodality schemes in a (neo)adjuvant setting to surgery are currently being explored. It is recognized that more than 85% of patients with pancreaticobiliary malignancies develop obstructive jaundice, and often it is a presenting symptom. Many of them will need optimal palliative treatment directed toward relief of jaundice, pain, and gastric outlet obstruction. Endoscopic retrograde cholangiopancreatography (ERCP) with placement of plastic or metal biliary stents has become the standard of care to relieve jaundice. Plastic stents insertion is usually reserved for patients with expected survival time limited to 3–4 months. Another indication for the use of plastic stents is the uncertainty of the malignant diagnosis, although the use of fully covered metal stents has been increasingly advocated for this situation. There is robust evidence on the superiority of metal stents over plastic ones with regard to long-term patency rate. There is a trend to give preference to fully and partially covered metal stents over uncovered ones, even considering a possible discrete increase in some adverse event rates such as migration and acute cholecystitis. Endoscopic biliary drainage of malignant hilar obstruction should aim for draining greater than 50% of liver parenchyma and every manipulated liver segment. Finally, in case of ERCP failure, endoscopic ultrasound (EUS)–guided biliary drainage has emerged as a valid option to percutaneous drainage. Local expertise, logistics, and cost issues should be taken into consideration in the planning of the therapeutic algorithm in case of ERCP failure.}
}
@incollection{SHARMA2020323,
title = {Chapter 13 - Cryptocurrency Mechanisms for Blockchains: Models, Characteristics, Challenges, and Applications},
editor = {Saravanan Krishnan and Valentina E. Balas and E. Golden Julie and Y. Harold Robinson and S. Balaji and Raghvendra Kumar},
booktitle = {Handbook of Research on Blockchain Technology},
publisher = {Academic Press},
pages = {323-348},
year = {2020},
isbn = {978-0-12-819816-2},
doi = {https://doi.org/10.1016/B978-0-12-819816-2.00013-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198162000137},
author = {Deepak Kumar Sharma and Shrid Pant and Mehul Sharma and Shikha Brahmachari},
keywords = {Cryptocurrency, blockchain, consensus, cryptography, transactions, tangle, hedera hashgraph, bitcoin},
abstract = {In recent years, blockchains have drawn considerable attention from engineers, researchers, and institutions alike; and their implementation has affected fields like e-healthcare, Internet of Things, smart contracts, e-finance, logistics, and so forth. The focus of this chapter shall be the cryptocurrency mechanisms for blockchains. Cryptocurrencies are a new form of virtual currency, first introduced to the masses with the creation of bitcoin, developed by Satoshi Nakamoto. They are a more secure and verified form of transaction, which uses cryptographic protocols in a peer-to-peer system generating a distributed ledger. With the growing popularity of blockchains, a large number of cryptocurrencies have been introduced, greatly changing the prospects of blockchains in the domain of finance. Greater attention is now being paid by stakeholders around the world to various mechanisms of using blockchains in cryptocurrencies. In these blockchain systems, all the committed transactions are stored in a list of blocks with several transactional properties including irreversibility, pseudonymous, security, and global scalability. As both permission and permissionless blockchain platforms are being challenged to meet rigorous real-world application requirements, such as immediate transaction finality, low latencies, good scalability, and high-performance, the limitations of existing consensus models are being recognized. To achieve the necessary agreement in a network among distributed processes, consensus mechanisms are used as fault-tolerant mechanisms in blockchains systems. Many consensus models have been designed and new ones are still emerging to combat the limitations of their predecessors. Models like Proof-of-Work, Proof-of-Stake, Proof-of-Elapsed Time, and many others that follow open-ended or closed-ended participation have their own advantages and limitations. The consensus mechanism maintains the sanctity of the data and the key properties of the blockchain; the security of the consensus model is perhaps an important measure of the quality of the model. Poor choice of consensus mechanism could lead to blockchain fork, consensus failure, dominance, and poor performance thereby compromising the data recorded on the blockchain. Despite all these challenges, blockchains show immense potential in improving cryptocurrency by bringing numerous opportunities. This chapter provides a primer on the basics of cryptocurrencies using blockchain technology and discusses the existing narratives about the technology’s potential to facilitate efficient mechanisms for financial transactions among others. The principal disciples of the technology are discussed in great detail while also flagging the potential points of concern and conflict surrounding the technology. It concludes with suggestions for future research.}
}
@article{FOLWARSKI2021111202,
title = {Organizational issues of home parenteral nutrition during COVID-19 pandemic: Results from multicenter, nationwide study},
journal = {Nutrition},
volume = {86},
pages = {111202},
year = {2021},
issn = {0899-9007},
doi = {https://doi.org/10.1016/j.nut.2021.111202},
url = {https://www.sciencedirect.com/science/article/pii/S0899900721000642},
author = {Marcin Folwarski and Stanisław Kłęk and Przemysław Matras and Lidia Bartoszewska and Sławomir Bednarz and Marlena Jakubczyk and Zbigniew Kamocki and Grzegorz Krasowski and Marek Kunecki and Bogna Kwella and Katarzyna Matysiak-Luśnia and Konrad Matysiak and Gabriela Pierzynowska and Waldemar Szafrański and Jacek Szopiński and Krystyna Urbanowicz and Jacek Sobocki},
keywords = {Home parenteral nutrition, Home enteral nutrition, COVID-19, Pandemic, Health care workers, Human resources},
abstract = {Objectives
Patients on home parenteral nutrition (HPN) are prone to severe complications of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. The pandemic requires adaptation of the health care standards, including epidemiologic surveillance, logistics of home supply, and monitoring. Potential lack of medical professionals may worsen the standard of care. The aim of this study was to evaluate the medical staff resources in HPN units.
Results
The study was conducted by major Polish scientific societies in clinical nutrition. A questionnaire was distributed among all Polish adult HPN centers concerning statistics from the first 3 mo of the pandemic (March through May 2020). Data on medical staff resources and organizational issues of the units were collected. Modifications of the home procedures, SARS-CoV-2 infection rates of HPN patients and health care workers (HCW) were analyzed. Influence of the pandemic on the rates of new qualifications for home artificial nutrition (HAN) was estimated. Fourteen of 17 adult Polish HPN units took part in the study. The point prevalence of HPN in Poland was 30.75/1 million citizens. Of HCWs, 344 were involved in patient care in Polish HPN units; 18.9% were physicians (49% surgeons, 18.46% internal medicine specialists, 15.38% anesthesiologists, 7.69% pediatricians, 1.54% palliative care specialists), 32.27% nurses, 5.23% dietitians, 9.01% pharmacists, 4.94% pharmacy technicians, 3.2% pharmacy assistants, 5.81% administrative workers, 3.49% physiotherapists. HAN patient-to-HCW ratios for physicians, nurses, pharmacists, dietitians were 49.5, 29.15, 111.6, and 181.6, respectively. Medium ages of physicians and nurses were 45.6 and 44.15 y, respectively. Slightly less than half (53.8%) of physicians and 31.53% of nurses worked parallelly in hospital wards. Thirty-one pharmacists overall were working in all HPN units (2.21 per unit) as were 18 dietitians (1.3 per unit). Nine patients had a confirmed COVID-19 infection (four HPN, five home enteral nutrition). All the units introduced telemedicine solutions in the first months of the pandemic. The number of new qualifications for HPN and home enteral nutrition in the units did not significantly decline from March through May in comparison with a similar period in 2019.
Conclusions
A shortage of HPN medical professionals requires attention when planning health care organization, especially during a pandemic. Severe restrictions in public health systems may not reduce the number of new qualifications for the HPN procedure. There is a need for the continuation of data collection during the evolution of the pandemic as it may have a detrimental effect on HPN including serious issues with access to professional HCWs.}
}
@article{LI2021128269,
title = {Healing characterisations of waste-derived bitumen based on crack length: Laboratory and modelling},
journal = {Journal of Cleaner Production},
volume = {316},
pages = {128269},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128269},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621024847},
author = {Linglin Li and Yang Yang and Yangming Gao and Yuqing Zhang},
keywords = {Waste-derived bitumen, Ageing, Healing, Plastics},
abstract = {The accumulations of waste plastics and municipal solid wastes from the resident groups and industrial companies have been causing serious environmental issues in the UK, due to difficulties in logistics, sorting, and reuse. In this sense, this paper is stimulated to develop novel approaches to convert some wastes into eco-friendly infrastructural materials, which provides a new way of waste reduction and reuse and extending the service life of asphalt pavement. This study aims to characterise the healing performance of waste-derived bitumen before and after pressure ageing vessel (PAV) ageing based on the crack length. One waste-derived bitumen was fabricated by blending the bio-oil pyrolysed from the organic fraction of municipal solid waste (5 wt%) with a control bitumen (X70) using a high shear mixer at a speed of 150 revolutions per minute (RPM) for 30 min at 150 °C under nitrogen atmosphere. A second waste-derived bitumen was fabricated using the low-density polyethene (LDPE) and mixed with the control bitumen at a concentration of 6 wt% at a speed of 900RPM for 90 min at 180 °C under nitrogen atmosphere. Crack length-based healing index and Ramberg-Osgood model were employed to characterise the healing rate and healing capability of the bitumen, respectively. Material properties (e.g., relaxation modulus and surface energy) of the bitumen used in the healing models were calibrated by linear amplitude sweep test (10 Hz and 20 °C), frequency sweep test (10 Hz, 10–70 °C), and time sweep fatigue-healing test (10 Hz and 20 °C) at a controlled strain level of 5% with different rest durations. Advancing contact angles used in the healing models of the bitumen were measured by a sessile drop tensiometer based on the tilting cradle method. Results show that the bio-oil productively promotes the healing potential and capability of the unaged bitumen, and the LDPE slightly strengthens them. The PAV ageing process evaporates most of the modifier bio-oil; hence, the PAV-aged bio-oil modified bitumen does not show better healing performance than that of the PAV-aged control bitumen. The PAV-aged LDPE modified bitumen has much better healing performance than those of the PAV-aged control bitumen and the PAV-aged bio-oil modified bitumen. The short-term healing rate and healing potential dominate the healing behaviours of the bitumen. The unaged bio-oil modified bitumen heals the fastest (having the highest short-term healing rate) and most (having the highest healing potential), followed by the unaged LDPE modified bitumen, and the unaged control bitumen heals the least and slowest. The PAV-aged LDPE modified bitumen heals the fastest and most, followed by the PAV-aged bio-oil modified bitumen and the PAV-aged control bitumen. The fundamental reason for LDPE's enhancement to bitumen's healing is that the LDPE increased the deformation recovery ability of the bitumen, leading to a higher wetting rate of the cracked surfaces and thus a higher short-term healing rate. However, the LDPE in bitumen cannot accelerate the molecular diffusion to increase the intrinsic healing or the long-term healing rate.}
}
@article{LYNCH20193526,
title = {Mitapivat (AG-348) in Adults with Pyruvate Kinase Deficiency Who Are Regularly Transfused: A Phase 3, Open-Label, Multicenter, Study (ACTIVATE-T) in Progress},
journal = {Blood},
volume = {134},
pages = {3526},
year = {2019},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2019-123107},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118614545},
author = {Megan Lynch and Lei Hua and Chris Mix and John B. Porter},
abstract = {Background: Pyruvate kinase (PK) deficiency is an under-recognized hereditary disease that causes lifelong hemolytic anemia. Mutations in the PKLR gene lead to reduced red cell PK (PK-R) enzyme activity, resulting in defective glycolysis and decreased lifespan of red blood cells. Mitapivat (AG-348) is a novel, first-in-class, oral, small-molecule allosteric activator of PK-R under clinical testing as the first targeted, disease-altering therapy for PK deficiency. In the DRIVE PK study (NCT02476916; a phase 2, open-label, dose-ranging trial in adults with PK deficiency who are not regularly transfused), twice-daily (BID) dosing with mitapivat for >6 months was well tolerated and induced rapid, durable responses (Grace et al. ASH 2017). As of July 14, 2017, 26 (50%) of 52 enrolled subjects had a maximum hemoglobin (Hb) increase of >1 g/dL. Among these 26 subjects, the mean maximum Hb increase was 3.4 g/dL, and 25 (96%) had ≥1 missense PKLR mutation. Based on these findings, mitapivat has entered phase 3 clinical development. The design of the ongoing phase 3 ACTIVATE-T study and its extension study are reported here, with an update on country/site activation and key early learnings on trial logistics in PK deficiency. Methods: ACTIVATE-T is a global, multicenter, open-label study (NCT03559699) to evaluate the efficacy and safety of mitapivat in regularly transfused adults with PK deficiency. Regularly transfused is defined as ≥6 transfusion episodes in the previous year. Subjects who are homozygous for the R479H mutation or have 2 non-missense mutations (without the presence of another missense mutation) in PKLR will be excluded, as will subjects with an average transfusion frequency of more than once every 3 weeks in the previous year. The study comprises an 8-week screening period, during which each subject's complete transfusion history from the prior 52 weeks is documented, followed by a 16-week dose optimization period and a 24-week fixed-dose period (Figure). During the dose optimization period, each subject will undergo individualized mitapivat dose optimization. All subjects will start on a dose of 5 mg BID, which may be increased twice over the course of 16 weeks (from 5 to 20 mg BID and from 20 to 50 mg BID). In the fixed-dose period, each subject will receive mitapivat at their optimized dose for 24 weeks. During the study, subjects will be transfused when their Hb reaches or falls below their individual transfusion trigger calculated from their transfusion history. The primary endpoint is the proportion of subjects who achieve a reduction in transfusion burden, defined as a reduction of ≥33% in the number of red blood cell units transfused during the 24 weeks of the fixed-dose period compared with the historical transfusion burden standardized to 24 weeks. Secondary endpoints include safety. All subjects who complete the study will have the opportunity to enroll in an open-label extension study (NCT03853798) in which all participants will receive mitapivat for up to 192 weeks. The ACTIVATE-T trial is enrolling globally. 
Disclosures
Lynch: Agios: Employment, Equity Ownership. Hua: Agios Pharmaceuticals, Inc.: Employment, Equity Ownership. Mix: Agios: Employment, Equity Ownership. Porter: Bluebird bio: Consultancy, Honoraria; Silence therapeutics: Honoraria; Vifor: Honoraria; La Jolla: Honoraria; Protagonism: Honoraria; Celgene: Consultancy, Honoraria; Agios: Consultancy, Honoraria.}
}
@article{GOMEZMESA20193,
title = {Consenso colombiano de falla cardíaca avanzada: capítulo de Falla Cardíaca, Trasplante Cardíaco e Hipertensión Pulmonar de la Sociedad Colombiana de Cardiología y Cirugía Cardiovascular},
journal = {Revista Colombiana de Cardiología},
volume = {26},
pages = {3-24},
year = {2019},
note = {Consenso colombiano de falla cardíaca avanzada},
issn = {0120-5633},
doi = {https://doi.org/10.1016/j.rccar.2019.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S012056331930110X},
author = {Juan Esteban Gómez-Mesa and Clara Saldarriaga and Adriana Milena Jurado and Alejandro Mariño and Alex Rivera and Álvaro Herrera and Andrés Felipe Buitrago and Ángel Alberto García and Antonio Figueredo and Edilma Lucy Rivera and Eduardo Contreras and Efraín Gómez and Erika María Martínez and Fernan Mendoza and Gina González-Robledo and Héctor Ventura and John Alexander Ramírez and José R. {González Juanatey} and Juan Carlos Ortega and Leonardo Salazar and Manuel Gómez Bueno and María Juliana Rodríguez and Marisa Crespo Leiro and Nicolás Manito and Nubia Lucía Roa and Luis Eduardo Echeverría},
keywords = {Avanzada, Tratamiento, Clínicas, Inotrópicos, Trasplante, Paliativo, Enfermería, Advanced, Treatments, Clinics, Inotropes, Transplant, Palliative, Nursing},
abstract = {Resumen
La definición más actualizada de falla cardiaca avanzada incluye síntomas refractarios al tratamiento convencional, independiente de la fracción de eyección del ventrículo izquierdo, acompañados de elevación de péptidos natriuréticos. En esta nueva definición se destacan condiciones específicas como son la necesidad usual de diurético intravenoso, hospitalizaciones o consultas frecuentes por falla cardíaca, medicación inotrópica intermitente y arritmias malignas recurrentes. Esta condición está presente en aproximadamente 4 a 6% de los pacientes con falla cardiaca y se asocia a más síntomas, más comorbilidades y mayor mortalidad (hasta 75% a un año). En este punto, las terapias convencionales han fallado o son refractarias y se requiere la toma de decisiones para instaurar tratamientos más avanzados (p. ej.: inotrópicos, asistencia ventricular, trasplante cardiaco, cuidado paliativo, entre otras). El tratamiento representa un reto para los sistemas de salud de Colombia por la necesidad de optimizar y racionalizar el uso de estos recursos; por esto se debe considerar que estos pacientes, en algún momento de su evolución, que sean remitidos para valoración en las Clínicas de Falla Cardíaca ya que estos servicios cuentan con personal altamente calificado y una estructura administrativa, logística y tecnológica que garantizan el acceso a un tratamiento integral y multidisciplinario con estándares de calidad internacionales que es lo que finalmente se requiere en estas condiciones. En el “Consenso colombiano de falla cardiaca avanzada” se presentan diferentes opciones de tratamiento a considerar y un modelo de atención integral que inicia desde el momento del diagnóstico hasta etapas refractarias y avanzadas.
The most up-to-date definition of advanced heart failure includes symptoms refractory to conventional treatment (regardless of the left ventricular ejection fraction), accompanied by an elevation in natriuretic peptides. Specific conditions are highlighted in this new definition, such as the usual need of an intravenous diuretic, hospital admissions, or frequent consultations due to heart failure, intermittent inotropic medication, and recurrent malignant arrhythmias. This condition is present in approximately 4 to 6% of patients with heart failure and is associated with more symptoms, more comorbidities, and higher mortality (up to 75% at one year). On this point, the conventional treatments have failed, or are refractory, and decisions need to be taken to introduce more advanced treatments (for example: inotropic, ventricular assistance, palliative care, among others). The treatment represents a challenge for the Health Systems of Colombia due to the need to optimise and rationalise the use of these resources. For this reason, it must be considered that these patients, at any time during its course, may be sent for assessment in Heart Failure Clinics, as these services have highly qualified staff and an administrative, logistics, and technological structure that ensures access to an integral and multidisciplinary treatment with standards of international quality, which is what is finally required in these conditions. Different treatment options to consider are presented in the “Colombian consensus on advanced heart failure”, as well as an integral care model that begins from the time of the diagnosis until the refractory and advanced stages.}
}
@article{SHULGA20207185,
title = {The Arctic: Ecology and hydrogen energy},
journal = {International Journal of Hydrogen Energy},
volume = {45},
number = {11},
pages = {7185-7198},
year = {2020},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2019.12.122},
url = {https://www.sciencedirect.com/science/article/pii/S0360319919346580},
author = {R.N. Shulga and A.Y. Petrov and I.V. Putilova},
keywords = {Hydrogen, The Arctic, Ecology, Hydrogen energy supply, Direct current, Electricity storage},
abstract = {Hydrogen fuel cells being hydrogen energy storage devices are the most effective and environmentally friendly for energy accumulation and storage. Direct current provides the accumulation of electric energy and is therefore necessary when using renewable energy sources. The social and environmental aspects, as well as climatic and glaciological features of the Arctic development in terms of energy supply are considered. The most expedient ways of complex development of the Arctic are shown. In terms of large and unique stationary projects a number of shortcomings is marked. They are high cost and long-term construction, incomplete autonomy and insufficient solution of ecological and waste processing problems. Incomplete autonomy is due to the need for transportation of materials, products, replacement crews and personnel, as well as insufficient logistics and transportation difficulties on the mainland in summer and by sea in winter. Ecological and waste processing problems are associated with the use of traditional methods of burning solid and liquid fuel using coal or fuel oil, polluting the environment. Switching to the liquefied natural gas (LNG) for electric propulsion and power supply will significantly improve the environmental situation. The research performed on the mathematical model of the multifunctional energy complex (MEC) showed the possibility of uninterrupted power supply of local load from the centralized network, diesel generator (DG) and the electricity storage (ES); by that DG is used to save fuel as a backup source. The proposed technologies of power generation based on hydrogen or low-power nuclear power plants (LPNPPs) allow, along with improving the environment, to increase the energy efficiency of the direct fuel conversion plant and provide integrated waste processing. The small population of the Arctic, its mobility when using the rotational method require the integrated development of mobile energy and life support systems of low power up to 30 MW using LNG or LPNPPs, completed by renewable energy sources (RES). If the hydrogen installation is both a source and a storage of electricity, the use of LPNPPs and especially RES require energy storage devices. These hydrogen or electrochemical cycle storage devices are the most progressive in the world energy sector and their applicability significantly depends on the development of the service infrastructure. Typing and replication of power supply sources will solve the problem of development of remote and isolated regions of the Arctic through the integrated use of innovative technologies for generation, storage, transmission and distribution of electricity, life support, utilization and recycling of wastes, environmental conservation using hydrogen energy and digital control and monitoring systems. The climatic conditions of the Arctic and the presence of LNG determine the use of hydrogen as a source for generating electricity, heat, water and air.}
}
@article{FRANK2020434,
title = {The Experiences of Persons Living with Dementia Planning for a Dementia Research Meeting. Lessons Learned From the National Research Summit on Care, Services, and Supports for Persons With Dementia and Their Caregivers},
journal = {The American Journal of Geriatric Psychiatry},
volume = {28},
number = {4},
pages = {434-442},
year = {2020},
issn = {1064-7481},
doi = {https://doi.org/10.1016/j.jagp.2019.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S1064748119305500},
author = {Lori Frank and Emily Shubeck and Melanie Schicker and Teresa Webb and Katie Maslow and Laura Gitlin and Cynthia Huling Hummel and Edward K. Kaplan and Brian LeBlanc and Myriam Marquez and Brenda P. Nicholson and Greg O'Brien and Louise Phillips and Brian {Van Buren} and Gary Epstein-Lubow},
keywords = {Dementia, patient engagement, participatory research, patient-centered research},
abstract = {Objective
A stakeholder group for persons living with dementia (PLWD) was convened to support the work of a major US dementia research meeting. The objectives of this examination are to present the steps used to implement the Group and guidance for both PLWD and researchers for partnering on research conference planning and participation.
Methods
PLWD met monthly to provide input into the agenda for the 2017 Research Summit on Dementia Care and some Group members also presented at the Summit. Following the Summit, the Group reviewed their contributions and completed an evaluation of the Group process, identifying best practices to support future efforts.
Results
Group members were initially unsure about participating due to concerns about ability to contribute and concerns about disease progression. Members reported that participation was a positive experience, however, identifying Group-led governance and attention to Group work process as important contributors. In addition to giving input to the Summit and having the opportunity to interact with researchers, sharing personal experiences with each other was part of the value of the Group to members. Careful Group selection and attention to governance were among the Best Practices members.
Conclusion
Despite initial uncertainty among members about participating as a Stakeholder Group to inform a national research meeting, members developed a successful process for governance, convening, and providing input to a major national research meeting. Group's self-evaluation yielded specific strategies likely to be useful in formation and implementation of future partnerships between researchers and persons living with dementia.}
}
@article{XIMENES201961,
title = {LEAP2 and LCATS industry clusters: A framework for lunar site technology development using global, space-STEM education and global space-industry development networks},
journal = {Acta Astronautica},
volume = {157},
pages = {61-72},
year = {2019},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2018.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0094576518302911},
author = {Samuel W. Ximenes and SherylLynn Roberts and Tai Sik Lee and Hyu-Soung Shin and Bernard Foing and Carlos Duarte},
keywords = {STEM education, Space economics, Lunar exploration, Space technology, Space industry clusters},
abstract = {Industry clusters, considered the building blocks of modern economies, are an economic concept used to identify and define the geospatial density, growth and network behavior associated with innovation and economic performance. Our program proposes use of cluster analysis related to space-STEM education and space-industry to identify aerospace system-sector industry clusters and factors on a global scale related to lunar site technology development. The goal is to document and encourage space-industry cluster network development, facilitating space-STEM workforce and economic development for communities, based on technologies relevant to particular community areas of interest and aerospace resources. Using a wheel model of unique industrial system-sectors needed for lunar site technology development, analyses and documentation of clusters and factors can assist potential system-sector collaborators in commercial exploration architecture development to cluster network participation and design of space-STEM development. At present, system-sector components for lunar exploration architectures include: satellite communications (Mexico), mission operations (Germany), ISRU and vacuum chamber test environment (Korea), and lunar ecosystem and architectural prototype development (United States). Development of these initial system-sectors are underway through the LCATS and LEAP2 global space-STEM education network project, “Lunar Caves Analog Test Sites (LCATS) for Space-STEM Learning Performance”, featuring a Lunar Ecosystem and Architectural Prototype (LEAP2). To expand the LCATS and LEAP2 initiative, the project seeks to identify, map, and analyze potential collaborating corporate and industry players representing other system-sector components needed for lunar site development from the perspective of evolving a global space-STEM education network beneficial to the local community of the collaborating organization relevant to their expertise in system-sector component development. Additional cluster expertise sought includes mining and energy generation; food and waste processing; water production for fuels; vehicles and equipment systems, and logistics, to name a few. Replication of an LCATS three to four year education and career development program, using actual lunar site technology development is intended to give international student participants the ability to learn about and build a cluster specialization with lunar site outcomes.}
}
@article{RIAZ2020e03950,
title = {Community clinics in Bangladesh: A unique example of public-private partnership},
journal = {Heliyon},
volume = {6},
number = {5},
pages = {e03950},
year = {2020},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2020.e03950},
url = {https://www.sciencedirect.com/science/article/pii/S2405844020307957},
author = {Baizid Khoorshid Riaz and Liaquat Ali and Sk. Akhtar Ahmad and Md. Ziaul Islam and Kazi Rumana Ahmed and Sharmin Hossain},
keywords = {Quality of life, Epidemiology, Pregnancy, Reproductive system, Health education, Inequality, Community clinics, Community participation, Health service delivery, Health service utilization, User satisfaction, Public private partnership},
abstract = {Background
Bangladesh has established more than 13,000 community clinics (CCs) to provide primary healthcare with a plan of each covering a population of around 6,000. The inception of CCs in the country has revolutionized the healthcare delivery to reach the doorstep of people. The provision of healthcare through CCs is truly participatory since the community people donate land for building infrastructure and also involve in management process. The study was conducted to assess pattern of public private partnership in healthcare delivery through participation of community people in establishment, management, monitoring and utilization of community clinics.
Methods
This quantitative study involving descriptive cross sectional design included 63 healthcare providers, 2,238 service-users and 3,285 community people as household members. Data were collected by face-to-face interview and reviewing records of CCs with the help of semi-structured questionnaire and checklist respectively. The public private partnership was assessed in this particular study by finding community participation in different activities of CCs. Data were analysed using descriptive statistics.
Results
Almost all (96.9%) CCs are located in easy-to-reach areas and have good infrastructure. Lands of all CCs are donated by the respective communities. The security of most of the CCs (93.7%) is maintained by community people. Cleanliness of the CCs is maintained by the cleaners or ayas who are appointed by local communities. Community Groups (CGs) of 88.9% and Community Support Groups (CSGs) of 96.8% CCs are found to be active. In most of the CCs (98.4%), monitoring is done by analysis of monthly reports. All CCs provide referral services for pregnant women. Health care delivery is found to be ‘good’ in more than three-fourths while health education service is ‘good’ in 96.7% of CCs. All CCs showed an increased trend in the utilization of services and conduction of normal child deliveries. Benefits of CCs as perceived by service users included free drugs (82.1%), free treatment (81.2%), easy access (76.3%), need-based health services (75.0%), and immunization services (68.6%). Almost all (99.0%) of the CC service users opined that CGs are involved in management of CC activities.
Conclusion
In resource-poor settings of developing countries, public private partnership in primary healthcare delivery through community clinics may play crucial role in sustainable development of community health by providing quality health care. The study recommends public-private partnership for strengthening CCs including establishment, maintenance, utilization, monitoring and supply of essential drugs and logistics.}
}
@article{HEARD2019189,
title = {Comparison of life cycle environmental impacts from meal kits and grocery store meals},
journal = {Resources, Conservation and Recycling},
volume = {147},
pages = {189-200},
year = {2019},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2019.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0921344919301703},
author = {Brent R. Heard and Mayur Bandekar and Benjamin Vassar and Shelie A. Miller},
keywords = {E-commerce, Food waste, Packaging, Supply chain management, Food retailing, Last-mile transportation},
abstract = {Meal kits contain ingredients for cooking a meal that are pre-portioned, packaged, and delivered to a consumer’s residence. Life cycle environmental impacts associated with climate change, acidification, eutrophication, land use, and water use are compared for five dinner recipes sourced as meal kits and through grocery store retailing. Inventory data are obtained from direct measurement of ingredients and packaging, supplemented with literature data for supply chain and production parameters. Results indicate that, on average, grocery meal greenhouse gas emissions are 33% higher than meal kits (8.1 kg CO2e/meal compared with 6.1 kg CO2e/meal kit). Other impact categories follow similar trends. A Monte Carlo analysis finds higher median emissions for grocery meals than meal kits for four out of five meals, occurring in 100% of model runs for two of five meals. Results suggest that meal kits’ streamlined and direct-to-consumer supply chains (−1.05 kg CO2e/meal), reduced food waste (−0.86 kg CO2e/meal), and lower last-mile transportation emissions (−0.45 kg CO2e/meal), appear to be sufficient to offset observed increases in packaging (0.17 kg CO2e/meal). Additionally, meal kit refrigeration packs present an average emissions decrease compared with retail refrigeration (−0.37 kg CO2e/meal). Meals with the largest environmental impact either contain red meat or are associated with large amounts of wasted food. The one meal kit with higher emissions is due to food mass differences rather than supply chain logistics. Meal kits are an evolving mode for food supply, and the environmental effects of potential changes to meal kit provision and grocery retailing are discussed.}
}
@article{DOURTHE2021S40,
title = {CAR T-cells in acute lymphoblastic leukemia: Current results},
journal = {Bulletin du Cancer},
volume = {108},
number = {10, Supplement },
pages = {S40-S54},
year = {2021},
note = {Cellules à récepteur antigénique chimérique (CAR-T) et Anticorps bispécifiques},
issn = {0007-4551},
doi = {https://doi.org/10.1016/j.bulcan.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007455121002836},
author = {Marie Emilie Dourthe and André Baruchel},
keywords = {Leucémie aiguë lymphoblastique, Immunothérapie, , Enfants, Acute lymphoblastic leukemia, Immunotherapy, CAR T-cells, Children},
abstract = {Summary
The marketing authorization of tisagenlecleucel, a 2nd generation of CD19-directed CAR T-cells, containing the 4-1 BB co-stimulatory domain, in 2017 in USA and in 2018 in EU, has revolutionized the therapeutic strategy in advanced B-cell acute lymphoblastic leukemia (B-ALL) in children, adolescents and young adults (AYAs) with relapsed or refractory disease. This innovative treatment, based on a “living drug”, has shown very impressive short-term responses. However, safety profile and complex logistics require high expertise centers and tight collaborations between addressing and treating centers. Current research is exploring the possibility to move to first line ALL with high-risk features and/or first high-risk relapse. More efficient CAR T-cells products, are still lacking to counteract the escape mechanisms already described. Moreover, to define the bridge-to-CAR time for each patient remains a challenge to obtain optimal disease burden allowing expansion and persistence of CAR T-cells. Also difficult is to identify patients who will benefit from further therapy after infusion, such as allogeneic HSCT or may be immuno-modulatory treatment. Finally, CAR T-cells directed against T-ALL are only in their beginning but require more complex engineering process to avoid T- cell immune-deficiency or fratricide.
Résumé
L’autorisation de mise sur le marché du tisagenlecleucel, CAR T-cells autologues de 2e génération, contenant le domaine de co-stimulation 4-1BB, en 2017 aux EU et en 2018 en Europe, a révolutionné la stratégie thérapeutique des phases avancées ou réfractaires des leucémies aigues lymphoblastiques B chez l’enfant, l’adolescent et le jeune adulte. Ce “médicament vivant” a effectivement montré des réponses à court terme impressionnantes. Cependant son profil de toxicité et sa logistique complexe nécessite des centres expérimentés et une collaboration étroite entre les centres. Les recherches en cours visent à évaluer les possibilités de traiter des maladies de haut risque en 1ère ligne et/ou les 1ères rechutes de haut risque. Gérer au mieux la période entre l’aphérèse et l’injection des CAR T-cells reste un défi pour obtenir une masse tumorale optimale permettant l’expansion et la persistance des CAR T-cells. On ne sait pas encore identifier les patients qui bénéficieront de thérapeutiques supplémentaires après l’injection des CAR T-cells, comme une allogreffe de cellules souches hématopoïétiques ou peut-être un traitement immuno-modulateur, ce qui nécessitera de nouvelles études cliniques. On espère l’arrivée de CAR-T cells plus efficaces pour contrer les mécanismes d’échappement déjà décrits. Enfin les CAR T-cells ciblant les LAL T sont aux prémices de leur développement mais exigent des procédés d’ingénierie complexe pour éviter une lutte fratricide entre cellules T et posent le problème potentiel d’un immuno-déficit T prolongé en cas de persistance.}
}
@article{PANI2019,
title = {Modelling non-response in establishment-based freight surveys: A sampling tool for statewide freight data collection in middle-income countries},
journal = {Transport Policy},
year = {2019},
issn = {0967-070X},
doi = {https://doi.org/10.1016/j.tranpol.2019.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0967070X1930472X},
author = {Agnivesh Pani and Prasanta K. Sahu},
keywords = {Freight surveys, Non-response, Responsive survey design, Sampling, K nearest neighbor},
abstract = {Non-response is unavoidable in any disaggregate-level survey efforts where information is sought from individuals. There is a strong need to understand the contributing factors of non-response behavior in freight surveys as there is very little information on what sort of establishments respond positively to survey inquiries. To meet this research gap, this paper analyzes the non-response behavior in an establishment-based freight survey (EBFS) conducted in Kerala, India. The analysis involves usage of five prominent classifiers: classification trees, random forests, Naïve Bayes classifier, logistic regression and K nearest neighbors. A closer look at the results revealed that the industrial classes handling commodities with high value density (machinery, electronics and electrical equipment, other manufacturing products, textiles) exhibit high non-response probability for freight surveys. This may be explained in terms of the limited logistic information shared by establishments handling high valued products due to less attention given to logistics strategies. Another reason could be that the amount of capital and opportunity costs tied up with these commodities are high, and therefore, their information tend to be more proprietary in nature. The analysis also reveals that the location of establishment plays a modest, yet, noticeable effect on non-response behavior. The establishments from cities located closer to Ports with high per-capita income are less likely to respond to survey requests, possibly due to the higher opportunity cost for time and increased concerns of intrusion into privacy. Finally, the comparison of ROC curves suggests that KNN algorithm is most suitable for modelling non-response behavior. These models are expected to be useful for developing sample weighting schemes and targeted incentive strategies that can improve the state of practice of freight data collection in middle-income countries like India. The study findings are expected to be useful for developing more elaborate and dynamically responsive survey designs for EBFS, in which sample recruitment strategies can be adapted real time during data collection. This study also informs policymakers that the apparent trends in non-response, if not arrested, are likely to weaken the validity of inferences drawn from estimates based on EBFS and undermine, perhaps fatally, the potential of EBFS to guide facility planning and policy interventions.}
}
@article{GILBEY2020S54,
title = {Time critical diagnosis and transfer of patients with acute type a aortic dissection in the United Kingdom – a need to define standards?},
journal = {Journal of Cardiothoracic and Vascular Anesthesia},
volume = {34},
pages = {S54-S55},
year = {2020},
note = {2020 EACTA Abstracts},
issn = {1053-0770},
doi = {https://doi.org/10.1053/j.jvca.2020.09.077},
url = {https://www.sciencedirect.com/science/article/pii/S1053077020309435},
author = {T. Gilbey and B. Milne and G. Kunst and J. Arrowsmith},
abstract = {Introduction
Type A aortic dissections are a surgical emergency, with roughly 2500 cases per year in England (1). About 20% of patients die before reaching a hospital and about 50% die before reaching a specialist centre, with reported delays in diagnoses in around 16 – 40% of cases (1). There is little knowledge about current logistics and practise by cardiac anaesthetic centres in the UK. We therefore conducted a survey, supported by the Association for Cardiothoracic Anaesthesia and Critical Care (ACTACC) network.
Methods
We sent a 17-question survey to 28 ACTACC link-persons in UK cardiac centres in February 2020. Data was collected and collated using the web-based survey platform “Survey Monkey” (Palo Alto, CA).
Results
The response rate was 68% (n=18). The majority of centres (73%, n=13) shared aortic dissection services with 1-3 other cardiac centres in their region. A majority of centres (n=13, 72%) reported that the maximum duration of ambulance transfer within their region was 90 minutes or less. In the remaining centres travel times were between 2-6 hours. A small majority of the respondents felt that there was often or always a delay in diagnoses and transfer of Type A aortic dissection patients to cardiothoracic centres (n=11, 61% and n=10, 56% respectively). Monitoring and blood pressure treatment of patients with acute Type A aortic dissections were only sometimes or rarely appropriate, as indicated by the majority of respondents with n=12 (67%) and n=15 (83%), respectively. The majority reported that escorting personnel was only sometimes or rarely experienced or trained (n=13, 72%). Half of the respondents assessed handover as often or always appropriate (n=9, 50%). The ideal destination at arrival for patients with acute Type A aortic dissections was the critical care unit in the majority (n=12, 67%) of centres, with 5 centres preferring theatre (28%). There was agreement from respondents that guidelines regarding the transfer of acute Type A aortic dissection patients would be beneficial.
Discussion
This survey of UK cardiac centres shows that the majority of centres already centralise treatment of Type A aortic dissection patients by sharing responsibilities. Furthermore, it reflects the observation by the majority of ACTACC link persons that there may be room for improvement of a timely diagnosis, transfer times, monitoring, and training and experience of escorting personnel. In the future a national prospective audit of acute Type A dissection cases in the UK will be necessary to further assess timely diagnoses and quality of transfer-related variables in individual patients with the view of elucidating how to potentially reduce the high incidence of pre-hospital deaths of patients with acute Type A aortic dissection. This survey was conducted before the COVID-19 pandemic. A future audit would help to assess NHS treatment of acute Type A aortic dissections after the pandemic peak.}
}
@article{PENEV201992,
title = {Economic analysis of a high-pressure urban pipeline concept (HyLine) for delivering hydrogen to retail fueling stations},
journal = {Transportation Research Part D: Transport and Environment},
volume = {77},
pages = {92-105},
year = {2019},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2019.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1361920918311982},
author = {Michael Penev and Jarett Zuboy and Chad Hunter},
abstract = {Reducing the cost of delivering hydrogen to fueling stations and dispensing it into fuel cell electric vehicles (FCEVs) is one critical element of efforts to increase the cost-competitiveness of FCEVs. Today, hydrogen is primarily delivered to stations by trucks. Pipeline delivery is much rarer: one urban U.S. station has been supplied with 800-psi hydrogen from an industrial hydrogen pipeline since 2011, and a German station on the edge of an industrial park has been supplied with 13,000-psi hydrogen from a pipeline since 2006. This article compares the economics of existing U.S. hydrogen delivery methods with the economics of a high-pressure, scalable, intra-city pipeline system referred to here as the “HyLine” system. In the HyLine system, hydrogen would be produced at urban industrial or commercial sites, compressed to 15,000 psi, stored at centralized facilities, delivered via high-pressure pipeline to retail stations, and dispensed directly into FCEVs. Our analysis of retail fueling station economics in Los Angeles suggests that, as FCEV demand for hydrogen in an area becomes sufficiently dense, pipeline hydrogen delivery gains an economic advantage over truck delivery. The HyLine approach would also enable cheaper dispensed hydrogen compared with lower-pressure pipeline delivery owing to economies of scale associated with integrated compression and storage. In the largest-scale fueling scenario analyzed (a network of 24 stations with capacities of 1500 kg/d each, and hydrogen produced via steam methane reforming), HyLine could potentially achieve a profited hydrogen cost of $5.3/kg, which is approximately equivalent to a gasoline cost of $2.7/gal (assuming FCEVs offer twice the fuel economy of internal combustion engine vehicles and vehicle cost is competitive). It is important to note that significant effort would be required to develop technical knowledge, codes, and standards that would enable a HyLine system to be viable. However, our preliminary analysis suggests that the HyLine approach merits further consideration based on its potential economic advantages. These advantages could also include the value of minimizing retail space used by hydrogen compression and storage sited at fueling stations, which is not reflected in our analysis.}
}
@article{MARSH2019S43,
title = {Unified electronic traceability and data storage system},
journal = {Cytotherapy},
volume = {21},
number = {5, Supplement },
pages = {S43},
year = {2019},
issn = {1465-3249},
doi = {https://doi.org/10.1016/j.jcyt.2019.03.387},
url = {https://www.sciencedirect.com/science/article/pii/S1465324919305389},
author = {M. Marsh and T. Chaput and D. Smith},
abstract = {Background & Aim
In a field that requires complete visibility and traceability, we are still relying on hand written forms and documents that introduce the possibility of fraud, human error, and other complications. I propose that soon, we as an industry will be able to electronically record patient information, sample data, logistics tracking, manufacturing batch records, and patient treatment data with little to no need for manual input. This software will use a series of patient, sample, and product barcodes to maintain complete traceability of the process from start to finish. All equipment used throughout the process will integrate into the software and automatically record values and calculations into the appropriate forms or batch records
Methods, Results & Conclusion
With this technology physicians and patients will have complete visibility into the treatment or therapy that is being developed and manufacturers will be able to track data trends and monitor incoming and outgoing materials in real time along with receiving updates and notifications related to critical events within the process. Privacy is also a serious concern within the cell therapy industry because all parties need the necessary information to produce a quality product all while respecting the regulations set in place by organizations like the FDA and HIPAA. With this technology only certain participants in the process will be given access to this sensitive information. A system like I am describing will streamline the FDA approval process that previously took years to complete by centralizing all necessary information. This will allow regulatory committees to locate specific pieces of data with a simple search on their computer instead of sifting through pages upon pages of documents allowing the company to get to market much faster. With date and time stamps attached to each piece of recorded information things such as deviation investigations and chain of custody will be expedited and made much easier to complete. This integrated software will also allow for real time communications between collection and manufacturing sites that will decrease the occurrence of miscommunication-based errors. Many collection and infusion sites do not have personnel that are aptly trained on things like cGMP regulations or proper technique to administer your product.}
}
@article{MULLER2019206,
title = {Digitization in wood supply – A review on how Industry 4.0 will change the forest value chain},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {206-218},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918305325},
author = {Fabian Müller and Dirk Jaeger and Marc Hanewinkel},
keywords = {Industry 4.0, Virtual forest, Digital forest, Wood supply, Timber},
abstract = {The term Industry 4.0 (I 4.0) has been shaping the discussion about increasing digitization in industrial and service value chains for several years. The concepts and technologies driving the fourth industrial revolution are increasingly moving to focus on forestry’s practice and research. They both are attempting to develop new solutions for the forestry sector by taking advantage of technological spillovers from other industry sectors. Based on an extensive systematic literature review, this article identifies general trends towards a smart wood supply chain and concrete I 4.0 application examples, which are already in practical use or still in the stage of research and development. On a process level, the I 4.0 application examples are described and discussed in detail, ranging from computerized decision support aids to electronic control, machine vision and post-harvest management. A process flow chart visualizes selected findings of the review, showing that the value of I 4.0 mainly lies in the interconnection of process steps along the value chain, with close to unlimited information flow and allocation in an internet of trees and services. This can lead to significant changes and value-adds in harvest planning, harvest organization and control, operations, transport and logistics as well as timber sales. Furthermore, we discuss the latest developments of simulation modelling based on remote sensing data in forestry, which turns out to be the basis for the concept of a virtual forest as digital copy of the reality. With respect to future research, we argue that the benefits of data generation and information flows across organizational borders within an internet of trees and services should be the interest of short and medium-term research. Moreover, we outline that research should not only work on overcoming the technical challenges of I 4.0 in wood supply such as robustness, reliability and accuracy. Socio-economic challenges such as willingness for cooperation, changes in work environments, labor qualification, data autonomy and added value distribution should also be discussed and analyzed. To conclude, with this review we contribute to a scientific discussion about the opportunities of I 4.0 and digitization in wood supply and give an extensive overview of technological developments, applications and challenges that wood supply will face in the future.}
}
@article{MERCHANT2019S280,
title = {Efficacy and Pharmacoeconomic Impact of Letermovir for CMV Prophylaxis in Allogeneic Hematopoietic Cell Transplant Recipients},
journal = {Biology of Blood and Marrow Transplantation},
volume = {25},
number = {3, Supplement },
pages = {S280},
year = {2019},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2018.12.349},
url = {https://www.sciencedirect.com/science/article/pii/S1083879118311716},
author = {Shelby Lorraine Merchant and Katie S. Gatwood and Gowri Satyanarayana and Michael T. Byrne and Adetola A. Kassim and Madan Jagasia and Bipin Savani and Brian G. Engelhardt and Kathryn Ann A. Culos},
abstract = {Cytomegalovirus (CMV) seropositivity and early CMV reactivation after hematopoietic-cell transplantation (HCT) remain associated with increased mortality. Those at high risk include CMV seropositive recipient/donor pairs (CMV R+ or D+) and those on escalated immunosuppression (prednisone ≥ 20mg/kg) for graft versus host disease (GVHD). Historically, our institutional CMV reactivation rate (RR) was 63% in our high risk cohort, similar to national average. Prophylaxis with letermovir, a new CMV-antiviral therapy, significantly reduced the incidence of CMV reactivation and viremia in a prospective trial (Marty FM, et al. NEJM 2017). The purpose of this study was to assess CMV reactivation, defined as CMV viral load > 500 IU/mL, with letermovir prophylaxis and its pharmacoeconomic impact in an outpatient transplant program. This was a retrospective review of adult HCT patients receiving letermovir from December 2017-August 2018 at Vanderbilt University Medical Center. Use of letermovir was standardized at a program level. Therapy was used in high risk patients, undergoing HCT with matched-unrelated donor (MUD), cord blood donor or haploidentical donor transplants with no active CMV reactivation prior to initiation and no anti-CMV treatment post-HCT. Primary endpoint compared CMV RR to historical controls utilizing a two-sided t-test. Secondary outcomes evaluated logistics and cost impact. 30 patients met entry criteria (26 CMV R+, 21 D+), RR was significantly lower than our historical control (20% vs 63%; p = 0.0003). Median time to reactivation was 38 days post-HCT (29-58). 4 of the 6 patients with reactivation received induction therapy with ganciclovir (50%), valganciclovir (25%), or letermovir (25%, peak viral load 740 IU/mL) for ∼40 days (31-52). All were CMV R-/D+ with AML and received HCT from MUD (75%) or haploidentical donors (25%). The remaining 2 patients (CMV R+/D+) had low level reactivation (137-500 IU/mL) and continued letermovir through day 100 without additional CMV treatment. Patients started letermovir by day 14 post-HCT (5-65) with a median 83 days (7-158) of prophylaxis. 3 patients received letermovir as secondary prophylaxis due to prior CMV reactivation or escalated immunosuppression for GVHD. Of those patients, reactivation occurred in 1 patient (AML MUD transplant; CMV D-/R+) who had 2 reactivations while on foscarnet therapy. No letermovir resistance was observed. Letermovir copay was between $10 and $360/month. 76% of prescriptions required prior authorization, 19% monetary grant, 18% patient assistance. Majority had private insurance (49%) and Medicare/Medicaid (36%) with a median of 3 days for approval and 5 days from prescription submission to patient medication pick-up. Primary prophylaxis with letermovir is associated with significantly lower RR compared to historical controls and is financially feasible with dedicated pharmacy services.}
}
@article{HOSEINZADEH2020101518,
title = {Quality of location-based crowdsourced speed data on surface streets: A case study of Waze and Bluetooth speed data in Sevierville, TN},
journal = {Computers, Environment and Urban Systems},
volume = {83},
pages = {101518},
year = {2020},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2020.101518},
url = {https://www.sciencedirect.com/science/article/pii/S0198971520302519},
author = {Nima Hoseinzadeh and Yuandong Liu and Lee D. Han and Candace Brakewood and Amin Mohammadnazar},
keywords = {Location-based data, Crowdsourced data, Waze, Bluetooth, Big data, Smart cities, Surface streets},
abstract = {Obtaining accurate speed and travel time information is a challenge for researchers, geographers, and transportation agencies. In the past, traffic data were usually acquired and disseminated by government agencies through fixed-location sensors. High costs, infrastructure demands, and low coverage levels of these sensor devices require agencies and researchers to look beyond the traditional approaches. With the emergence of smartphones and navigation apps, location-based and crowdsourced Big Data are receiving increased attention. In this regard, location-based big data (LocBigData) collected from probe vehicles and road users can be used to provide speed and travel time information in different locations. Examining the quality of crowdsourced data is essential for researchers and agencies before using them. This study assessed the quality of Waze speed data from surface streets and conducted a case study in Sevierville, Tennessee. Typically, examining the quality of these data in surface streets and arterials is more challenging than freeways data. This research used Bluetooth speed data as the ground truth, which is independent of Waze data. In this study, three steps of methodology were used. In the first step, Waze speed data was compared to Bluetooth data in terms of accuracy, mean difference, and distribution similarity. In the second step, a k-means algorithm was used to categorize Waze data quality, and a multinomial logistics regression model was performed to explore the significant factors that impact data quality. Finally, in the third step, machine learning techniques were conducted to predict the data quality in different conditions. The result of the comparison showed a similar pattern and a slight difference between datasets, which verified the quality of Waze speed data. The statistical model indicates that that Waze speed data are more accurate in peak hours than in night hours. Also, the traffic speed, traffic volume, and segment length have a significant association on the accuracy of Waze data on surface streets. Finally, the result of machine learning prediction showed that a KNN method performed the highest prediction accuracy of 84.5% and 82.9% of the time for training and test datasets, respectively. Overall, the study results suggest that Waze speed data is a promising data source for surface streets.}
}
@article{SIDDIQI2020S157,
title = {Walking the Tightrope: A Center's Experience with Simultaneous Heart-liver-kidney Transplantation},
journal = {Journal of Cardiac Failure},
volume = {26},
number = {10, Supplement },
pages = {S157},
year = {2020},
note = {Abstracts From the Heart Failure Society of America's (HFSA) Annual Scientific Meeting 2020},
issn = {1071-9164},
doi = {https://doi.org/10.1016/j.cardfail.2020.09.452},
url = {https://www.sciencedirect.com/science/article/pii/S1071916420313993},
author = {Umar A. Siddiqi and Pamela S. Combs and Gene Kim and Talia Baker and Yolanda Becker and Valluvan Jeevanandam},
abstract = {Background
Fewer than 25 simultaneous heart-liver-kidney transplants (SHLKTxs) have been performed in the U.S. This highly complex operation was performed nine times by only four centers from 2018 to 2019. However, one institution, the University of Chicago Medical Center (UCMC), is responsible for two-thirds of all SHLKTxs performed in that period. There is a paucity of literature regarding the logistics and infrastructure of performing SHKLTxs. The development of a standardized, effective protocol would improve outcomes in the high-risk patients who undergo this operation. We assessed the unique strategies that this center employs to successfully perform a high volume of SHLKTxs to understand possible programmatic procedures.
Methods
We reviewed the logistical methods and infrastructure of the UCMC concerning the process of SHLKTx, spanning the stages from patient selection to operating room (OR) management. Additionally, we attempted to identify areas of future improvement.
Results
The UCMC employs strict patient selection criteria, as potential candidates must meet the listing criteria for each organ independently. The severity of illness, however, must also indicate the potential for a successful outcome, and the age limit for candidates is typically 60 years. Donor selection and organ allocation are critical to ensure that all organs are received from the same donor, which can require negotiation when the procurement is not in a local area. The technically challenging surgery requires the transplant teams to move quickly in order to minimize ischemic time for the heart and prevent reperfusion injury in the liver, while the kidney is perfused. Due to the risk of these events, the transplant team recommends the use of mechanical support, such as extra-corporeal membrane oxygenation (ECMO). The key element of the UCMC's success was found to be the team's ability to procure and achieve success with organs that many other centers would turn down. The team is willing to accept undersized hearts, travel further distances, use DCD organs, and transplant Hepatitis C seropositive non-viremic (HCV Ab+/NAT-) livers to an HCV seronegative recipient in pursuit of an expeditious and successful SHLKTx. The combined efforts of a skilled, multidisciplinary team are also essential. The various teams see the patients together in a structured rounding schedule, and the operation itself consists of three distinct phases with choreographed and planned handoffs. Areas identified for future improvement included standardizing the approach used in the OR, particularly team transfer and timing.
Conclusion
The UCMC owes its established track record of successful SHLKTxs to the internal infrastructure of its program. In particular, its willingness to accept organs that other centers refuse allows it to perform a high volume of expeditious and successful SHLKTxs. Future steps include protocolizing OR management along with identifying parameters that allow for a structured system of team transfer.}
}
@article{LEBRAS2019351,
title = {Chariot et transpalette en logistique : comparaison d’OSEV 2017 pour évaluer l’exposition journalière aux vibrations corps entier A(8) des caristes, concordance des résultats avec des mesurages terrain (suite)},
journal = {Archives des Maladies Professionnelles et de l'Environnement},
volume = {80},
number = {5},
pages = {351-357},
year = {2019},
issn = {1775-8785},
doi = {https://doi.org/10.1016/j.admp.2019.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S1775878519300098},
author = {M. {Le Bras} and R. Petitfour},
keywords = {Évaluation, Exposition journalière aux vibrations corps entier, Valeur déclenchant l’action, Valeur limite d’exposition, Evaluation, Whole body vibrations, Exposure action value, Exposure limit value},
abstract = {Résumé
Problématique et objectifs
« Comment réaliser une évaluation fiable de l’exposition journalière aux vibrations corps entier A(8) sans mesure métrologique ? ». L’Association interprofessionnelle des centres médicaux sociaux de santé au travail de la région Île-de-France (ACMS) a été recontactée pour réévaluer l’outil OSEV2017. L’objectif est d’optimiser les ressources du service et des adhérents en minimisant les mesurages.
Méthodes
Cent-seize mesures, issues des études ACMS de terrain, réalisées en logistique de 2009 à 2014 avec des chariots frontaux et des transpalettes, ont été analysées en 2015. Leurs éléments observés ont servi de paramètres dans différents outils réputés : Whole Body Vibration calculator (WBV-HSE), OSEV2015 et OSEV2017 pour mesurer l’effet de la programmation. Les valeurs A(8) des caristes provenant des études de terrain sont confrontées à celles issues des trois outils, avec en référence les seuils réglementaires (0,5 et 1,15m/s2), illustrées graphiquement par « box plot ». L’interprétation probabiliste pour comparer les résultats des outils et des études ACMS terrain est fondée sur les calculs de sensibilité et de spécificité, et sur l’étude de la concordance entre deux méthodes par approche graphique « Bland-Altman plots ».
Résultats
Les outils étudiés Whole Body Vibration calculator (WBV-HSE), et OSEV2015 ont tendance à surestimer l’exposition journalière A(8) par rapport aux études ACMS de terrain pour les deux types d’engins. Les résultats d’OSEV2017 sont plus proches des valeurs terrain (biais+ ou −0,02). La sensibilité et la spécificité sont plus élevées pour les TEP que pour les chariots frontaux.
Conclusion
L’outil d’estimation OSEV2017 est plus fiable et peut être utilisé pour évaluer le risque vibratoire. L’amélioration d’OSEV a été efficiente (biais faibles).
Summary
Purpose of the study
“How to carry out a reliable assessment of the daily exposure whole body vibrations A (8) without measurements?” The interprofessional Association of the Social Medical centers of occupational health in Île-de-France region (ACMS) has been contacted to reassess the OSEV2017 tool. The objective of this study are to optimize the resources of the association and their members by minimizing measuring.
Methods
In 2015, the results of 116 ACMS vibrations measurements, carried out in logistics from 2009 to 2014 with forklift trucks and pallet trucks with on-board standing drivers, were analyzed. Their observed elements were used as parameters in three famous tools: Whole Body Vibration calculator (WBV-HSE), OSEV2015, OSEV2017. Values A(8) of the drivers coming from the measurement campaign are confronted with those from the three tools, in reference to the lawful thresholds (0.5 and 1.15m/s2), illustrated graphically by “box plot”. To compare the results from the tools and measurement campaign, the probabilistic interpretation is founded on calculations of the sensitivity and the specificity, and on the study of the agreement between two methods by graphic approach “Bland-Altman plots”.
Results
The studied tools Whole Body Vibration calculator (WBV-HSE), et OSEV2015 tend to over-estimate daily exposure A (8) compared to measurement studies for the two types of trucks. The results of OSEV2017 are closer to field values (bias+ or −0.02). Around 0.5m/s2, sensitivity and specificity are higher for pallet trucks than for forklift trucks.
Conclusion
The OSEV2017 estimation tool is consistent with ground values and can be used to assess vibratory risk. The improving of OSEV has been efficient (low biases).}
}
@article{ROBERTI202018,
title = {The Challenge of Recruiting Convalescent Plasma Donors during the COVID-19 Pandemic: Preliminary Results from a Single Center in Midwest Brazil},
journal = {Blood},
volume = {136},
pages = {18-19},
year = {2020},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2020-143058},
url = {https://www.sciencedirect.com/science/article/pii/S000649711872781X},
author = {Maria do Rosario Ferraz Roberti and Tiago Paiva Prudente and Renato Gomes Castro and Marcos Antonio Candido and Roberta Luiza Rodrigues and Maria Cunha Ribeiro Morelli and Alexandra Vilela Gonçalves and Jaciane Soares {de Sá} and Layane Marques {de Souza} and Marcelo Fouad Rabahi and Adriano de Moraes Arantes},
abstract = {In Brazil, until the 1980s, the context of blood as transfusion therapy was marked by paid donations. Thus, self-interest has surpassed solidarity as a motivator to donate. Recruiting donors involves advising the population due to the difficulties related to the myths around donation. With the COVID-19 pandemic, recruiting convalescent plasma (CP) donors has been a hard. This is an observational, prospective and non-interventionist study carried out in a hemotherapy unit of the Unified Health System, in central-western Brazil. Data collection was carried out from 06/19/2020 to 07/31/2020. The subjects were contacted by the Recruitment and Collection (CR) sector, through an active search, using lists of patients previously diagnosed with COVID-19. The study was also published on social and traditional networks, which resulted in self-reference. Convalescent COVID-19 patients tested, of both genders, aged between 18 and 60 years, weight over 60 kg, without symptoms for more than 14 days, and nulliparous donors were invited to the study. Those who met the criteria were scheduled for clinical and serological screening. The subjects eligible for donation, with IgG reagent, signed the Free and Informed Consent Form. Individuals with positive RT-PCR and / or non-reactive IgG were excluded. During the study period, RC made 308 and received 1,797 calls (2,105 contacts), generating 242 (11.5%) screening appointments, 173 (8.2%) of which resulted from self-referral and 69 (3.2%) from active search. Of these, 131 (6.2%) subjects attended the appointment. After clinical screening, 37 (28.25%) subjects were ineligible, 37 (28.25%) after serological tests and 57 (43.5%) were eligible for donation. The ineligibility causes in clinical and serological screening are described in table 1. Many countries face difficulties in meeting the demand for blood and its components during the pandemic (Barone & DeSimone. Transfusion, 2020), especially in those where blood commercialization is prohibited, as in Brazil. The purpose of recruiting donors is to make blood donation habitual to Brazilians, as it occurs in developed countries. Figure 2 shows self-referral rates after dissemination in traditional media. The ads focused on the donor’s ability to save lives by encouraging altruism (Ronse, et al. 2018).On the other hand, despite attracting more people, most were not eligible for donation, demonstrating a great capacity to raise awarenessamong the population, but it was necessary to improve criterias and demonstrate them clearly for the likely donor. Of the 26 donors, 22 (84.6%) are older than 29. For these, awareness-raising occurred mainly through the television media 9(34.6%) and 5(19.3%) through personal contact. In the youngest 4(15.4%), the stimulus was social networks (Sümnig, et al. Transfusion, 2018). Marketing was important for recruitment. As blood donation is not usual for most brazilians, it is essential to plan, develop, evaluate strategies, enabling new forms of collection. Another difficulty encountered was the logistics for this donation type. As the donor is convalescent, the recruitment, screening, and collection was restricted to a physical space, isolated from conventional donos (Bloch, et al. J Clin Invest. 2020). In conclusion, the COVID-19 pandemic has become a public health challenge worldwide. Many recovered patients could donate CP. However, it is necessary to define the ideal requirements for donor selection to ensure the therapeutic viability and efficacy of PC transfusion. Blood collection teams need to strengthen strategies to inform the population about blood donation needs. The information available in the traditional and digital media about the donation process can increase the donation rate and guarantee a safe blood component. Strategies such as a greater number of insertions in social networks with well-defined criteria for donating plasma from a convalescent donor, clarification of exclusion criteria in the means of greater reach, creation of easily accessible channels to the donor (registrations, central doubts),in addition to stratifying by age group and proposing different dissemination strategies and thanksgiving for the donation, forming a network of donations. The combined efforts of these actions will contribute with expert advice and experience, technical guidance and additional support to potentially save more lives. 
Disclosures
No relevant conflicts of interest to declare.}
}
@article{SREENIVASAN2019A6,
title = {Overview of rabies post-exposure prophylaxis access, procurement and distribution in selected countries in Asia and Africa, 2017–2018},
journal = {Vaccine},
volume = {37},
pages = {A6-A13},
year = {2019},
note = {Scientific and Operational Updates on Rabies},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2019.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X1930475X},
author = {N. Sreenivasan and A. Li and M. Shiferaw and C.H. Tran and R. Wallace and J. Blanton and L. Knopf and B. Abela-Ridder and T. Hyde and U.R. Siddiqi and S. Tahmina and K. Penjor and L. Sovann and Y. Doeurn and K. Sim and V. Houssiere and M. Tejiokem and R. Mindekem and L. Yu and Y. Wenwu and J. Benié and M. Tetchi and I. Tiembre and A. Deressa and A. Haile and B. Hurisa and N.A. Yawson and S.A. Ohene and M.K. Sudarshan and A. Narayana and A. Mwatondo and S.M. Thumbi and G. Edosoa and L. Baril and R. Ramiandrasoa and M. Rajeev and M.S. Fofana and A. Traore and M. Matchaya and J.L. {Burdon Bailey} and G. Yale and A. Dolgorkhand and N. Tsogbadrakh and A. Ochirpurev and K. Shrestha and J. Balami and H. Qureshi and N. Salahuddin and E. Villalon and L. Blumberg and A. Gunesekara and Joel Changalucha and H. Nguyen},
keywords = {Human rabies, Rabies post-exposure prophylaxis, Rabies vaccine access},
abstract = {Background
Rabies is a neglected zoonotic disease with a global burden of approximately 59,000 human deaths a year. Once clinical symptoms appear, rabies is almost invariably fatal; however, with timely and appropriate post-exposure prophylaxis (PEP) consisting of wound washing, vaccine, and in some cases rabies immunoglobulin (RIG), the disease is almost entirely preventable. Access to PEP is limited in many countries, and when available, is often very expensive.
Methods
We distributed a standardized assessment tool electronically to a convenience sample of 25 low- and middle-income countries in Asia and Africa to collect information on rabies PEP procurement, forecasting, distribution, monitoring and reporting. Information was collected from national rabies focal points, focal points at the World Health Organization (WHO) country offices, and others involved in procurement, logistics and distribution of PEP. Because RIG was limited in availability or unavailable in many countries, the assessment focused on vaccine. Data were collected between January 2017 and May 2018.
Results
We received responses from key informants in 23 countries: 11 countries in Asia and 12 countries in Africa. In 9 of 23 (39%) countries, rabies vaccine was provided for free in the public sector and was consistently available. In 10 (43%) countries, all or some patients were required to pay for the vaccine in the public sector, with the cost of a single dose ranging from US$ 6.60 to US$ 20/dose. The primary reason for the high cost of the vaccine for patients was a lack of funding at the central level to subsidize vaccine costs. In the remaining 4 (17%) countries, vaccine was provided for free but was often unavailable so patients were required to purchase it instead. The majority of countries used the intramuscular route for vaccine administration and only 5 countries exclusively used the dose-sparing intradermal (ID) route. Half (11/22; 50%) of all countries assessed had a standardized distribution system for PEP, separate from the systems used for routine childhood vaccines, and almost half used separate storage facilities at both central and health facility levels. Approximately half (9/22; 41%) of all countries assessed reported having regular weekly, monthly or quarterly reporting on rabies vaccination.
Conclusions
While all countries in our assessment had rabies vaccines available in the public sector to some extent, barriers to access include the high cost of the vaccine to the government as well as to patients. Countries should be encouraged to use ID administration as this would provide access to rabies vaccine for many more people with the same number of vaccine vials. In addition, standardized monitoring and reporting of vaccine utilization should be encouraged, in order to improve data on PEP needs.}
}
@article{GURRIARANBAS2019S881,
title = {SA110 - SHARED POLYGENIC RISK ANALYSIS OF ALCOHOLISM AND 5 MAJOR PSYCHIATRIC DISORDERS},
journal = {European Neuropsychopharmacology},
volume = {29},
pages = {S881-S882},
year = {2019},
note = {Abstracts of the XXVth World Congress of Psychiatric Genetics (WCPG), 13 - 17 October 2017, Orlando, Florida},
issn = {0924-977X},
doi = {https://doi.org/10.1016/j.euroneuro.2017.08.182},
url = {https://www.sciencedirect.com/science/article/pii/S0924977X17306466},
author = {Xaquín {Gurriarán Bas} and Julio Rodríguez-López and César Pereiro and José {Manuel Fernández} and Emilio Fariñas and Mario Páramo and Raquel Calvo and Manuel Arrojo and Gerardo Flórez and Javier Costas},
abstract = {Background
Alcohol is the most commonly used and abused substance. Addictions to alcohol and other legal/illicit drugs are heritable disorders influenced by a large number of variants of small effect, frequently being a comorbidity of other psychiatric disorders. This comorbidity between a mental illness and a Substance Use Disorder (SUD) is consistently contributing to an increased disability in individuals. In spite of this evidence of important comorbidity, shared genetic factors remain partially understudied. Previous GWAS of SUD showed evidence of genetic overlap with schizophrenia, bipolar disorder and major depressive disorder. We tested individual associations using Polygenic Risk Scores (PRS) from the Psychiatric Genomics Consortium's Cross-Disorder meta-analysis as discovery samples, and each of the five psychiatric disorders included in the study (ADHD, AUT, BIP, MDD, and SCZ), including 2014 PGC schizophrenia mega-analysis results, and, as target sample, a 1144 individuals case/control sample of alcohol abuse/dependence from Galicia, northwest Spain.
Methods
A total of 572 substance dependent patients were included. Inclusion criteria were: age between 18 and 65, born in Galicia and follow DSM-IV criteria for dependence of at least one substance and abuse/dependence of other substance. The substances registered in the study were: alcohol, tobacco, cannabis, cocaine, opiates, hypnotics, stimulants, hallucinogens and solvents. Most patients (N=540) were diagnosed with alcohol abuse/dependence. A total number of 604 controls from Galicia were included (mean age at recruitment: 40.26, SD: 10.70). DNA was extracted from blood samples and genotyping was performed using Illumina Infinium PsychArray. Variant imputation was executed with SHAPEIT and IMPUTE2, and PRS models were derived from the summary statistics of the PGC cross-disorder meta-analysis (CROSS) and 2014 PGC schizophrenia mega-analysis (SCZ2). Extensive data cleaning and Quality Control (QC) was employed. SNPs within the extended MHC region were excluded from part of the analysis. Associations between every PRS model and our data were tested using logistics regression.
Results
After QC and imputation, a total number of 503 alcohol cases and 587 controls remained (728 males and 362 females) and genotypic data remained in a total number of 6294324 SNPs. Covariates were included in regression analysis for correction (missing genotyping rate, significant MDS dimensions, sex and age). General CROSS-disorder PRSs (5 disorders included) showed a strong association with alcohol dependence (P=7.39e-06, ΔR=2%). After analyzing each disease separately, significant results were found in bipolar disorder (P=0.0064, ΔR=0.7%) and schizophrenia (P=7.06e-05, ΔR=1.5%). A consistent result was achieved using the greater sample of SCZ2 were obtained a consistent (P=4.49e-10, ΔR=4.1%). SCZ2 and general CROSS-disorders results are robust after Bonferroni multiple test correction (7 thresholds and 7 pathologies employed).
Discussion
The use of a greater sample in SCZ2 improves results in schizophrenia, showing the consistency of these in this pathology. Moreover, the variability percent explained is high considering previous data of shared genetic susceptibility between schizophrenia and other psychiatric disorders. Despite the fact that the sample used in major depression disorder was bigger than the one in bipolar disorder, these results were not significant. It is necessary to consider that a fraction of PGC individuals show comorbidity with SUDs. As evidenced in this study, an increase in the number of PGC discovery individuals sample will improve the ability to detect this shared genetic susceptibility.}
}
@article{RYHAMMER2019S114,
title = {Combined spirometry and diffusion capacity test does not enhance diagnostic prediction before TAVI},
journal = {Journal of Cardiothoracic and Vascular Anesthesia},
volume = {33},
pages = {S114-S115},
year = {2019},
note = {2019 EACTA Abstracts},
issn = {1053-0770},
doi = {https://doi.org/10.1053/j.jvca.2019.07.066},
url = {https://www.sciencedirect.com/science/article/pii/S1053077019307050},
author = {P.K. Ryhammer and J. Greisen and M. Gissel and C.-J. Jakobsen},
abstract = {Introduction
Chronic Pulmonary disease (CPD) has been considered a high risk factor in aortic valve replacement. Many studies have found an acceptable short time outcome, but CPD influences long term mortality [1], and thus are increasingly referred to transcatheter aortic valve implantation (TAVI). A limited activity level and shortness of breath can be due to both pulmonary and cardiac reasons and pulmonary function testing are routinely used in patients referred for TAVI. So far the impact of obstructive and restrictive lung disease on TAVI outcomes remains unclear [2,3]. The aim of this study was to assess whether diffusion capacity testing improves diagnostic prediction.
Methods
Fifty patients scheduled for TAVI were evaluated with spirometry, diffusion capacity-test (Diffusion capacity Lung Carbon monoOxide, (DLCO)) and 6 minutes walking-test the day before the procedure, and repeated 30-45 days after. Outcomes were changes in walking-test, in-hospital complications and 30-days/6-month mortality.
Results
Average age was 79.0 ± 6.0, BMI 27.1 ± 6.1 and 36% females. Preoperative testing showed that 20 (40%) had CPD (FEV1 < 80% of predicted), of which 11 had obstructive disease (FEV1/FVC < 0.7) and 9 restrictive disease (FEV1/FVC > 0.7). Sixteen patients had marginally reduced DLCO (60-80 % of predicted), while 15 were moderately reduced (40-60%). More patients, although not significant, with obstructive CPD had a reduced DLCO (9/11), compared to other groups (Left). Significantly more patients without CPD, but reduced diffusion capacity, improved the postoperative walking-test (> 10%), compared to other groups (P = 0.031; Right). The complications were low with one new dialysis (restrictive CPD), one stroke (obstructive CPD) and one death within 30-days (No CPD). Nine patients did not complete the second examination due to death (1), still ICU day 30 (1), readmitted cancer (1), logistics (3), while the final three declined due to lack of energy.
Discussion
Overall the number of complications was low and chronic lung disease seems without serious impact on postoperative outcome. Patients with isolated lower diffusion capacity seemed to benefit most in postoperative activity, theoretically to improved circulation or less pulmonary oedema after TAVI. The combination of spirometry and diffusion testing did not increase the ability to select patients that will not benefit from TAVI. Interestingly,. Research in high age patients increase the risk of dropouts.}
}
@article{SHACKLEFORD2021S175,
title = {P74. Cost impact of intravenous drug use on the treatment of spine infections},
journal = {The Spine Journal},
volume = {21},
number = {9, Supplement },
pages = {S175-S176},
year = {2021},
issn = {1529-9430},
doi = {https://doi.org/10.1016/j.spinee.2021.05.282},
url = {https://www.sciencedirect.com/science/article/pii/S1529943021005465},
author = {Taylor Shackleford and William Hickman and Ankur Makani and Brent Zutaut and Clinton Garret Cooper and Shari Cui},
abstract = {BACKGROUND CONTEXT
Intravenous drug use (IVDU) is the most common cause of spinal infections in otherwise healthy young patients without medical risk factors or significant comorbidities. IVDU is also associated with significant medical and psychological morbidity and mortality, resulting in a large financial burden to the entire health care system. Psychosocial issues and noncompliance are common, plaguing and complicating the logistics of standard of care.
PURPOSE
The purpose of this study is to identify the cost of treating spinal infections in patients with IVDU history and compare it to the cost of treating similar infections in medical patients without IVDU history.
METHODS
A retrospective chart review was performed to identify all adult patients admitted in 2018 to a single tertiary referral center with a diagnosis of discitis, vertebral osteomyelitis, or spinal epidural abscess. Information on demographics, treatment, comorbidities, costs of treatment, and payment were collected for each patient. Data was compared between the group with IVDU history and the group without.
RESULTS
A total of 130 patients met inclusion criteria; 42 had IVDU history and 88 did not. The non-IVDU group was found to be older (age of 63.7 years vs 41.3 years, p<0.0001) with higher rates of diabetes, end stage renal disease, and cancer, and lower rates of infective endocarditis and liver disease. The average length of stay in the hospital was 28.1 days for the IVDU group, and 13.5 for the non-IVDU group (p<0.0001). Nine (21.4%) of the IVDU group were able to be discharged to rehab or long-term care facility for treatment, while 38 (43.2%) of the non-IVDU were discharged to another facility (p=0.0001). Forty (95.2%) of the IVDU group and 75 (85.2%) of the non-IVDU group had either Medicare or Medicaid as their insurance (p=0.06). Average total charge per hospitalization for the patients in the IVDU group was $141,070 and $125,283 in the non-IVDU group (p=0.41). Insurance payment per day was significantly lower in the IVDU group compared to the non-IVDU group, with the values being $1,231.47 and $3,549.61, respectively (p=0.0008). Total cost per day to the hospital was also significantly lower in the IVDU group, who had a per day cost of $3,374.16 compared to $6,788.19 in the non-IVDU group (p=0.0049). Total charges per day were lower in the IVDU group at $6,192 compared to $10,151.20 in the non-IVDU group (p=0.0009).
CONCLUSIONS
While those who use IV drugs do not cost the hospital as much per day as others being treated for spinal infections, the length of stay for these patients is more than double that of non-IV drug users. This is likely due to the practice in many hospitals, where active IVDU history is a contraindication to discharge with long-term intravenous access (such as peripheral intravenous central catheters). This population is also often self-pay or Medicaid, thereby often not accepted by short-term rehabilitation or long-term care facilities to finish their medical treatment. Tertiary care centers are often left to treat these patients until completion of intravenous course. This constellation of situational consequences results in a significant loss of revenue and tieing-up of resources that could otherwise be utilized on other patients. This study quantifies the significant cost burden created by IVDU-associated spine infections in one tertiary academic hospital center and offers insight on specific areas where policy and public health can help in minimizing the cost of this epidemic.
FDA DEVICE/DRUG STATUS
This abstract does not discuss or include any applicable devices or drugs.}
}
@article{GUO2020101917,
title = {Digital twin-enabled Graduation Intelligent Manufacturing System for fixed-position assembly islands},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {63},
pages = {101917},
year = {2020},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2019.101917},
url = {https://www.sciencedirect.com/science/article/pii/S0736584519304405},
author = {Daqiang Guo and Ray Y. Zhong and Peng Lin and Zhongyuan Lyu and Yiming Rong and George Q. Huang},
keywords = {Digital twin, Intelligent manufacturing system, Fixed-position assembly, Cloud-based services, Real-time synchronization},
abstract = {The layout of fixed-position assembly islands is widely used in the heavy equipment industry, where the product remains at one assembly island for its entire assembly period, while required workers, equipment, and materials are moved to the island according to the assembly plan. Such layout is not only suitable for producing bulky or fragile products, but also offers considerable flexibility and competitive operational efficiency for products with medium variety and volumes. However, due to inherent complexity of the product, sophisticated assembly operations heavily rely on skilled operators, and the complexity and uncertainty are high and amplified by such massive manual interventions as well as the unique routing patterns of the fixed-position assembly process. Aiming at reducing the complexity and uncertainty, this paper introduces a digital twin-enabled Graduation Intelligent Manufacturing System (DT-GiMS) for fixed-position assembly islands. Inspired by the success of graduation ceremony, an assembly system-Graduation Manufacturing System (GMS) is proposed for fixed-position assembly islands, in which job tickets, setup tickets, operation tickets, and logistics tickets are designed to organize the production activities. Following the concept of digital twin, unified digital representations with appropriate sets of information are created at object level, product level, and system level, respectively. Through Internet of Things (IoT), smart gateway, Web 3D and industrial wearable technologies, vital information including identity, status, geometric model, and production process can be captured and mapped in physical space, and converged and synchronized with their digital representations in twin (cloud) space on a real-time basis. The overall framework of DT-GiMS is presented with physical layer, digital layer, and service layer. Real-time convergence and synchronization among them ensure that right resources are allocated and utilized to the right activities at the right time with enhanced visibility. Considering customer demand and production capacity constraints, real-time ticket pool management mechanisms are proposed to manage production activities in a near-optimal way under DT-GiMS. With the support of cloud-based services provided in service layer in DT-GiMS, managers could easily make production decisions, and onsite operators could efficiently complete their daily tasks with nearly error-free operations with enhanced visibility. A demonstrative case is carried out to verify the effectiveness of the proposed concept and approach.}
}
@article{RODRIGUEZ2019883,
title = {A trauma registry experience from the main referral center of Honduras: A call for action},
journal = {Injury},
volume = {50},
number = {4},
pages = {883-889},
year = {2019},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2019.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0020138319301226},
author = {Cristina Rodriguez and Francisco J. Bonilla-Escobar and Catalina Restrepo-Lopera and Anastasia Markovtsova and Marco T. Medina and Juan Carlos Puyana},
keywords = {Public health surveillance, Honduras, Violence, Wounds and injuries, Traffic accidents, Attempted suicide (source: MeSH, NLM)},
abstract = {Background: Honduras is one of the most violent countries in the world and it has limited epidemiological data that describes the extent of intentional and unintentional injuries. This research is needed to develop and inform prevention programs in Honduras, as well as to spread international awareness. Methods: A cross-sectional study was carried out on a paper-based injury surveillance system (InSS) with the help of Honduras’ University Medical School Hospital (UMSH), the main referral medical center in Tegucigalpa-Honduras. Descriptive statistics and bivariate analysis were carried out using data from all registered injuries in 2013. Results: Of the 17,971 injuries reported, intentional injuries made up 18.14% of all injuries. Interpersonal violence from gun violence, robberies, and physical altercations accounted for 14.68%. Self-inflicted injuries made up 3.46% of injuries, with suicide falls and poison intoxications being the most frequent (1.9% and 1.2%, respectively). Sexual harassment was minimally reported (0.27%, n = 48). Unintentional injuries made up 81.79% of the total injuries. The most common causes of unintentional injuries were falls (38.01%) and road traffic injuries (16.65%). Motorocyclists made up 35.4% of those injured by road traffic accidents. In general, injuries occured during the weekend and mainly affected men during the ages when they would be most likely to work and maintain jobs. The modified Kampala trauma score (M-KTS) showed that most of the injuries were mild (range 3–11), with 59.59% of the patients with a M-KTS of 9, and an overall mortality rate of 0.65% (n = 117). Conclusion: The description of injuries provides the basis for prevention. The disproportionate number of unintentional injuries (4:1) seen in Honduras’ referral hospital calls for further research in: 1) trauma care logistics and emergency systems, 2) mortality and lethality of intentional injuries, and 3) analysis of the types of unintentional injuries. Further research is necessary to evaluate interventions and identify the socioeconomic effects of injuries in the region.}
}
@article{SUYAMBU2020152,
title = {Blockchain – A Most Disruptive Technology On The Spotlight Of World Engineering Education Paradigm},
journal = {Procedia Computer Science},
volume = {172},
pages = {152-158},
year = {2020},
note = {9th World Engineering Education Forum (WEEF 2019) Proceedings : Disruptive Engineering Education for Sustainable Development},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920313466},
author = {G. Thiraviya Suyambu and M. Anand and M. Janakirani},
keywords = {Revolutionary innovations, Centralized, Decentralized systems, World engineering education, Blockchain, Corporate giants, startups, immutable ledger},
abstract = {Throughout its history, preferably over the last four centuries, the world witnessing game changing and disruptive technologies on certain regular intervals. Wheels, Compass, calendar and pozzolana are some of the remarkable inventions in before Christ (B.C) period. Clock, printing press, steam engines, vaccines, electricity, mechanical computer, telegraph, iron and steel, aero plane, transistors, ARPANET, personal computer and Internet are few outstanding innovations fuelled our world for last four centuries. If we look at the time line of inventions, it is dramatically reduced over the advancement of time. Inventions took centuries in B.C, but needs only a few years or a decade in A.D. We would like to add the blockchain technology in this line up, which could fuel new era of inventions in new dimensions. This technology relies on decentralized concepts, entirely against the present centralized system, the world relies on. Why we still need a third party book keepers or why we still need an third party intermediary for trust and transactions? This article will answer these arguments. This article begins with the conceptual understanding, then reveals its disruptiveness through several case studies across several industries such as Banking, Administration, Supply chain management, Logistics, Asset management, Intellectual property management, Transport and Energy. Blockchain technology has the potential to redefine every one another technology of human beings. Concept of ledger and its evolution, from its voyage from Indian origin single entry ledger to Satoshi Nakamoto’s triple entry ledger has been highlighted, as these are vital to understand the technology behind bit coin. Without mentioning the crypto currencies, the blockchain use cases will not ended up, hence few excerpts of crypto currencies also added. From cryptography in technology, Anti money laundering, Know your customer, Transaction monitoring in Banking to day to day administration as in the case of land records storage, identity management etc., are few contributions of this article. We also covered the case studies from corporate giants such as Amazon, IBM, MAERSK to the startups like EzyRemit, Signzy etc., and from an individual state of administration Andrapradesh to the entire country, Dubai. It is important for the global engineering education needs to identify and nurture the disruptive technologies, which could contribute to our society in meaningful way. We believe that, blockchain technology belongs to the category of future technologies, which could shape up and fuel the development of global economy for next few decades as internet did for past few decades. Through this article, the young generation engineering pupils, matured practitioners and influential decision makers will understand the potential of blockchain technology and provide impetus to global engineering education.}
}
@article{FRANK2020S313,
title = {MDS-107: MDS Patients' Needs from Online Discussion Forums: An Artificial Intelligence and Natural Language Processing Analysis of 20,000 Posts in US, UK, Canada, and China},
journal = {Clinical Lymphoma Myeloma and Leukemia},
volume = {20},
pages = {S313-S314},
year = {2020},
note = {Proceedings of the Society of Hematologic Oncology 2020 Annual Meeting},
issn = {2152-2650},
doi = {https://doi.org/10.1016/S2152-2650(20)30965-4},
url = {https://www.sciencedirect.com/science/article/pii/S2152265020309654},
author = {Pauline Frank and Emma Sasse},
keywords = {MDS, myelodysplastic syndromes, quality of life, caregivers},
abstract = {Context:
Online patient discussion forums are important in helping myelodysplastic syndrome (MDS) patients and caregivers navigate the disease and treatment journey. These forums can uncover patient information gaps or needs. Access to therapies and cultural backgrounds influence perceptions of health and disease management approaches. Patient interactions may also identify similarities and cultural nuances of MDS patients across countries.
Objective:
To understand what conversations from online forums of MDS patients and their caregivers convey about their needs as they navigate the disease and treatment journey.
Design:
We leveraged Artificial Intelligence and Natural Language Processing (NLP) to algorithmically analyze over 20,000 public, anonymous online comments from 2011 to 2019 to understand the motivation of MDS patients and caregivers from the US, UK, Canada, and China. The NLP algorithm generates a Network that organizes large volumes of unstructured data into topics based on semantic similarity.
Results:
Seven overarching motivations were extrapolated. “Emotional” refers to receiving/providing emotional support to other patients. “Treatments” relates to treatments, including regimes and decisions. “Transplants” includes the benefits, risks, and experience of transplants. “Clinical” relates to diagnosis, progression, and monitoring. “Education and Logistics” focuses on learning about the disease and care options. “Physical” highlights management of symptoms and treatment side effects. “Diet and Lifestyle” focuses on diet changes and other aspects of living with MDS. The analysis of 20,000 posts detected different motivations but also universal similarities in MDS narratives across countries. In the US, the top conversation driver indicated that patients seek out those with similar cytogenetics profiles, MDS types, or diagnoses. In contrast, in the UK, emotional support was a top motivational driver for patients and caregivers. In Canada, the conversation was driven by patients asking others for specific treatment experiences to evaluate their treatment options. Conversely, patient posts in China indicated that patients are more focused on understanding the disease.
Conclusions:
The findings suggest that there are unmet information and support needs among MDS patients and caregivers. These include disease/treatment information, support, adequate information sources, and overall guidance to navigate patients through their journey. Greater healthcare professional awareness of these gaps may improve patient care.}
}
@article{LLORENTEPARRADO2020339,
title = {Modelo de evaluación del plan de respuesta frente a la pandemia de COVID-19 en un hospital de tercer nivel},
journal = {Journal of Healthcare Quality Research},
volume = {35},
number = {6},
pages = {339-347},
year = {2020},
issn = {2603-6479},
doi = {https://doi.org/10.1016/j.jhqr.2020.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2603647920301068},
author = {C. Llorente-Parrado and R. Mejon-Berges and Y. Cossio-Gil and M.S. Romea-Lecumberri and A. Roman-Broto and M.A. Barba-Flores and A. Salazar-Soler},
keywords = {COVID-19, Plan de emergencia, Hospitales, Investigación sobre servicios de salud, Mejoramiento de la calidad, Auditoría administrativa, COVID-19, Emergency preparedness, Hospitals, Health services research, Quality improvement, Management audit},
abstract = {Resumen
Antecedentes y objetivo
Durante la primera onda epidémica del SARS-CoV-2, los hospitales han soportado una importante presión asistencial. Este escenario de incertidumbre, baja evidencia científica y medios insuficientes ha generado una importante variabilidad de la práctica entre diferentes centros sanitarios. En este contexto, planteamos desarrollar un modelo basado en estándares para la evaluación del sistema de preparación y respuesta frente a la COVID-19 en un hospital terciario.
Materiales y métodos
El estudio se llevó a cabo en el Hospital Universitario Vall d’Hebron de Barcelona en dos fases: 1) desarrollo de modelo de estándares mediante revisión narrativa de la literatura, análisis de planes y protocolos del hospital, método Delphi por profesionales expertos y plan de actualización y 2) validación de aplicabilidad y utilidad del modelo mediante autoevaluación y auditoría.
Resultados
El modelo consta de 208 estándares distribuidos en nueve criterios: liderazgo y estrategia; prevención y control de la infección; gestión de profesionales y competencias; áreas públicas comunes; áreas asistenciales; áreas de apoyo asistencial; logística, tecnología y obras; comunicación y atención al paciente; sistemas de información e investigación. La evaluación alcanza un 85,2% de cumplimiento, y se identifican 42 áreas de mejora y 96 buenas prácticas.
Conclusiones
La implementación de un modelo basado en estándares es útil para identificar áreas de mejora y buenas prácticas en los planes de preparación y respuesta frente a la COVID-19 en un hospital. En el actual contexto, proponemos la conveniencia de adaptar esta metodología a otros ámbitos de atención sanitaria no hospitalaria o de salud pública.
Background and purpose
During the first wave of the epidemic caused by SARS-CoV-2, hospitals have come under significant pressure. This scenario of uncertainty, low scientific evidence, and insufficient resources, has generated significant variability in practice between different health organisations. In this context, it is proposed to develop a standards-based model for the evaluation of the preparedness and response system against COVID-19 in a tertiary hospital.
Materials and methods
The study, carried out at the University Hospital of Vall d’Hebron in Barcelona (Spain), was designed in two phases: 1) development of the standards-based model, by means of a narrative review of the literature, analysis of plans and protocols implemented in the hospital, a review process by expert professionals from the centre, and plan of action, and 2) validation of usability and usefulness of the model through self-assessment and hospital audit.
Results
The model contains 208 standards distributed into nine criteria: leadership and strategy; prevention and infection control; management of professionals and skills; public areas; healthcare areas; areas of support for diagnosis and treatment; logistics, technology and works; communication and patient care; and information and research systems. The evaluation achieved 85.2% compliance, with 42 areas for improvement and 96 good practices identified.
Conclusions
Implementing a standards-based model is a useful tool to identify areas for improvement and good practices in COVID-19 preparedness and response plans in a hospital. In the current context, it is recommended to repeat this methodology in other non-hospital and public health settings.}
}
@article{LIM202018,
title = {Feasibility of Advanced Practice Nurse - Led Telehealth Service in Patients with Myeloproliferative Neoplasm in the Community: A Singapore Single-Centre Report},
journal = {Blood},
volume = {136},
pages = {18-19},
year = {2020},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2020-138410},
url = {https://www.sciencedirect.com/science/article/pii/S0006497118733776},
author = {Chi Ching Lim and Xiaojuan Chen and Yee Mei Lee and Winnie ZY Teo and Moon Ley Tung and Wee-Joo Chng and Melissa Ooi},
abstract = {Introduction Telehealth is fast becoming a promising alternative service for face-to-face consultation in healthcare to improve access to healthcare in a cost effective manner. An academic medical centre (AMC) piloted a tele-consultation program for patients with myeloproliferative neoplasm (MPN), a disease with an abnormal mutation in the bone marrow leading to overproduction of any combination of white cells, red cells and platelets. The program aimed to demonstrate the feasibility and safety of the use of telehealth in managing patients with MPN. Methods For this program only patients with Essential Thrombocytosis (ET) and Polycythemia Vera (PV) who met the criteria were recruited and enrolled into the program. Workflows, logistics and education materials were developed and briefed to stakeholders prior to the commencement of the program. The program utilised the Advanced Practice Nurses' (APNs) expertise in the haematology unit to support the service. APNs were provided addition training on both clinical practice knowledge and the appropriate use of the telehealth equipment. Data was collected between January and July 2020. Prospective outcome indicators measured were i) correct treatment prescribed according to guidelines; ii) number of emergency visits due to events related to MPN and its complications, iii) deterioration in cardiovascular health (namely hypertension, diabetes mellitus and hyperlipidermia) iv) number of patient visits right-sited to the community and v) barriers and facilitators for the uptake of the program. Results A total of 21 patients with 44 tele-consults over 7 months was captured. Average age of the patients were 70.1 years. Thirteen patients were diagnosed with ET and 8 patients have PV. Only 1 patient was on a combination of hydroxyurea and anagrelide, the rest of the patients were on hydroxyurea. A total of 14 dosage adjustments were made based on patients' complete blood count, and all of patients' blood countsremained stable during the following review. Two venesections were prescribed for patients with PV. None of the patients required ED visit or admission due to events related to MPN and its complications. One patient was referred back to physician earlier due to non-compliance to telehealth review. All patients had their blood pressure reviewed within 1 year. Sixteen patients had fasting glucose/HbA1c within 2 years, and 14 patients had fasting lipid within 2 years. None of the patients required cardiovascular medication titration, thus there is no deterioration in their cardiovascular health since recruitment. For 9 of the telehealth review, patients did their blood tests concurrently with other medical appointments they had at an earlier date, hence saving a separate trip to hospital for blood test. We were also able to consolidate blood tests and reduce repetition for these 9 patients. Only 8 telehealth blood tests were done in the community, largely due to the closure of satellite blood test service during COVID pandemic. There were only 6 home medicine deliveries, largely because many of the patients had collected adequate medications lasting half a year to a year during physical consult with physicians. The MPN telehealth service has right sited a total of 67 hospital visits to the community. We determined the barriers and facilitators to the program are due to patient, physician and workflow factors. Some of our older patients do not own a mobile device, or prefer traditional, physical consultations with physicians. Some physicians are unfamiliar with telehealth referral workflow. Potential facilitators include older, immobile patients with multiple comorbiditieswanting to cut down hospital visits, as well as patients whose work schedule did not permit frequent hospital visits. Conclusions Our results show that utilising APN-led telehealth service is a feasible and safe method to deliver care to patients with myeloproliferative neoplasm in the community. Right-siting of patient care could reduce patient visits to hospitals especially during COVID pandemic. Ongoing challenges include increasing the number of blood test facilities in the community to facilitate blood taking in the community. Other proposed intangible benefits would include improving patients' psychosocial well-being by transiting them to a new normalcy with minimal hospital visits to a haematology centre. There is potential cost- saving as well that will be explored.
Disclosures
Chng: Janssen: Honoraria, Research Funding; Celgene: Honoraria, Research Funding; Novartis: Honoraria; Abbvie: Honoraria; Amgen: Honoraria, Research Funding.}
}
@article{SEHEULT2019174,
title = {The Dead Sea needs salt water… massively bleeding patients need whole blood: The evolution of blood product resuscitation},
journal = {Transfusion Clinique et Biologique},
volume = {26},
number = {3},
pages = {174-179},
year = {2019},
note = {Etats de l'art - XXIXe Congrès de la Société Française de Transfusion Sanguine (SFTS) - Nantes, 18-20 septembre 2019},
issn = {1246-7820},
doi = {https://doi.org/10.1016/j.tracli.2019.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1246782019300680},
author = {J.N. Seheult and M.P. Bahr and P.C. Spinella and D.J. Triulzi and M.H. Yazer},
keywords = {Whole blood, Massive bleeding, Low titer, Trauma, Transfusion, Sang total, Hémorragie massive, Titres en isoagglutinines, Traumatisme, Transfusion},
abstract = {Whole blood, that is blood that is not manufactured into its component red blood cells (RBC) plasma, and platelets (PLT) units, was the mainstay of transfusion for many years until it was discovered that the component parts of a blood donation could be stored under different conditions thereby optimizing the storage length of each product. The use of low anti-A and -B titer group O whole blood (LTOWB) has recently been rediscovered for use in massively bleeding trauma patients. Whole blood has several advantages over conventional component therapy for these patients, including simplifying the logistics of the resuscitation, being more concentrated than whole blood that is reconstituted from conventional components, and providing cold-stored PLTs, amongst other benefits. While randomized controlled trials to determine the efficacy of using LTOWB in the resuscitation of massively bleeding trauma patients are currently underway, retrospective data has shown that massively bleeding recipients of LTOWB with traumatic injury do not have worse outcomes compared to patients who received conventional components and, in some cases, recipients of LTOWB have more favourable outcomes. This paper will describe some of the advantages of using LTOWB and will discuss the emerging evidence for its use in massively bleeding patients.
Résumé
Le sang total, c’est-à-dire le sang non fractionné en concentrés de globules rouges et plaquettaires et en plasma, a été le standard de la transfusion pendant des décennies avant qu’on n’ait découvert les conditions permettant la conservation différentielle du sang donné en différents produits permettant le stockage optimisé de chaque fraction. L’utilisation de sang total de groupe O et de titre bas en anti-A et anti-B (LTOWB : « Low anti-A and -B titer group O Whole Blood ») a été récemment redécouvert pour les situations d’hémorragie massive chez les patients traumatisés. Le sang total a de nombreux avantages par rapport aux produits séparés pour la prise en charge de ces patients, dont la simplification logistique de la réanimation, et par le fait que les facteurs essentiels y sont plus concentrés que dans une reconstitution à partir des produits séparés ; ils pourvoient aussi en plaquettes conservées à froid qui apportent un bénéfice. Des essais cliniques sont actuellement en cours pour déterminer l’efficacité du LTOWB dans la réanimation des patients hémorragiques massifs ; des données rétrospectives dans ce type de pathologie ont montré l’absence d’effet délétère comparé aux prises en charge conventionnelles et au contraire, dans un certain nombre de situations, ont montré un bénéfice sur le devenir des traumatisés. Ce papier décrit les avantages et les inconvénients à recourir au LTOWB, et il discute les avancées dans son application dans les situations d’hémorragie massive.}
}
@article{LOUDON2019206,
title = {Development of a Collaboration Model between Two Cancer Centres to Maintain Patient Access to Radiation Therapy during the Replacement of a Sole CT Simulator at a Regional Cancer Centre},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {50},
number = {2},
pages = {206-211},
year = {2019},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2019.03.178},
url = {https://www.sciencedirect.com/science/article/pii/S1939865418304740},
author = {James Loudon and Leslie Proctor and Julie Wenz and Jerry Roussos and Nelissa Chaudhry and Douglas Moseley and Beibei Zhang and Ivan Yeung and Fei-Fei Liu and Woodrow Wells},
keywords = {CT simulation, access, radiation therapy},
abstract = {Introduction
Replacement of a sole computed tomography (CT) simulator at a Regional Cancer Centre risks interruption of patient access to radiation therapy clinical services. This study reports a collaboration model between two cancer centres to maintain patient access to radiation therapy during the replacement period.
Methods
Representatives from each cancer centre collaborated to plan and facilitate offsite CT simulation. Activities required were identified and included process coordination, patient consent, patient registration, requisitions, appointment bookings, immobilization equipment, staffing strategy, clinical practice protocols, data transfer, and cost recovery. The logistics of each activity were planned and mapped, with roles identified to perform each activity. During the 2-week replacement duration, from April 30 to May 11, 2018, patients consulted for radiotherapy were offered offsite CT simulation.
Results
A detailed process was developed to outline the flow of activities for successful coordination of offsite CT simulations. A total of 14 patients consented to radiation treatment during the CT simulator replacement downtime, of which 8 patients agreed to offsite CT simulation. A total of 11 body regions were simulated for the 8 patients. CT images acquired offsite were electronically transferred to the primary cancer centre to proceed with treatment planning and delivery.
Discussion
A collaboration model between two cancer centres was successfully developed and implemented to maintain patient access to radiation therapy during the replacement of a sole CT simulator at a regional cancer centre.
Conclusion
This strategy and process developed could be valuable for future major equipment upgrades/replacements at other centres.
Résumé
Introduction
Le remplacement du seul appareil de simulation TDM dans un Centre régional de cancérologie risque de causer une interruption de l’accès aux services cliniques de radiothérapie pour les patients. Le présent article présente un modèle de collaboration entre deux centres de cancérologie pour maintenir l’accès des patients aux services de radiothérapie durant la période de remplacement.
Méthodologie
Des représentants des deux centres ont collaboré pour planifier et faciliter la simulation TDM hors-site. Les activités nécessaires ont été recensées et incluses : coordination du processus, consentement des patients, inscription des patients, demandes de services, prises des rendez-vous, équipement d’immobilisation, stratégie de dotation, protocoles de pratique clinique, transfert de données et recouvrement des coûts. Pendant les deux semaines du processus de remplacement, du 30 avril au 11 mai 2018, la simulation TDM hors-site a été offerte aux patients en consultation pour des soins de radiothérapie.
Résultats
Un processus détaillé a été établi pour préciser le flux des activités nécessaires à la coordination réussie de la simulation TDM hors-site. Au total, 14 patients ont consenti à des traitements de radiothérapie durant la période de remplacement de l’appareil de simulation TDM, parmi lesquels huit ont accepté la simulation hors-site. Au total, 11 régions ont fait l’objet de simulations pour ces huit patients. Les images TDM acquises hors-site ont été transférées électroniquement au Centre de cancérologie primaire afin de permettre la poursuite de la planification et de l’administration du traitement.
Discussion
Un modèle de collaboration entre deux centres de cancérologie a été développé et mis en œuvre avec succès afin de maintenir l’accès des patients aux services de radiothérapie durant la période de remplacement du seul appareil de simulation TDM dans un Centre régional de cancérologie.
Conclusion
La stratégie et le processus développés pourraient être utiles dans le cas de mise à niveau ou de remplacement d’équipements importants dans d’autres centres.}
}
@article{BISWAS202016,
title = {Exploration of gaps and challenges in managing burn injury at district and sub-district government health care facilities in Bangladesh},
journal = {Burns Open},
volume = {4},
number = {1},
pages = {16-21},
year = {2020},
issn = {2468-9122},
doi = {https://doi.org/10.1016/j.burnso.2019.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468912219300112},
author = {Animesh Biswas and Abu Sayeed Md. Abdullah and Toity Deave and Koustuv Dalal and Saidur Rahman Mashreky},
keywords = {Facility, Burn injury, Management, Bangladesh},
abstract = {Background
Burn injury is one of the leading cause of mortality and morbidity worldwide. In developing countries like Bangladesh, burn is one of the leading causes of illness, disabilities and deaths. More than 365,000 people are injured every year by electrical, thermal and other causes of burn injuries where 27,000 people needed hospital admission and over 5600 people died. Emergency management of burn at the facility level can reduce the severity of burn injuries and improve overall survival. The study has explored the health care providers’ views on gaps and challenges in management of burn injury at the facilities district and sub district health facilities in Bangladesh.
Methodology
A qualitative study was conducted during the period in July 2015. In-depth interviews (n = 19) were performed with the doctors and nurses working in the three district government hospitals and seven sub-district (upazila) government health facilities. Thematic analysis was performed on different themes.
Results
Health care providers mentioned that the people are coming to the facilities usually, hours after the incidence. Before visiting the facilities, the burn victims mostly seek treatment from the traditional healers or form village doctors (quack) or from the local pharmacy, over the counter. Family waited until they felt that the patient may not survive. It has identified that delaying in decision making and transferring the patient to the health facility are the key challenges identified by the doctors and nurses when they attended any burn patients in their facility. Moreover, use of different traditional infectious agent in burnt areas from their home make the burn surface more damage. While as, deficiency of adequate supplies, logistics and adequate trainings for the health workers in the facility create much more difficulties to treat a burn patient at primary or secondary health care centers.
Conclusion
Burn patients are maltreated in the community before coming to the healthcare facility in most of the cases. The community has misperceptions on burn management which delay the proper management in the facility. Readiness of the facility on the other hand is a big challenge. In order to consistent in burn care in Bangladesh, its equally important to build knowledge and awareness among the community on burn prevention and their role. Like this, readiness of the facilities in time will build confidence in community, thus in turns, will save thousands of lives from burn injury in Bangladesh.}
}
@article{WEGENER2020S162,
title = {Automated leukapheresis cryopreparation using fully-defined synthetic solutions},
journal = {Cytotherapy},
volume = {22},
number = {5, Supplement },
pages = {S162-S163},
year = {2020},
issn = {1465-3249},
doi = {https://doi.org/10.1016/j.jcyt.2020.03.340},
url = {https://www.sciencedirect.com/science/article/pii/S1465324920304047},
author = {C. Wegener and K. Thompson},
abstract = {Background & Aim
Leukapheresis products are commonly used as source material for cell and gene therapy products. To avoid risks associated with shipping/storing fresh products and to optimize manufacturing logistics, this starting material may be cryopreserved soon after collection. Cryopreparation, the process of preparing cells for cryopreservation, typically involves several manual steps including concentration/plasma depletion, optional washing/plasma removal, and formulation with cryoprotectant. In this study, an automated system was compared to manual processing for cryoprep of leukapheresis material using either autologous plasma (AP) or synthetic solution (SYN), then frozen in either vials or bags.
Methods, Results & Conclusion
Peripheral blood mononuclear cells (n=4) were collected from healthy donors, shipped at 4°C to the processing facility, and processed within 24 hours. Products were split, then processed manually via centrifugation in a test tube (MAN) or with a fully-automated prototype small-volume processing system (AUTO, Fresenius Kabi). Cells were concentrated and washed to <2e8 TNC/mL with either AP or SYN solution (2-8CELLsius, Protide Pharmaceuticals). Suspensions were then diluted 1:1 with a fully-defined synthetic cryomedia (2-8CELLsius + 10% DMSO, Protide Pharmaceuticals) to achieve a final concentration of 5% DMSO and <1e8 TNC/mL. The formulated cells were aliquoted into bags (20mL fill, AUTO samples) or vials (1mL fill, all samples) and frozen at ∼-1°C/min in a controlled rate freezer. Once frozen <-110°C, cells were immediately thawed in a 37°C bath. Samples were evaluated for pre-freeze and post-thaw cell enumeration and viability (CD45+/7AAD−). Hematology analyzer results showed no significant differences in TNC recovery between cryopreparation method used (101.2% [±8.5%] MAN vs 102.2% [±4.4%] AUTO), wash solution (101.2% [±5.6%] AP vs 102.4% [±6.4%] SYN), nor freezing format (104.2% [±3.3%] BAG vs 100.6% [±6.6%] VIAL). Similarly, post-thaw viability showed no significant difference between variables tested (84.4% [±7.1%] MAN vs 82.9% [±5.3%] AUTO vs 85.6% [±3.8%] AP vs 81.1% [±6.8%] SYN vs 80.2% [±5.3%] BAG vs 84.9% [±5.6%] VIAL). Leukapheresis cryoprep using a fully-automated system and synthetic wash solution results in comparable post-thaw cell recovery and viability to manual processing with autologous plasma.}
}
@article{BAILEY2020S31,
title = {Successful Drive-thru Point-of-Distribution Influenza Vaccination Program for Veterans Affairs Medical Center Employees},
journal = {American Journal of Infection Control},
volume = {48},
number = {8, Supplement },
pages = {S31},
year = {2020},
issn = {0196-6553},
doi = {https://doi.org/10.1016/j.ajic.2020.06.201},
url = {https://www.sciencedirect.com/science/article/pii/S0196655320305836},
author = {Lisa C. Bailey and Nancy R. Barrett and Monique Thorne and Florence M. Ford and Werns Elizabeth and George Psevdos},
abstract = {Background
The Advisory Committee on Immunization Practices recommends all healthcare personnel receive an annual influenza vaccination. There are multiple challenges in achieving this goal. During flu season 2017-18, a fixed-internal location was utilized for administration of employee influenza vaccination. This point-of-distribution (POD) event lasted 12 hours; 250 vaccinations were administered. Flu season 2018-19, a fixed-internal POD was conducted for 10 hours; 90 vaccinations were administered. Staff feedback noted time constraints and inconvenience in leaving unit/work area. We organized and executed a fixed-external Drive-Thru Employee Flu POD in fall 2019.
Methods
A 90-minute drive-thru Flu POD was accomplished from 7am-8:30am at the main employee Veterans Affairs (VA) Medical Center entrance. VA-Police directed traffic into two lanes; flu shot lane and non-flu shot lane which was determined at the checkpoint. Employees were directed to drive to one of ten tables staffed with 19 nurses and received vaccine while remaining in their vehicle. Necessary forms were collected for tracking. Employee safety was of paramount concern; weather, rain date, traffic control, location were all predetermined. Coordination with services included: VA-Police, Emergency Management, VA-Fire Department, Public Affairs, Logistics, Nursing, Pharmacy, Environmental Management, and Information Technology for advertising/promoting this event.
Results
On September 18, 2019, 290 employees received the flu vaccine over a 90-minute interval. Drive-thru flu POD yielded a rate of 322 doses per 100 minutes compared to only 15 administered per 100 minutes during flu POD 2018-19. This thoroughly planned event was convenient, safe, quick and efficient with no unintended consequences. The overall experience was welcomed as positive and “lots of fun.”
Conclusions
Our drive-thru POD event significantly improved time/vaccine ratio for employee flu vaccine administration. Our effective project management resulted in a well-organized, streamlined process and higher employee satisfaction. This innovative strategy can be utilized as an emergency-response vaccination/treatment plan for possible future emerging public infectious threats.}
}
@article{SONG202028,
title = {Machine Leaning Algorithm on Chemotherapeutic Drug Resistance Related Gene Classifier in Acute Myeloid Leukemia},
journal = {Blood},
volume = {136},
pages = {28-29},
year = {2020},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2020-142194},
url = {https://www.sciencedirect.com/science/article/pii/S000649711871080X},
author = {Yang Song and Yannan Jia and Guangji Zhang and Shuning Wei and Yan Li and Yimin Hu and Qishan Hao and Zhe Wang and Qiuyun Fang and Zheng Tian and Shangzhu Li and Min Wang and Jianxiang Wang and Yingchang Mi},
abstract = {Background: Acute myeloid leukemia (AML) is a heterogeneous disease in which 20-50% patients are resistant to chemotherapy. Relapsed/refractory (R/R) AML has a poor long-term prognosis resulting from chemotherapeutic drug resistance. However, the specific gene-drug pairs have been rarely reported. The purpose of our study was to explore an accurate algorithm for screening gene profiles classifier associated with chemotherapy drug sensitivity. Method: 43 AML patients from the Institute of Hematology and Blood Diseases Hospital were enrolled, including newly diagnosis (n=23) and R/R (n=20) AML between March 2019 to January 2020. We separated bone marrow cells (BMCs) of the 43 patients. Additionally, 24 therapeutic drugs panel (Figure 1) were selected and 7-concentration gradient were used to test drug sensitivity in vitro by HDS (High-throuphput Drug Sensitivity Analysis Strategy). Paired molecular data of RNA-seq and DNA methylation 850K CHIP implemented simultaneously. K-Means, an unsupervised algorithm, was applied to cluster all samples into two groups (Resistance/Sensitive group) according to IC50 and 100% PPC inhibition rate of each drug. We used a combination of different algorithms to build a proper gene classifier. The whole process was shown as Figure 2. The major objectives of the evaluating algorithm included F1 score, precision rate, recall rate and AUC. “pRRophetic”, a R package, was modified to specify target type as “AML” in aim to estimate IC50 of samples based on GDSC database. Furthermore, we cultured Ara-C resistant cell line of HL-60 in purpose of comparing relative gene expression with wide type (wt) by quantitative Real-time PCR (qPCR) to prove the selected gene signature. Result: The HDS data suggested that sensitivities of newly diagnosis AML to chemotherapeutic-drugs were highly variable. However, Newly Diagnosis Group was more sensitive to majority chemotherapeutic drugs in contrast to R/R AML (P<0.05). As heterogeneous drug response in vitro, we found K-means (k=2) was more reasonable algorithm, as compared to K-means (k=3) for grouping all samples. SVM of transcription data for each drug showed a significantly advantage over other algorithms (P<0.001) with the median F1 score was 0.805295 (0.710648-0.934641), median AUC was 0.818 (0.545-1), median precision rate was 0.75 (0.55-1), and median recall rate was 0.76(0.66-1). The screening feature genes from SVM also performed well on different models (SVM, RF, logistics regression, KNN, Decision Tree) of test set. The SVM mean F1 scores for each algotithm were as follows:0.7382, 0.6128, 0.6530, 0.6168,and 0.5956. It is worth mentioning that SVM equally applies to DMP analysis (P<0.001).We confirmed our algorithm by using Ara-C selected genes grounded by SVM and RF. The difference of estimated IC 50 between resistant group and sensitive group based on SVM (P=0.058) was better than RF (p=0.087) (Figure 3). Compared to newly diagnosis AML, R/R Group possessed 2134 upregulated genes and 1210 down-regulated genes in the aspect of RNA-seq data. Crosslinking analysis of RNA-seq and methylation data of the two group, 1 gene were described as up-regulated expression with hypo-methylation, and 39 genes was down-regulated expression with hyper-methylation. 8/39 genes are corresponded with SVM algorithm. Moreover, 4-gene-drug pairs, including FOXC1 for anthracyclines drug, IGFBP5 for Ara-C, VTRNA1-1 and TKTL1 for pan-drug, were investigated by overlapping TOP 5 genes for each drug of SVM algorithm and DEGs between R/R and newly diagnosis AML. High expression of four genes was identified as a risk factor for AML prognosis. The result of qPCR revealed that IGFBP5 is overexpression in Ara-C-resistant HL-60 than wt. Conclusion: We construct a model of K-Means and RFE-DEG/DMP-SVM, a validated and precise computational approach, for predicting drug sensitivity related genes in AML patients. Up-regulated expression with hypo-methylation genes may be signature genes for drug resistance. 4-gene-based classifier may make contributions to chemotherapeutic-drug resistance prediction and AML treatment decision-making. 
Disclosures
No relevant conflicts of interest to declare.}
}
@article{RIEDELL2019S174,
title = {Factors Influencing Prescribing Patterns and Patient Management Among US Centers Offering Commercial Axicabtagene Ciloleucel and Tisagenlecleucel for B-NHL},
journal = {Biology of Blood and Marrow Transplantation},
volume = {25},
number = {3, Supplement },
pages = {S174},
year = {2019},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2018.12.315},
url = {https://www.sciencedirect.com/science/article/pii/S1083879118311376},
author = {Peter A. Riedell and Richard T. Maziarz and Joseph McGuirk and Loretta J. Nastoupil and Olalekan Oluwole and Miguel-Angel Perales and David L. Porter and Michael R. Bishop},
abstract = {Axicabtagene ciloleucel (axi-cel) and tisagenlecleucel (tisa-cel) are both anti-CD19 chimeric antigen receptor (CAR) T-cell therapies indicated for the management (mgmt) of relapsed/refractory large B-cell non-Hodgkin lymphoma (B-NHL). Though two registrational phase 2 trials yielded promising results, comparison studies are lacking and long term data are not yet available. Given the approval of axi-cel in 10/2017 and tisa-cel in 5/2018, we conducted a survey in 7/2018 to better understand early prescribing patterns and mgmt strategies with these two commercial products in B-NHL. Surveys were issued to 26 US centers certified to prescribe both drugs, with 19 (73%) surveys returned. Of respondents, 26% took part in axi-cel trials, 26% in tisa-cel trials, 26% did not take part in either, and 21% took part in trials with both drugs. Tisa-cel was most frequently delivered in a hybrid setting (outpatient (outpt) chemotherapy and inpatient (inpt) CAR T infusion) in 42% of sites, 37% performed exclusively inpt treatment (tx), 11% outpt tx, and 11% used multiple tx strategies. Axi-cel was administered exclusively inpt in 47% of sites, 42% used a hybrid approach, and 11% used multiple tx strategies; however, no site employed entirely outpt axi-cel tx. There was significant variability in supportive care measures across sites. In grading toxicities, 32% of centers used Lee criteria, 32% CAR-T associated Toxicity (CARTOX) criteria, 21% center specific policies, and 16% company guidance. Similarly, toxicity mgmt varied greatly, where 42% of sites used center specific policies, 21% Lee criteria, 21% company guidance, and 16% CARTOX. In 68% of respondents, baseline patient (pt) factors impacted prescribing patterns. Tisa-cel was more likely to be considered in pts with advanced age/comorbidities or a history of central nervous system B-NHL/other neurologic conditions. In 84% of sites, product logistics influenced prescribing practice. The most frequently cited reasons were shorter production time favoring use of axi-cel followed by later onset of cytokine release syndrome favoring use of tisa-cel. Of respondents, the single strongest reason influencing tx decisions was drug toxicity profile (32%). The results of this survey highlight the significant heterogeneity in practice patterns that exist among sites offering both products in B-NHL. While numerous factors may impact prescribing patterns, toxicity profile and production time appear to heavily influence this decision. Given the limited available data and the relatively small number of pts treated with commercial drug at each site, open discussions about institutional experiences will be important in understanding the pros and cons of various approaches and products. Future efforts should focus on formulating consensus guidelines to standardize prescribing patterns and supportive care measures, with the goal of optimizing outcomes.}
}
@article{BARRAGAN20208443,
title = {Effects of postpartum acetylsalicylic acid on metabolic status, health, and production in lactating dairy cattle},
journal = {Journal of Dairy Science},
volume = {103},
number = {9},
pages = {8443-8452},
year = {2020},
issn = {0022-0302},
doi = {https://doi.org/10.3168/jds.2019-17966},
url = {https://www.sciencedirect.com/science/article/pii/S0022030220304756},
author = {A.A. Barragan and E. Hovingh and S. Bas and J. Lakritz and L. Byler and A. Ludwikowski and S. Takitch and J. Zug and S. Hann},
keywords = {parturition, acetylsalicylic acid, daily milk production, daily rumination},
abstract = {ABSTRACT
The transition period is one of the most challenging times for dairy cattle. Previous research suggests that treatment of postpartum cows with anti-inflammatory drugs may decrease pain and inflammation, enhancing cow welfare and performance during this challenging period. However, these strategies involve numerous time-consuming interventions, which require extra labor and do not fit modern farm logistics. The objective of this experiment was to assess the effects of acetylsalicylic acid (ASA) every 24 h for 2 d after calving on (1) daily milk yield, daily milk conductivity, and daily rumination during the first 60 days in milk (DIM), and 305-d mature-equivalent milk, milk fat, and milk protein yields, (2) body condition score, β-hydroxybutyrate (BHB), and haptoglobin, and (3) incidence of clinical diseases during the first 60 DIM. Dairy cows (n = 246) from a dairy farm located in Pennsylvania were enrolled in this experiment. Cows were blocked by parity and assigned randomly to 1 of 2 treatments: (1) ASA (n = 121), in which cows received 2 treatments with ASA (200 mg/kg; 4 boluses), the first within 12 h after parturition and the second 24 h later; or (2) untreated (UNT; n = 125), in which cows remained untreated. Blood samples were collected at 30 ± 6 h, 7 ± 3 d, and 14 ± 3 d after calving to measure BHB and haptoglobin concentrations. Body condition score was assessed at enrollment, 7 ± 3 DIM, 14 ± 3 DIM, and 50 ± 10 DIM. Furthermore, incidences of diseases, daily rumination, daily milk yield, and daily milk conductivity during the first 60 DIM and 305-d mature-equivalent milk, milk fat, and milk protein yields were collected from on-farm computer records. The data were analyzed using mixed multiple linear and logistic regression models as a randomized complete block design. Multiparous cows treated with ASA produced 1.64 kg/d more milk compared with multiparous cows that remained untreated (ASA = 41.66 ± 0.88 kg/d; UNT = 40.02 ± 0.81 kg/d) during the first 60 DIM. There was no difference in daily milk conductivity and rumination between treatments. Cows treated with ASA had lower concentration of BHB (ASA = 1.16 ± 0.64 mmol/L; UNT = 1.23 ± 0.80 mmol/L) during the first 14 ± 3 DIM and had higher body condition score within the first 50 ± 10 DIM compared with cows that remained UNT. There were no differences in circulating concentrations of haptoglobin between treatments. These results support previous findings showing that the use of anti-inflammatory drugs after calving may increase milk production and affect the metabolic status of dairy cows.}
}
@article{MENEGHEL2020S131,
title = {Ultra-low shipping temperatures for cell therapies},
journal = {Cytotherapy},
volume = {22},
number = {5, Supplement },
pages = {S131},
year = {2020},
issn = {1465-3249},
doi = {https://doi.org/10.1016/j.jcyt.2020.03.255},
url = {https://www.sciencedirect.com/science/article/pii/S1465324920303194},
author = {J. Meneghel and P. Kilbride and W. Shingleton and J. Morris},
abstract = {Background & Aim
Cell therapies require a cold chain delivery as part of the production and delivery process. Whether following an autologous or allogeneic route, a common workflow for manufacturing cell therapies consists of collecting a cell sample from a healthy donor or a patient, cryopreserving and shipping it to a manufacturing site for engineering purposes, cryopreserving the resulting therapeutic product and shipping it to a clinical site for thaw and patient administration. Cryopreservation enables extended shelf-life of cell products and facilitates the logistics. Cryogenic shipping has typically been undertaken using a dry shipper, a vessel containing some liquid nitrogen (LN2) to ensure that the product being shipped remains below approximately -150°C. The precise limits for safe transportation are however poorly understood, with variations methods and temperatures reported, between transport in liquid nitrogen (-196°C), to transport on dry ice (-80°C). This study examined the impact of transferring samples from stable ultra-low temperatures and storing for 5 and 10 days at -120°C, -100°C, -80°C, and -60°C before transfer back to ultra-low temperature storage to mimic the effect of shipping at lower temperatures.
Methods, Results & Conclusion
Two common cell lines were tested, Jurkats (immortalized human t cell line), and HepG2s (hepatocarcinoma). It was found that while -120°C transfer has no impact on post-thaw outcome, temporary storage temperatures above -120°C resulted in reduced post-thaw function and viable cell number. The reduction in post-thaw outcome was lower after 10 days’ storage compared with 5 days’ storage at all temperatures >-120°C, with the higher the temperature the greater the reduction in post-thaw function and viable cell number. For the transport of cellular therapies, we conclude that the temperature must be maintained at or below -120°C for optimal post-thaw outcome when cryopreserving with a DMSO based cryoprotectant.}
}
@article{BENTSEN2019491,
title = {Dynamic sustainability assessment of heat and electricity production based on agricultural crop residues in Denmark},
journal = {Journal of Cleaner Production},
volume = {213},
pages = {491-507},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.12.194},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618339106},
author = {Niclas Scott Bentsen and Johannes Ravn Jørgensen and Inge Stupak and Uffe Jørgensen and Arezoo Taghizadeh-Toosi},
keywords = {Agricultural residues, Bioenergy, Global bioenergy partnership (GBEP), Heat and power production, Sustainability},
abstract = {Bioenergy use is expected to increase significantly to support energy strategies and to meet climate targets in a large number of countries. Agricultural residues as an energy resource have attracted a lot of interest, as the use of residue biomass is perceived as beneficial to mitigate greenhouse gas emission and to be less harmful to the environment than other biomass resources. Here we present a holistic sustainability assessment of the use of cereal straw for heat and electricity production in Denmark. The assessment applies a methodology and framework developed by the Global Bioenergy Partnership. Sixteen sustainability indicators within the three pillars of sustainability (environmental, social and economic) are quantified or assessed qualitatively together with their development over time from year 2000–2014/2015. The assessment points to a number of benefits of straw based bioenergy as reductions in GHG emissions, income generation and jobs for a rural population, reduced use of fossil fuels and increased diversity of the national energy supply. These benefits come at a risk of soil degradation and soil organic matter mining, of increased emissions of non-greenhouse gases. The assessment shows that land allocation to straw harvest for energy has increased over time together with land productivity. The diversity of the national energy supply has increased over time just as the infrastructure required to support straw to energy supply chains. Ecologically there is a potential for further use of agricultural residue biomass for energy. To realise the potential sustainably, attention should be put on developing guidelines or regulation on biomass harvest, on avoidance of environmental burden shifting, on logistics and efficient conversion to energy services, and on maintaining a suitable organisational and policy framework. The framework of the Global Bioenergy Partnership proved to be a versatile tool for the assessment of bioenergy sustainability, also in a developed country. It is, however, relying on specific data sources and formats, which in many cases are not readily available.}
}
@article{DUAN2020193,
title = {Relationship between high-sensitivity C-reactive protein and early neurological deterioration in stroke patients with and without atrial fibrillation},
journal = {Heart & Lung},
volume = {49},
number = {2},
pages = {193-197},
year = {2020},
issn = {0147-9563},
doi = {https://doi.org/10.1016/j.hrtlng.2019.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0147956319305254},
author = {Zuowei Duan and Wei Guo and Tieyu Tang and Lihong Tao and Kaizheng Gong and Xinjiang Zhang},
keywords = {Stroke, C-reactive protein, Early neurological deterioration, NIHSS, Atrial fibrillation},
abstract = {Background and purpose
The association of high-sensitivity C-reactive protein (hsCRP) with early neurological deterioration (END) is unclear, especially in stroke patients with atrial fibrillation (AF). In this study, we aimed to assess the association of baseline hsCRP levels with END in acute ischemic stroke with and without AF.
Methods
Consecutive acute ischemic stroke patients prospectively recruited from the Affiliated Hospital of Yangzhou University were analyzed and divided into two groups: AF related stroke (AF-S) and non-AF related stroke (Non-AF-S) groups. Plasma hsCRP levels on admission were categorized into three risk groups: low (<1.0 mg/L), average (1–3 mg/L) and high (>3 mg/L).
Results
A total of 655 consecutive patients diagnosed acute ischemic stroke were prospectively registered from our department in 2015–2018, which included 168 AF-S and 487 Non-AF-S cases. After standard therapy, 62 AF-S and 155 Non-AF-S cases developed END within 72 h of hospitalization. In AF-S cases, statistical differences between END and Non-END patients were found in age, gender, baseline National Institute of Health Stroke Scale (NIHSS) score, fasting blood glucose, responsible artery occlusion, CHA2DS2-VASc score and hsCRP level (p < 0.05). When variates showing p ≤ 0.1 in univariate analysis were adjusted, logistics regression analysis revealed following indexes as independent risk factors for END in AF-S patients: female (OR = 2.396, 95%CI:1.062–5.405, P = 0.035), fasting blood glucose (OR = 1.192, 95%CI:1.026–1.385, P = 0.022), responsible artery occlusion (OR = 3.589, 95%CI 1.425–9.036, P = 0.007), and high risk hsCRP (OR = 2.780, 95%CI 1.067–7.240, P = 0.036). In the Non-AF group, any level of hsCRP was not independently related to END after adjustment for age, sex, diabetes mellitus, smoking, baseline NIHSS, lesion size and responsible artery occlusion.
Conclusion
High hsCRP level was independently correlated with END in patients with AF-S.}
}
@article{ASSAL2019S408,
title = {Pre-Apheresis Peripheral Blood CD34+ Cell Count Obviates Need for Pre-Emptive Plerixafor in Half of Patients Undergoing Stem Cell Mobilization.},
journal = {Biology of Blood and Marrow Transplantation},
volume = {25},
number = {3, Supplement },
pages = {S408},
year = {2019},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2018.12.826},
url = {https://www.sciencedirect.com/science/article/pii/S1083879118317592},
author = {Amer Assal and Nicole Howard and Alexandra Kaiser and Samantha Prinzing and Corinne Shamehdi and Shanlong Y Jiang and Zelos Zhu and Codruta Chiuzan and Christian A Gordillo and Joseph Schwartz and Ran Reshef and Markus Y Mapara},
abstract = {Success and safety of autologous stem cell transplant (ASCT) is contingent on collecting enough CD34+ cells. CXCR4 antagonists (plerixafor) can increase the success and efficiency of stem cell mobilization. Plerixafor has been increasingly used but concerns remain about its cost and logistics of administration. We report our experience with plerixafor administration based on pre-apheresis peripheral blood (PB) CD34+ cell counts. We retrospectively reviewed consecutive patients who underwent stem cell mobilization and transplant at our center between 07/2012 and 06/2018. Patients with incomplete records were excluded. PB CD34+ cell counts were obtained daily starting the day before apheresis. Target yield was 5 × 10^6 CD34+ cells/kg with a minimum of 2 × 10^6 CD34+ cells/kg being acceptable. Lymphoma patients were mobilized primarily after chemotherapy whereas patients with plasma cell disorders were mobilized with steady state G-CSF. Plerixafor was pre-emptively given when PB CD34+ cell count was ≤20 cells/uL. Repeat plerixafor dosing was per provider preference. Median [IQR] is reported, and t-tests or Wilcoxon Rank-Sum tests were used for continuous variables whereas n (%) is reported, and Chi-Square/Fisher Exact tests were used for categorical variables. A total of 132 patients were included. 50.8% were given plerixafor pre-emptively (Pre-emptive group, n=67) and 49.2% were not (non-pre-emptive group, n=65). 13 patients in the non-pre-emptive group subsequently received plerixafor. Median pre-apheresis PB CD34+ cell count (cell/uL) was 11.22 in the pre-emptive group (before plerixafor administration) and 42.99 in the non-pre-emptive group. Overall, 11 patients (8.3%) required a second mobilization and 40 patients (30.3%) successfully reached target yield after 1 apheresis session without plerixafor use. No difference was noted between both groups in age (p=0.45), gender (p=0.16), mobilization method (p=0.063), primary diagnosis (p=0.571), mobilization attempts (p=0.53), number of apheresis sessions (p=0.72) and CD34+ cell yield (p=0.70). Total number of plerixafor doses was significantly lower in the non-pre-emptive group (p<0.001). Median time to neutrophil (12.1 vs 11.8 days, p=0.38) and platelet (20 vs 19.8 days, p=0.70) engraftment was similar. No difference in PFS was noted (fig 1, p=0.99). In summary, dosing plerixafor based on pre-apheresis PB CD34+ cell counts allows for a high success rate on the first mobilization attempt while minimizing plerixafor use.}
}
@article{KANDASAMY2021144,
title = {Barriers to, and Facilitators of, Lifestyle Changes to Prevent Gestational Diabetes: An Interpretive Description of South Asian Women and Health-Care Providers Living and Working in Southern Ontario, Canada},
journal = {Canadian Journal of Diabetes},
volume = {45},
number = {2},
pages = {144-154},
year = {2021},
issn = {1499-2671},
doi = {https://doi.org/10.1016/j.jcjd.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S149926712030201X},
author = {Sujane Kandasamy and Linda Nguyen and Dipika Desai and Sonia S. Anand and Diana Sherifali and Russell J. {de Souza}},
keywords = {gestational diabetes, healthy active living, interpretive description, maternal health, diabète gestationnel, vie saine et active, description interprétative, santé maternelle},
abstract = {Objectives
People of South Asian ancestry are the fastest growing non-Caucasian ethnic group in Canada and are at high risk for developing type 2 diabetes and coronary heart disease. Pregnant South Asian women have a 2-fold increased risk of developing gestational diabetes, which increases their risk of type 2 diabetes and coronary heart disease. The specific objectives of this study were to explore the perceptions of health behaviours (diet and physical activity) during pregnancy in the South Asian community.
Methods
We used interpretive description to further understand the cultural and contextual factors that influence the knowledge, attitudes and practices of diet and physical activity of South Asian women of childbearing age and those who provide health care to this group.
Results
Two major themes that emerged from the perspectives of 10 South Asian pregnant women included: (1) importance of considering an individual’s locus of control; and (2) support (emotional and information exchange) from family, friends and health-care providers. Two major themes identified by the 11 health-care providers were: (1) cultural awareness in caring for South Asian women during pregnancy; and (2) clinic management, logistics and resources. A common theme for both South Asian pregnant women and health-care providers was the importance of considering the cultural landscape in relation to how knowledge is obtained, shared and valued.
Conclusion
A better understanding of these cultural underpinnings may support the development of interventions tailored for pregnant South Asian women and their health-care providers.
Résumé
Objectifs
Les personnes d’ascendance sud-asiatique appartiennent au groupe ethnique non caucasien, qui connaît la croissance la plus rapide, et sont exposées à un risque élevé de diabète de type 2 et de coronaropathie. Les femmes sud-asiatiques enceintes ont un risque 2 fois plus élevé de diabète gestationnel, qui fait augmenter leur risque de diabète de type 2 et de coronaropathie. Les objectifs précis de la présente étude étaient d’examiner les perceptions relatives aux comportements liés à la santé (régime alimentaire et activité physique) durant la grossesse dans la communauté sud-asiatique.
Méthodes
Nous avons utilisé la description interprétative pour mieux comprendre les facteurs culturels et contextuels qui influencent les connaissances, les attitudes et les pratiques en matière de régime alimentaire et d’activité physique des femmes sud-asiatiques en âge de procréer et des personnes qui fournissent les soins de santé à ce groupe.
Résultats
Les 2 principaux thèmes qui découlaient des perspectives des 10 femmes sud-asiatiques enceintes sont : (1) l’importance de tenir compte du lieu de maîtrise de l’individu; (2) le soutien (émotionnel et échange d’informations) de la famille, des amis et des prestataires de soins de santé. Les 2 principaux thèmes mentionnés par les 11 prestataires de soins de santé étaient : (1) les connaissances culturelles en matière de soins aux femmes sud-asiatiques durant la grossesse; (2) la prise en charge clinique, la logistique et les ressources. Le thème commun aux femmes sud-asiatiques enceintes et aux prestataires de soins de santé était l’importance de considérer le contexte culturel en ce qui concerne la façon dont les connaissances sont obtenues, partagées et valorisées.
Conclusion
Une meilleure compréhension de ces fondements culturels peut contribuer à l’élaboration d’interventions adaptées aux femmes sud-asiatiques enceintes et à leurs prestataires de soins de santé.}
}
@article{NEGUSSIE20197248,
title = {Reliability of breeding values for feed intake and feed efficiency traits in dairy cattle: When dry matter intake recordings are sparse under different scenarios},
journal = {Journal of Dairy Science},
volume = {102},
number = {8},
pages = {7248-7262},
year = {2019},
issn = {0022-0302},
doi = {https://doi.org/10.3168/jds.2018-16020},
url = {https://www.sciencedirect.com/science/article/pii/S002203021930459X},
author = {E. Negussie and T. Mehtiö and P. Mäntysaari and P. Løvendahl and E.A. Mäntysaari and M.H. Lidauer},
keywords = {dairy cattle, feed efficiency, dry matter intake, reliability, genetic parameter},
abstract = {ABSTRACT
Currently, routine recordings of dry matter intake (DMI) in commercial herds are practically nonexistent. Recording DMI from commercial herds is a prerequisite for the inclusion of feed efficiency (FE) traits in dairy cattle breeding goals. To develop future on-farm phenotyping strategies, recording strategies that are low cost and less demanding logistically and that give relatively accurate estimates of the animal's genetic merit are therefore needed. The objectives of this study were (1) to estimate genetic parameters for daily DMI and FE traits and use the estimated parameters to simulate daily DMI phenotypes under different DMI recording scenarios (SCN) and (2) to use the simulated data to estimate for different scenarios the associated reliability of estimated breeding value and accuracies of genomic prediction for varying sizes of reference populations. Five on-farm daily DMI recording scenarios were simulated: once weekly (SCN1), once monthly (SCN2), every 2 mo (SCN3), every 3 mo (SCN4), and every 4 mo (SCN5). To estimate reliability of estimated breeding values, DMI and FE observations and true breeding values were simulated based on variance components estimated for daily observations of Nordic Red cows. To emulate realistic on-farm recording, 5 data set replicates, each with 36,037 DMI and FE records, were simulated for real pedigree and data structure of 789 Holstein cows. Observations for the 5 DMI recording scenarios were generated by discarding data in a step-wise manner from the full simulated data per the scenario's definitions. For each of these scenarios, reliabilities were calculated as correlation between the true and estimated breeding values. Variance components and genetic parameters were estimated for daily DMI, residual feed intake (RFI), and energy conversion efficiency (ECE) fitting the random regression model. Data for variance components were from 227 primiparous Nordic Red dairy cows covering 8 to 280 d in milk. Lactation-wise heritability for DMI, RFI, and ECE was 0.33, 0.12, and 0.32, respectively, and daily heritability estimates during lactation ranged from 0.18 to 0.45, 0.08 to 0.32, and 0.08 to 0.45 for DMI, RFI, and ECE, respectively. Genetic correlations for DMI between different stages of lactation ranged from −0.50 to 0.99. The comparison of different on-farm DMI recording scenarios indicated that adopting a less-frequent recording scenario (SCN3) gave a similar level of accuracy as SCN1 when 17 more daughters are recorded per sire over the 46 needed for SCN1. Such a strategy is less demanding logistically and is low cost because fewer observations need to be collected per animal. The accuracy of genomic predictions associated with the 5 recording scenarios indicated that setting up a relatively larger reference population and adopting a less-frequent DMI sampling scenario (e.g., SCN3) is promising. When the same reference population size was considered, the genomic prediction accuracy of SCN3 was only 5.0 to 7.0 percentage points lower than that for the most expensive DMI recording strategy (SCN1). We concluded that DMI recording strategies that are sparse in terms of records per cow but with slightly more cows recorded per sire are advantageous both in genomic selection and in traditional progeny testing schemes when accuracy, logistics, and cost implications are considered.}
}
@article{YOOST2021274,
title = {88. Parent and Provider Views of Using Pharmacies for HPV Vaccination in Adolescents},
journal = {Journal of Pediatric and Adolescent Gynecology},
volume = {34},
number = {2},
pages = {274-275},
year = {2021},
issn = {1083-3188},
doi = {https://doi.org/10.1016/j.jpag.2021.02.092},
url = {https://www.sciencedirect.com/science/article/pii/S1083318821001169},
author = {Jennie Yoost and Niccia Ditrapano and Jamila Ranavaya and Katherine Redmond},
abstract = {Background
West Virginia (WV) has high rates of HPV-related cancers and lagging rates of HPV vaccination. Recent legislation in WV allows pharmacists to administer the HPV vaccine to adolescents if prescribed by a provider. The purpose of this study was to assess parent and provider views about using pharmacies to provide the HPV vaccine to adolescents.
Methods
Pediatric, Family Practice and OBGYN physicians within a single institution that serves rural counties were surveyed regarding HPV vaccination practice, and awareness of using pharmacies for provision. Teaching sessions with providers then reviewed the legislation and the logistics of prescribing the vaccine through a pharmacy. Six months later the same departments were surveyed regarding HPV vaccination practice, pharmacy provision, and perspectives about this pharmacy service. Parents of adolescents age 11-18 were also surveyed. Adolescent vaccination status, gender, and WV county of residence were collected, along with Likert scale questions about usefulness of pharmacy access for vaccination. Provider responses were compared before and after the teaching intervention after six months. Parental responses were compared by adolescent gender and rural/urban county designation. Proportions were compared using Chi square statistics. Institutional review board approval was obtained.
Results
Seventy one physicians completed the initial survey, and 45 completed the six month assessment. Only 22.5% were aware of the pharmacy legislation initially, and 64.4% were aware at six months (p= <.001). Most providers felt that pharmacy access would be beneficial for rural patients initially and at 6 months (69% vs 78%, p=0.31). Providers also felt they would be “Likely” or “Very Likely” to prescribe the vaccine to adolescents through a pharmacy, and this did not change significantly at 6 months (71.8% vs 73.3%, p=0.86). However, at 6 months only 2 providers (both OBGYN) actually reported prescribing the vaccine this way. 121 parents completed the survey, which represented 196 adolescents age 11-18. HPV vaccine completion was not affected by rural/urban county designation, but overall males were less likely to have completed the vaccine (Figure 1). Rural parents lived closer to pharmacies than their primary care providers (Figure 2), but only 16 (13.2%) parents were aware of pharmacy access for the HPV vaccine. Of parents whose adolescents had started or completed the vaccine series, 78.1% felt pharmacy access would have been “Very beneficial”, and this did not vary by rural/urban designation.
Conclusions
Pharmacy provision of HPV vaccination is under- utilized. Both parents and physicians had favorable views on using pharmacies for adolescent HPV vaccination series completion.}
}
@article{SHAH2019S63,
title = {Clinical Results of a First-in-Human Phase 1 Study of Point-of-Care Manufactured Bispecific Anti-CD19, Anti-CD20 Chimeric Antigen Receptor Modified T (CAR-20.19-T) Cells for Relapsed, Refractory, Non-Hodgkin Lymphoma (NHL)},
journal = {Biology of Blood and Marrow Transplantation},
volume = {25},
number = {3, Supplement },
pages = {S63-S64},
year = {2019},
issn = {1083-8791},
doi = {https://doi.org/10.1016/j.bbmt.2018.12.146},
url = {https://www.sciencedirect.com/science/article/pii/S1083879118309686},
author = {Nirav N Shah and Fenlu Zhu and Carolyn Keever-Taylor and Dina Schneider and Winfred Kruger and Andrew Worden and Mehdi Hamadani and Timothy S. Fenske and Bryon D. Johnson and Boro Dropulic and Rimas Orentas and Parameswaran Hari},
abstract = {Background
CAR-T cell therapy against the CD19 antigen is a breakthrough treatment for patients (pts) with relapsed/refractory (R/R) B-cell NHL. Despite impressive outcomes, non-response and relapse with CD19 negative disease remains a clinical challenge. Through dual B-cell antigen targeting of CD20 and CD19, with a first-in-human bispecific CAR-T cell (CAR-20.19-T), we hope to improve response rates while limiting relapses due to target antigen loss. To optimize production and eliminate third party shipping logistics we utilized point of care automated manufacturing using the CliniMACS Prodigy, a compact GMP compliant tabletop device.
Methods
Phase 1 dose escalation + expansion trial (NCT03019055) to demonstrate feasibility of point of care manufacturing and safety of a bispecific 41BB/CD3z CAR-20.19-T cell for adults with R/R B-cell NHL. Feasibility goal was >75% successful production rate. Safety was assessed by incidence of dose limiting toxicities (DLTs) within 28 days post-infusion. Dose was escalated in a 3+3 fashion with a starting dose of 2.5 × 10^5 cells/kg and a target cell dose of 2.5 × 10^6 cells/kg. CAR-T manufacturing set at 14 days for all pts. All pts received lymphodepletion with fludarabine 30 mg/m2 × 3 days and cyclophosphamide 500 mg/m2 × 1 day. Clinically appropriate pts received fresh CAR-T cell infusion while others received CAR-T cells after cryopreservation.
Results
8 pts have received treatment and completed their DLT monitoring period: 3 pts at 2.5 × 10^5 cells/kg, 3 pts at 7.5 × 10^5 cells/kg, and 2 pts at 2.5 × 10^6 cells/kg. 4 pts had MCL, 2 pts had DLBCL, and 2 pts had CLL (Figure 1). CAR-T production reached target dose in all pts indicating 100% feasibility. Five pts received fresh CAR-T cells and 3 pts received CAR-T cells after cryopreservation. To date there are no DLTs to report. No patient experienced grade 3-4 cytokine release syndrome (CRS) or neurotoxicity (NTX). 3 pts had Grade 2 CRS and 1 patient had Grade 2 NTX. Median time to CRS was Day +9 post-infusion and no patient required ICU level care. Day 28 responses (Figure 1) are as follows: 4/8 pts complete response (CR) including both at the highest dose level, 2/6 pts partial response (PR), and 2/6 pts had progressive disease (PD). CAR-T cell persistence up to day 90 is presented in Figure 2. All PD pts underwent repeat biopsy, and all retained either CD19 or CD20 positivity. Additional pts are being enrolled at 2.5 × 10^6 cells/kg dose.
Conclusions
Point of care manufacturing via CliniMACS Prodigy and therapy with bispecific CAR-20.19-T cells is feasible and safe for pts with R/R B-cell NHL. Down-regulation of target antigens was not identified as a mechanism of CAR-T failure in this cohort. With no DLTs to date and 4/8 heavily pre-treated pts achieving CR at day +28 with longest CR >1 year, this approach to CAR-T production and dual B-cell targeting merits further investigation.}
}
@article{BRUGGENWIRTH2020100092,
title = {Extended hypothermic oxygenated machine perfusion enables ex situ preservation of porcine livers for up to 24 hours},
journal = {JHEP Reports},
volume = {2},
number = {2},
pages = {100092},
year = {2020},
issn = {2589-5559},
doi = {https://doi.org/10.1016/j.jhepr.2020.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2589555920300264},
author = {Isabel M.A. Brüggenwirth and Otto B. {van Leeuwen} and Yvonne {de Vries} and Silke B. Bodewes and Jelle Adelmeijer and Janneke Wiersema-Buist and Ton Lisman and Paulo N. Martins and Vincent E. {de Meijer} and Robert J. Porte},
keywords = {hypothermic machine perfusion, liver preservation, extended preservation, donation after circulatory death},
abstract = {Background & Aims
End-ischemic hypothermic oxygenated machine perfusion (HOPE) of the donor liver for 1–2 h mitigates ischemia-reperfusion injury during subsequent liver transplantation. Extended preservation time may be preferred to facilitate difficult recipient hepatectomy or to optimize logistics. We therefore investigated whether end-ischemic dual HOPE (DHOPE) could extend preservation time for up to 24 h using a porcine liver reperfusion model.
Methods
Following 30 min warm ischemia, porcine livers were subjected to 2 h static cold storage (SCS), followed by 2 h, 6 h, or 24 h DHOPE (n = 6 per group). Subsequent normothermic reperfusion was performed for 4 h using autologous blood. Two livers preserved by 24 h SCS served as additional controls. A proof of principle confirmation was carried out in 2 discarded human livers subjected to extended DHOPE. Hepatocellular and cholangiocyte injury and function were assessed. Oxidative stress levels and histology were compared between groups.
Results
Perfusion flows remained stable during DHOPE, regardless of duration. After normothermic reperfusion, livers perfused for 24 h by DHOPE had similar lactate clearance, blood pH, glucose, and alanine aminotransferase levels, and biliary pH, bicarbonate, and LDH levels, as livers perfused for 2 h and 6 h. Levels of malondialdehyde and high-mobility group box 1 in serum and liver parenchyma were similar for all groups. Histological analysis of bile ducts and liver parenchyma revealed no differences between the groups. Extended DHOPE in discarded human livers preserved hepatocellular and cholangiocyte function and histology after reperfusion. In contrast, livers preserved by 24 h SCS were non-functioning.
Conclusion
Extended end-ischemic DHOPE enabled successful preservation of porcine and discarded human donor livers for up to 24 h. Extended DHOPE enables safe extension of preservation time, which may facilitate allocation and transplantation from a logistical perspective, and further expand the donor pool.
Lay summary
It has been suggested that preserving liver grafts with a technique called (dual) hypothermic oxygenated machine perfusion ([D]HOPE) leads to better outcomes after transplantation than if livers are stored on ice, especially if an organ is of lesser quality. In this study, we showed that DHOPE could be used to preserve liver grafts for up to 24 h. This extended procedure could be used globally to facilitate transplantation and expand the donor pool.}
}
@article{NWAOZURU2020S12,
title = {An innovation bootcamp model to develop HIV self-testing social enterprise among young people in Nigeria: a youth participatory design approach},
journal = {The Lancet Global Health},
volume = {8},
pages = {S12},
year = {2020},
note = {CUGH 11th annual conference},
issn = {2214-109X},
doi = {https://doi.org/10.1016/S2214-109X(20)30153-4},
url = {https://www.sciencedirect.com/science/article/pii/S2214109X20301534},
author = {Ucheoma Nwaozuru and Titilola Gbajabiamila and Chisom Obiezu-Umeh and Florida Uzoaru and Stacey Mason and Kadija Tahlil and David Oladele and Adesola Musa and Ifeoma Idigbe and Collins Airhihenbuwa and Oliver Ezechi and Joseph Tucker and Juliet Iwelunmor},
abstract = {Background
There is a critical gap in the uptake of HIV testing among young people in sub-Saharan Africa. In Nigeria, only a quarter of young people aged 14–24 years have ever tested for HIV. Recent evidence suggests that HIV self-testing (HIVST) may play a role in addressing gaps in HIV testing coverage and serve as an entry point for HIV prevention services. However, there is limited information on strategies that may increase the uptake of HIV testing among young people. Current strategies rarely include young people in the design stages, which often results to poor adoption of HIV interventions. We aimed to address this gap with the development of an innovation bootcamp for participants aged 14–24 years to generate interventions to promote HIVST among young people in Nigeria.
Methods
The innovation bootcamp was a 4-week accelerated training programme to build entrepreneurial and research capacities among young people to develop HIV self-testing social enterprise. The training programme consisted of social enterprise and research development modules. At the completion of the bootcamp, we also examined participants' perspectives of the programme using surveys.
Findings
Between May 6 and May 30, 2019, 20 people participated in the innovation bootcamp in Lagos State, Nigeria; 13 (65%) were male and age range was 22–24 years. The innovation bootcamp generated five youth-participatory HIVST social enterprises. Two of the social enterprise focused on repacking HIVST kits to increase their appeal among young people, one idea focused on leveraging community engagement platforms (vocational skills training and youth community events) to promote HIVST, and another social enterprise seeks to use a reward-referral system to promote HIVST in young people. Participants' survey responses suggest that the innovation bootcamp fostered an environment for young people to connect with their peers to generate ideas and solutions. The bootcamp also provided opportunities for skills development such as logistics management and research (protocol writing, data collection, and needs assessment) skills.
Interpretation
The innovation bootcamp model can leverage the resourcefulness, capabilities, and resilience of youth to generate youth-centred and youth-sensitive interventions to promote HIV testing. The innovation bootcamp led to the development of five youth-centred and participatory interventions to promote uptake of HIV self-testing among young people in Nigeria.
Funding
Eunice Kennedy Shriver National Institute of Child Health and Human Development Grant number: 1UG3HD096929 and NIAID K24AI143471}
}
@incollection{SHARMA2020257,
title = {Chapter 9 - Internet of Things: the new Rx for pharmaceutical manufacturing and supply chains},
editor = {Valentina Emilia Balas and Vijender Kumar Solanki and Raghvendra Kumar},
booktitle = {An Industrial IoT Approach for Pharmaceutical Industry Growth},
publisher = {Academic Press},
pages = {257-288},
year = {2020},
isbn = {978-0-12-821326-1},
doi = {https://doi.org/10.1016/B978-0-12-821326-1.00010-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128213261000103},
author = {Deepak Kumar Sharma and Prachi Gupta and  Priety},
keywords = {Warehousing, supply chains, radio-frequency identification (RFID), smart labels, bidirectional communication, pharmaceuticals packaging, sensors, smart warehouses, real-time visibility},
abstract = {As the demand for multiple healthcare and medical services has risen, the traditional pharma industry has been greatly disrupted, and supply shortages and insufficiency of medicines have become bottlenecks that have limited its growth. Because the Internet of Things (IoT) has clear benefits in obtaining, processing, and implementing data, its deployment in the pharmaceutical sector can help patients by providing them with reduced cost, but also better quality medicines in the shortest time possible. Warehousing is a critical component of pharmaceutical manufacturing. The shortage of specific medicines can have severe implications, while overstocking leads to a waste of products and greater cost of holding inventories. By monitoring products in the warehouse and making optimal use of operators and transportation facilities, smart warehouses can improve real-time visibility in operations. In smart warehouses, sensors collect data on shipment movements—from the warehouses, to allocation and production planning—and help to analyze them further. Data are further collected by the incorporated environmental sensors in temperature-controlled areas of the facility to track the environmental conditions of the products in real time, resulting in lower product expiry rates and degradation due to adverse temperature and environmental conditions. Optimization of the flow of processing resources is necessary to increase operational productivity in warehouses. The IoT helps to achieve this goal through the use of sensors to carry products, which directly relay consumer location information, stock, and mismatches to the handheld device and/or dashboard of the warehouse manager. The device uses sensor information to simulate a 3D view in real time. Radio-frequency identification (RFID) tags on material-handling equipment in warehouses can be used to track asset locations and movements. Several logistics companies have also attached RFID tags to shipping crates that transport highly sensitive medical drugs. Using smart labels, a small, single product can also be tracked, allowing companies to monitor the product instead of the shipping container. This makes it possible to track each handshake in the supply chain, from manufacturing to dispensing, resulting in a complete digital footprint. There are multiple IoT technologies that can aid in pharmaceuticals packaging, to ensure product quality. These include bidirectional communication, tracking, and status display mechanisms. Drug inventories’ movement can be tracked at every possible point, helping the supply chain sector to reduce costs. However, to fully draw on the promise of the IoT and reap these opportunities across their value chain, pharmaceutical companies need to first invest in a responsive IoT network with the requisite capacity for handling heavy-duty needs and so take full advantage of the opportunities that the IoT has to offer and profit from these advantages. As safety is essential, companies also need to be ready to invest in security solutions based on IoTs. When it is important to communicate with existing systems, it can also become difficult to work with different vendors and to maintain common terminology and standards. In this chapter, we introduce the IoT technologies that can be used in pharmaceutical manufacturing and supply chains to overcome the existing challenges in the industry. Furthermore, we also present open challenges with regards to the implementation of these technologies and the scope for future work in the field, allowing readers to understand the need to implement IoT solutions, but also realize the difficulties in integrating them with the current architecture.}
}
@article{CLAVERIA2019389,
title = {Understanding truck driver behavior with respect to cell phone use and vehicle operation},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {65},
pages = {389-401},
year = {2019},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2019.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S1369847818302729},
author = {Joseph B. Claveria and Salvador Hernandez and Jason C. Anderson and Eric L. Jessup},
keywords = {Distracted driving, Cell phone, Large trucks, Random parameters, Binary logit, Driver inattention},
abstract = {Distracted driving continues to pose threats to transportation safety as it impairs driver performance and increases crash risk. In recent years, cell phone use while driving has become the primary research interest regarding distracted driving. However, the majority of this research has focused on the prevalence and risks of such behavior in passenger car drivers and few have investigated its effect on the performance of drivers of large trucks. Due to the inherent job responsibilities, truck drivers are more susceptible to use a cell phone, or other communication devices (e.g., CB radio), while driving to coordinate delivery logistics. The purpose of this study is to further understand distracted driving in the context of large trucks by identifying the factors that contribute to large truck drivers’ decision to report using a cell phone while operating a commercial motor vehicle. Through survey data collected in 2017 from drivers of large trucks who either pick-up or deliver goods in the Pacific Northwest (Oregon, Washington, Idaho, British Columbia), a random parameters binary logit model is used to identify these factors. Of the 515 respondents, 234 (45%) indicated that they use a cell phone while driving. Through the random parameters binary logit model, unobserved heterogeneity is captured, and specific driver behaviors, demographic, work, temporal, and management characteristics are found to affect the likelihood of truck drivers reporting to use their cell phone while driving. Of particular interest, are carrier management characteristics and safety training. Carriers who manage fatigue by imposing schedules to make it easier to take breaks result in a decrease in probability of drivers reporting cell phone use, while carriers who restrict the number of hours worked decreased the probability of reporting cell phone use for the majority of drivers. In addition, having participated in road safety driving resulted in a decrease in probability of reporting cell phone use for the majority of drivers. Such findings have the potential to aid government agencies and commercial motor vehicle carriers in understanding the factors influencing cell phone use while driving among truck drivers. Understanding these motives can aid in the development of programs and policy initiatives that are intended to mitigate distracted driving among truck drivers.}
}
@article{WANG2020101986,
title = {Estimating aboveground biomass of the mangrove forests on northeast Hainan Island in China using an upscaling method from field plots, UAV-LiDAR data and Sentinel-2 imagery},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {85},
pages = {101986},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2019.101986},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419306440},
author = {Dezhi Wang and Bo Wan and Jing Liu and Yanjun Su and Qinghua Guo and Penghua Qiu and Xincai Wu},
keywords = {Mangroves, Aboveground biomass, UAV-LiDAR, Sentinel-2, Random forest},
abstract = {The mangrove forests of northeast Hainan Island are the most species diverse forests in China and consist of the Dongzhai National Nature Reserve and the Qinglan Provincial Nature Reserve. The former reserve is the first Chinese national nature reserve for mangroves and the latter has the most abundant mangrove species in China. However, to date the aboveground ground biomass (AGB) of this mangrove region has not been quantified due to the high species diversity and the difficulty of extensive field sampling in mangrove habitat. Although three-dimensional point clouds can capture the forest vertical structure, their application to large areas is hindered by the logistics, costs and data volumes involved. To fill the gap and address this issue, this study proposed a novel upscaling method for mangrove AGB estimation using field plots, UAV-LiDAR strip data and Sentinel-2 imagery (named G∼LiDAR∼S2 model) based on a point-line-polygon framework. In this model, the partial-coverage UAV-LiDAR data were used as a linear bridge to link ground measurements to the wall-to-wall coverage Sentinel-2 data. The results showed that northeast Hainan Island has a total mangrove AGB of 312,806.29 Mg with a mean AGB of 119.26 Mg ha−1. The results also indicated that at the regional scale, the proposed UAV-LiDAR linear bridge method (i.e., G∼LiDAR∼S2 model) performed better than the traditional approach, which directly relates field plots to Sentinel-2 data (named the G∼S2 model) (R2 = 0.62 > 0.52, RMSE = 50.36 Mg ha−1<56.63 Mg ha−1). Through a trend extrapolation method, this study inferred that the G∼LiDAR∼S2 model could decrease the number of field samples required by approximately 37% in comparison with those required by the G∼S2 model in the study area. Regarding the UAV-LiDAR sampling intensity, compared with the original number of LiDAR plots, 20% of original linear bridges could produce an acceptable accuracy (R2 = 0.62, RMSE = 51.03 Mg ha−1). Consequently, this study presents the first investigation of AGB for the mangrove forests on northeast Hainan Island in China and verifies the feasibility of using this mangrove AGB upscaling method for diverse mangrove forests.}
}
@article{ROBICHAUD2019732,
title = {An ecological microsystem to treat waste oil contaminated soil: Using phytoremediation assisted by fungi and local compost, on a mixed-contaminant site, in a cold climate},
journal = {Science of The Total Environment},
volume = {672},
pages = {732-742},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2019.03.447},
url = {https://www.sciencedirect.com/science/article/pii/S0048969719314585},
author = {Kawina Robichaud and Katherine Stewart and Michel Labrecque and Mohamed Hijri and Jensen Cherewyk and Marc Amyot},
keywords = {Co-contamination, North, Bioremediation, Phytoremediation, Mycoremediation},
abstract = {As a result of anthropization and industrialization, northern remote communities face issues of soil contamination by mixtures of organic and inorganic contaminants. Soil bioremediation in cold environments is particularly challenging because of slower degradation rates, slower production of biomass for phytoextraction of trace elements (TEs), and remoteness, which can complicate logistics and inflate costs. This study evaluated a decontamination approach integrating indigenous willows, fungi and compost in a northern community. The site was a waste oil pit and its soil was initially contaminated with petroleum hydrocarbons (PHC) exceeding 200 g kg−1 and TEs including As, Cd, Co, Cr, Cu, Pb and Zn. In under five years, 65 and 75% of PHC (C6-C50 and >C50) were degraded, compared to 27 and 13% for the untreated control soil. We found contrasting TE translocation patterns to the aboveground biomass for the willow species used (Salix planifolia and Salix alaxensis), as well as distinctive rooting strategies. Hazard quotients were calculated to assess the risk plant material could pose to local wildlife. The highest TE concentration measured was Zn in S. planifolia, which exceeded Canadian soil guidelines. Results indicate toxicity risks to animals linked to TEs in Salix spp. leaves is generally unlikely. The fungus Trametes versicolor inoculated into the soil did not fruit, however fruiting bodies of Psathyrella sp. were observed consistently (four out of five years). Biological tests indicated that in five growing seasons soil toxicity significantly decreased compared to the untreated soil used as control. This was demonstrated by vegetation cover (137 vs 11% cover), toxicity assays on earthworms (Eisenia andrei) (0 vs 33% mortality) and barley seed germination (Hordeum vulgare) (86 vs 62% germination). The proposed decontamination approach, without the use of synthetic fertilizers, is promising for the PHC remediation of mixed-contaminants on cold climate sites.}
}
@article{CRAIG2019104,
title = {Pill, patch or ring? A mixed methods analysis of provider counseling about combined hormonal contraception},
journal = {Contraception},
volume = {99},
number = {2},
pages = {104-110},
year = {2019},
issn = {0010-7824},
doi = {https://doi.org/10.1016/j.contraception.2018.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010782418304323},
author = {Amaranta D. Craig and Jody Steinauer and Miriam Kuppermann and Julie A. Schmittdiel and Christine Dehlendorf},
keywords = {Hormonal contraception, Contraceptive counseling, Vaginal ring, Contraceptive patch, Combined oral contraceptive pills},
abstract = {Objective
In this study we aimed to investigate the content and process of contraceptive counseling surrounding combined hormonal contraceptive (CHC) methods (combined oral contraceptives, the ring, and the patch).
Study design
We performed a mixed methods analysis of data collected as part of the Patient-Provider Communication about Contraception study, in which reproductive age women and their providers were recruited at several San Francisco Bay Area clinics from 2009–2012. Participants completed pre- and post-visit surveys, and had their visits audio recorded and transcribed. We performed descriptive and bivariate analyses of the entire cohort to examine associations between demographic characteristics and pre-existing method preferences with method selection and counseling content, and coded transcripts of a subset of the sample for salient themes related to content and process of counseling about combined hormonal contraceptive methods using a directed content analysis approach.
Results
The overall sample included 342 women, with 152 women (44%) having a preference for a specific CHC prior to their visit, 127 women (37%) had a preference for a non-CHC method, and 63 (18%) having no existing method preference. Of the women who reported preferring a CHC in their pre-visit survey, the majority (72%) chose that method. We found that women were inconsistently counseled about the range of CHC methods. For example, women who had no pre-visit method preference (52%) or who preferred the ring (54%) or the patch (73%) were more likely to receive comprehensive counseling about the three CHC methods than were women who preferred combined oral contraceptives (35%) or non-CHC methods (33%). Providers mentioned the patch the least often, and in qualitative analysis indicated discomfort with prescribing this method. Side effects and benefits of methods, as well as strategies to enhance successful use of the chosen method, were inconsistently discussed. In only 73% of visits in which a woman chose a CHC did the provider assess the patient's ability to use the chosen method correctly, and in 66% of all visits in which women chose a CHC method, providers discussed what to do if she was dissatisfied with the method.
Conclusions
Counseling about combined hormonal contraceptive methods often does not include information about all available methods, or comprehensive information about side effects, benefits, or logistics of use. As this counseling can impact patient's satisfaction with and continuation of their chosen method of contraception, future work should focus on designing interventions to improve providers' ability to meet patients' needs.
Implications
Short acting hormonal contraception is widely used, but counseling for these methods often neglects key features. Comprehensive counseling about all methods and their individual features can improve contraceptive selection and use.}
}
@article{LU2020325,
title = {A Thematic Analysis of the Online Discussion Board, FrankTalk, Regarding Penile Implant},
journal = {The Journal of Sexual Medicine},
volume = {17},
number = {2},
pages = {325-330},
year = {2020},
issn = {1743-6095},
doi = {https://doi.org/10.1016/j.jsxm.2019.11.258},
url = {https://www.sciencedirect.com/science/article/pii/S1743609519317825},
author = {Jennifer Y. Lu and Eric J. Miller and Charles Welliver},
keywords = {Erectile Dysfunction, Impotence, Penile Prosthesis, Penile Implantation, Internet},
abstract = {Introduction
Medical websites and discussion boards are commonly used by patients to obtain information. The online forum FrankTalk.org provides a venue specifically for men to discuss sexual dysfunction and particularly inflatable penile prosthesis (IPP). By querying and better understanding the content of this forum related to implants, we can better understand patient concerns before and after IPP.
Aim
The aim of this study is to understand the main topics being discussed about IPPs online and to use these topics to understand patient concerns and patient needs and to improve care.
Methods
Messages posted in a 6-month window from January 2018 to June 2018 under the topic “Implant” were identified on FrankTalk.org. Posts were broken down into preoperative and postoperative and then organized using a 3-stage analysis to determine central themes of each post: open coding, axial coding, and selective coding.
Main Outcome Measure
The primary outcome measure is the prevalence of each selective code.
Results
Of all 587 posts, 304 were written preoperatively with the most common theme being “Size” (23.0%), followed by “seeking support” (18.4%). 283 posts were considered postoperative, of which the most common theme was “Concern about healing” (22.6 %) which questioned if they needed to see a physician, followed by size concerns (20.1%).When analyzed with the 3-stage coding system, there were a total of 41 axial codes which were organized into 6 selective codes: “Social Support” (27.8% of all posts), “Pre-Operative Worries” (23.58%),“Technical Issues” (11.1%), “Prosthesis Logistics” (14.37%), “Post-Operative Worries” (20.22%), “Forum and Misc” (2.93%) for topics outside the scope of penile prosthesis.
Clinical Implications
The percentage of men seeking medical opinion is concerning, and providers should consider using resources to better educate patients on normal postoperative findings. Implanters should continue to preoperatively counsel patients on size-related changes with surgery.
Strength & Limitations
Strengths include the use of a common online website for men to discuss IPPs and a systematic coding system. Limitations include the applicability of these results to nonheterosexual men as these are likely oversampled in this population. The inherent bias of those willing to post on an online forum may have influenced results along with no oversight for factual accuracy.
Conclusion
Patients use online discussion boards like FrankTalk.org for social support, medical advice, and validation of their concerns. Providers should be aware of these online topic focuses to help open a discussion with patients about concerns they may feel are difficult to approach with providers. Lu JY, Miller EJ, Welliver C. A Thematic Analysis of the Online Discussion Board, FrankTalk, Regarding Penile Implant. J Sex Med 2020;17:325–330.}
}
@article{CADDELL2019S35,
title = {Reporting of surgical response to disasters in low-income and middle-income countries: a literature review},
journal = {The Lancet Global Health},
volume = {7},
pages = {S35},
year = {2019},
note = {CUGH 10th annual conference},
issn = {2214-109X},
doi = {https://doi.org/10.1016/S2214-109X(19)30120-2},
url = {https://www.sciencedirect.com/science/article/pii/S2214109X19301202},
author = {Luke Caddell and Taylor Wurdeman and Rolvix H Patterson and Jordan Pyda and Rachel Koch and John G Meara and Scott Corlew},
abstract = {Background
Natural and man-made disasters can overwhelm the capacity of surgical systems in low-income and middle-income countries (LMICs). Most studies addressing peri-disaster surgical care focus on international relief efforts rather than on how disasters stress local surgical capacity. Our understanding of factors that affect the ability of health systems to absorb increased volume and case-complexity is poor. We conducted a structured literature review to identify whether components of capacity were reported as part of surge response in local surgical care after disasters.
Methods
We searched PubMed and Medline databases for articles published between January, 2008, and August, 2018, using English language search terms for LMICs, surgery, and disasters. We extracted information about the WHO region, disaster classification, and the components of surge capacity using the 4S framework: Staff (human resources), Stuff (equipment/supplies), Space (infrastructure), and Systems (logistics). The 4S components were further classified by data quality into the following categories: quantitative description, qualitative description, or no description.
Findings
We identified 7704 articles but after applying exclusion criteria, including foreign aid response, we selected 84 articles for analysis. Most articles (59/84 [70%]) described earthquakes and 40/84 (48%) reported events in the Western Pacific region. Using the 4S framework, we identified articles that reported quantitative data: 16 (19%) for Staff, 3 (4%) for Stuff, 21 (25%) for Space, and 9 (11%) for Systems. Despite a low threshold for quantitative categorisation, only 1/84 (1%) articles described all four components with quantitative data. By comparison, 51/84 (61%) articles provide no quantitative data on any of the four components.
Interpretation
There is no organised framework for evaluation of surgical surge capacity in disasters. Our analysis shows that there are very few descriptions of capacity within disaster literature and a limited understanding of LMIC health system response to surges in surgical volume. Without a structured framework to collect data on health system response, we miss opportunities to identify and strengthen areas of insufficient capacity. We encourage the incorporation of quantitative surgical metrics when reporting outcomes after disaster response, and propose the 4S framework as a conceptual model for reporting such metrics and understanding the surgical system response to disasters.
Funding
None.}
}
@article{ARRANJA2020110244,
title = {Preparation and characterization of inorganic radioactive holmium-166 microspheres for internal radionuclide therapy},
journal = {Materials Science and Engineering: C},
volume = {106},
pages = {110244},
year = {2020},
issn = {0928-4931},
doi = {https://doi.org/10.1016/j.msec.2019.110244},
url = {https://www.sciencedirect.com/science/article/pii/S0928493119314547},
author = {A.G. Arranja and W.E. Hennink and C. Chassagne and A.G. Denkova and J.F.W. Nijsen},
keywords = {Microspheres, Holmium phosphate, Holmium hydroxide, Radionuclide therapy, Neutron activation, Hemocompatibility},
abstract = {Microspheres with high specific activities of radionuclides are very interesting for internal radiotherapy treatments. This work focuses on the formulation and characterization of inorganic microspheres with a high content of holmium and therefore a high specific radioactivity of holmium-166. Two novel formulations of inorganic microspheres were obtained by dispersing solid holmium acetylacetonate microspheres (Ho2(AcAc)3-ms) in NaH2PO4 or NaOH solutions followed by 2 h incubation at room temperature. By exchange of acetylacetonate with phosphate or hydroxyl ions, holmium phosphate microspheres (HoPO4-ms) and holmium hydroxide microspheres (Ho(OH)3-ms) were formed respectively. The inorganic microspheres had a significantly smaller diameter (28.5 ± 4.4 μm (HoPO4-ms) and 25.1 ± 3.5 μm (Ho(OH)3-ms)) than those of Ho2(AcAc)3-ms (32.6 ± 5.2 μm). The weight percentage of holmium-165 in the microspheres increased significantly from 47% (Ho2(AcAc)3-ms) to 55% (HoPO4-ms) and 73% (Ho(OH)3-ms). After preparation of both HoPO4-ms and Ho(OH)3-ms, the stable holmium-165 isotope was partly converted by neutron activation into radioactive holmium-166 to yield radioactive microspheres. High specific activities were achieved ranging from 21.7 to 59.9 MBq/mg (166HoPO4-ms) and from 28.8 to 79.9 MBq/mg (166Ho(OH)3-ms) depending on the neutron activation time. The structure of both microspheres was preserved up to neutron activations of 6 h in a thermal neutron flux of 4.72 × 1016 n m−2 s−1. After activation, both microspheres revealed excellent stability in administration fluids (saline and phosphate buffer) having less than 0.05% of holmium released after 72 h incubation. Finally, the hemocompatibility of these inorganic microspheres was evaluated and it was shown that the microspheres did cause neither hemolysis nor depletion or inhibition of the coagulation factors of the intrinsic blood coagulation pathway meaning that the microspheres have a good hemocompatibility. Overall, this work shows that radioactive inorganic microspheres with high specific activities of holmium-166 can be prepared which potentially can be used for internal radionuclide therapy.}
}
@article{SCHUMACHER2020223,
title = {Gestion de la pandémie COVID-19 en Suisse : rôles et défis d’une pharmacie interhospitalière},
journal = {Médecine de Catastrophe - Urgences Collectives},
volume = {4},
number = {3},
pages = {223-232},
year = {2020},
issn = {1279-8479},
doi = {https://doi.org/10.1016/j.pxur.2020.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1279847920301051},
author = {Laurence Schumacher and Cédric Blatrie and Séverine Krähenbühl and Camilla Pasteur and Anne-Laure Blanc and Charline Pellaton and Pascal Bonnabry and François Rouiller and Nicolas Widmer},
keywords = {Plans catastrophe, Pharmacie d’hôpital, Protection civile, Pandémie, COVID-19, Disaster planning, Pharmacy Service, Hospital, Civile Defense, Pandemics, COVID-19},
abstract = {Résumé
Du 16 mars au 18 juin 2020, en raison de la pandémie COVID-19, le Conseil fédéral suisse a déclaré une « situation extraordinaire » au sens de la Loi sur les épidémies. Le présent travail évalue les rôles d’une pharmacie interhospitalière dans la lutte contre le SRAS-CoV-2 en Suisse dans le contexte du Service sanitaire coordonné. Pendant cette période, toutes les missions effectuées par cette pharmacie ont été systématiquement collectées et évaluées. Elles ont également été comparées à ses responsabilités traditionnelles. Les missions spécifiques ont été principalement gérées par la cellule de crise et les 4 secteurs de la pharmacie (Logistique pharmaceutique, Fabrication, Pharmacie clinique et Approvisionnement des maisons de retraite) : (1) garantie de la continuité des ressources humaines; (2) sécurisation de l’infrastructure propre à la pharmacie (notamment en termes d’hygiène); (3) approvisionnement spécifique en médicaments (par exemple : anesthésiques, sédatifs, antiviraux, y.c. pour les essais cliniques); (4) production et approvisionnement de désinfectant pour les mains ; (5) appui clinique (particulièrement dans les unités de soins critiques); (6) fabrication de médicaments individualisés; (7) gestion des pharmacies d’unité de soins, et (8) fourniture de masques hygiéniques pour les professionnels de la santé de la région. Les missions (4) et (8) ne faisaient pas partie des rôles habituels de la pharmacie et ont été réalisées avec le soutien de la Protection civile suisse. Une difficulté particulière a été la gestion de la pénurie de divers produits et l’identification d’options thérapeutiques alternatives. En conclusion, notre pharmacie d’hôpital a été confrontée à divers défis durant la première vague de la pandémie. Certaines missions réalisées ont même dépassé les responsabilités traditionnelles. Sur la base des enseignements tirés de cette pandémie, le plan d’urgence de notre pharmacie, ainsi que la formation associée du personnel, ont été développés.
Summary
From March 16 to June 18, 2020, because of the COVID-19 pandemic, the Swiss Federal Council declared an “extraordinary situation” in terms of the Epidemics Act. The present work assesses the roles of an interhospital pharmacy in the fight against SARS-CoV-2 in Switzerland, in the frame of the Coordinated Medical Service. During this time, all missions performed by the pharmacy were systematically collected and evaluated. They were also compared to its official duties. Specific missions have been mainly managed by the crisis unit and the 4 departments of the pharmacy (Logistics, Manufacturing, Clinical Pharmacy and Nursing Homes Supply): (1) guarantee continuity of human resources; (2) internal infrastructure securing (especially in terms of hygiene); (3) specific drug supply (e.g. anesthetics, sedatives, antivirals, incl. for clinical trials); (4) hand disinfectant production and supply; (5) clinical assistance (especially in the Critical Care units); (6) individual drug manufacturing; (7) management of ward pharmacies, and (8) hygienic masks supply for healthcare professionals in the area. The missions (4) and (8) were out of the usual duties of the pharmacy and have been achieved with the support of the Swiss civil protection. A particular difficulty was the management of the shortage of various products and the identification of alternative therapeutic options. In conclusion, our pharmacy has faced various challenges during the first wave of the pandemic. Some missions performed were even beyond the traditional duties. Based on the lessons learned from this pandemic, the disaster plan of our pharmacy, as well as the associated staff training, have been further developed.}
}
@article{KELLY2021391,
title = {Remote Monitoring of Cardiovascular Implantable Electronic Devices in Canada: Survey of Patients and Device Health Care Professionals},
journal = {CJC Open},
volume = {3},
number = {4},
pages = {391-399},
year = {2021},
issn = {2589-790X},
doi = {https://doi.org/10.1016/j.cjco.2020.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S2589790X20301980},
author = {Shannon E. Kelly and Debra Campbell and Lenora J. Duhn and Karen Giddens and Anne M. Gillis and Amir AbdelWahab and Isabelle Nault and Satish R. Raj and Evan Lockwood and Jessica Basta and Steve Doucette and George A. Wells and Ratika Parkash},
abstract = {Background
Remote monitoring is used to supplement in-clinic follow-up for patients with cardiac implantable electronic devices (CIEDs) every 6-12 months. There is a need to optimize remote management for CIEDs because of the consistent increases in CIED implants over the past decade. The objective of this study was to investigate real and perceived barriers to the use of remote patient management strategies in Canada and to better understand how remote models of care can be optimized.
Methods
We surveyed 512 CIED patients and practitioners in 22 device clinics in Canada.
Results
Device clinic surveys highlighted significant variation and inconsistency in follow-up care for in-clinic and remote visits across and within clinics. This survey showed that funding policies and management of additional workflow are barriers to optimal use and uptake. Despite this, device clinics perceive remote follow-up as a valuable resource and an efficient way to manage patient follow-up. Patients were broadly satisfied with their CIED follow-up care but identified barriers related to coordination of care, visit logistics, and information needs. Views varied as a function of clinical or sociodemographic characteristics. Most patients (n = 228; 91%) expressed a desire to receive a phone call from their device clinic after a remote transmission has been received.
Conclusions
Lack of a unified, guideline-supported approach to follow-up after CIED implant, and discrepant funding policies across jurisdictions, are significant barriers to the use of remote patient management strategies in Canada. Efforts to increase or expand use of remote follow-up must recognize these barriers and the needs of specific subgroups of patients.
Résumé
Introduction
La télésurveillance sert de complément à la consultation en clinique des patients porteurs d’un dispositif cardiaque électronique implantable (DCEI) tous les 6 à 12 mois. Il est nécessaire d’optimiser la prise en charge à distance des patients porteurs de DCEI en raison de la constante augmentation des implantations de DCEI au cours de la dernière décennie. L’objectif de la présente étude était d’examiner les obstacles réels et perçus à l’utilisation des stratégies de prise en charge à distance des patients du Canada et de mieux comprendre la façon d’optimiser les modèles de soins à distance.
Méthodes
Nous avons interrogé 512 patients porteurs de DCEI et praticiens de 22 cliniques spécialisées en DCEI du Canada.
Résultats
Les enquêtes des cliniques spécialisées en DCEI ont fait ressortir la variation importante et le manque d’uniformité dans les soins de suivi lors des consultations en clinique et à distance au sein de toutes les cliniques et entre elles. Cette enquête a montré que les politiques de financement et la gestion du flux de travail supplémentaire sont les obstacles qui empêchent l’utilisation optimale et l’adoption. Malgré cela, les cliniques spécialisées en DCEI perçoivent le suivi à distance comme une ressource très utile et un moyen efficace de prendre en charge le suivi du patient. Les patients étaient dans l’ensemble satisfaits de leurs soins de suivi relatifs à leur DCEI, mais relevaient des obstacles liés à la coordination des soins, à la logistique des consultations et à leurs besoins d’information. Les points de vue variaient en fonction des caractéristiques cliniques et sociodémographiques. La plupart des patients (n = 228 ; 91 %) ont fait part de leur souhait de recevoir un appel téléphonique de leur clinique spécialisée en DCEI après la réception de la transmission à distance.
Conclusions
L’absence d’une approche unifiée et fondée sur les lignes directrices qui porte sur le suivi après l’implantation de DCEI, et la divergence des politiques de financement des provinces et territoires sont des obstacles importants à l’utilisation de stratégies de prise en charge à distance des patients au Canada. Les efforts visant à accroître ou à étendre l’utilisation du suivi à distance doivent tenir compte de ces obstacles et des besoins des sous-groupes particuliers de patients.}
}
@article{ZIMMERMANSAVILL20214096,
title = {Real-World Treatment of Patients with Large B-Cell Lymphoma in the United States with Chimeric Antigen Receptor T-Cell Therapy},
journal = {Blood},
volume = {138},
pages = {4096},
year = {2021},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2021-150723},
url = {https://www.sciencedirect.com/science/article/pii/S0006497121060109},
author = {Kristin M. {Zimmerman Savill} and Andrew J Klink and Djibril Liassou and Dhruv Chopra and Jalyna Laney and Ajeet Gajra},
abstract = {Introduction: The advent of chimeric antigen receptor (CAR) T-cell therapy has represented one of the most innovative therapeutic advances in oncology in recent years. Impressive clinical responses to CAR T-cell therapy observed in patients in clinical trials have led to the Food and Drug Administration (FDA) approval of five CAR T-cell therapies in the US since 2017 to treat large B-cell, mantle cell, and follicular lymphomas, as well as acute lymphoblastic leukemia (ALL) and multiple myeloma. The first two CAR T-cell therapies approved by the FDA, axicabtagene ciloleucel (axi-cel) and tisagenlecleucel (tisa-cel), have now been on the US market for the treatment of patients with large B-cell lymphoma (LBCL) since 2017 and 2018, respectively, allowing for assessment of their use in real-world clinical practice. Given the complex logistics of the manufacturing, distribution, administration and unique toxicity of CAR T-cell therapies, initial use was limited to larger centers with prior experience with CAR T-cell therapy clinical trials. With greater use and availability of multiple CAR T-cell therapies, real-world evaluation of the clinical profiles, treatment patterns, and outcomes of LBCL patients treated with CAR T-cell therapies may inform clinical, regulatory, and drug development decision making, ultimately helping to improve patient outcomes. This real-world claims-based study aimed to describe characteristics and treatment outcomes of patients with diffuse LBCL (DLBCL) treated with the CAR T-cell therapies axi-cel or tisa-cel in the non-trial setting. Methods: Patients with at least 1 claim for axi-cel or tisa-cel made prior to 03/31/21 and a diagnosis code of DLBCL were identified from the Symphony Integrated Dataverse (IDV), a large US claims database containing linked longitudinal prescription, medical, and hospital claims. The IDV contains claims for 280 million active unique patients representing over 63% of prescriptions with full lifecycle data, 62% of medical claims, and 25% of hospital claims volume in the US. Patients were excluded from analysis if axi-cel or tisa-cel was the first therapy identified for the patient since diagnosis of DLBCL within the claims database, if treatment was received as a part of a clinical trial, if there were no supporting claims around CAR T-cell therapy in the claims database, if next line of therapy was received within 30 days of a sole claim for axi-cel or tisa-cel, or if data supported a diagnosis of ALL. Patient characteristics and treatment patterns were summarized using descriptive statistics. Results: Among a total of 88 eligible patients with DLBCL identified in this study, 52% (n=46) received axi-cel and 48% (n=42) received tisa-cel. At the time of treatment with axi-cel or tisa-cel therapy, median patient age was 63 years (range, 20-78 years) and commercial insurance was the primary payer for 83% of patients (n=73). The majority (n=59, 67%) of patients were male. Patients with DLBCL treated with axi-cel or tisa-cel were distributed across each of the 4 US census regions, with 27% from the Northeast, 11% from the South, 32% from the Midwest, and 30% from the West. . Axi-cel or tisa-cel was received a median of 14 months following patients' initial diagnosis of DLBCL and for the majority (n=54, 61%) of patients, axi-cel or tisa-cel-related claims were associated with administration of CAR T-cell therapy in the outpatient setting (Table). Prior to axi-cel or tisa-cel, 57% of patients (n=50) received 2 or more lines of systemic therapy. Within a median follow-up period of 7.8 months, 17% of patients (n=15) received systemic therapy following axi-cel or tisa-cel treatment. Conclusions: In the first few years of US market availability, the CAR T-cell therapies axi-cel and tisa-cel have been used to treat patients with LBCL outside of the clinical trial setting. While the majority of patients in this real-world claims-based study received axi-cel or tisa-cel in an outpatient setting, hospital claims are underrepresented in the database utilized. Despite short follow-up (less than 8 months from initiation of these CAR T-cell therapies), approximately one in 6 patients appear to have relapsed disease, based on the need for subsequent systemic therapy. Further research is warranted to understand real-world clinical outcomes among patients treated with CAR T-cell therapy outside the trial setting. Figure 1
Disclosures
Zimmerman Savill: Roche/Genentech: Ended employment in the past 24 months; Cardinal Health: Current Employment. Klink: Cardinal Health: Current Employment, Current holder of stock options in a privately-held company. Liassou: Cardinal Health: Current Employment. Chopra: Cardinal Health: Current Employment. Laney: Cardinal Health: Current Employment. Gajra: Cardinal Health: Current Employment, Current equity holder in publicly-traded company.}
}
@article{DEPASQUALE2019171,
title = {Family Members’ Experiences With Dialysis and Kidney Transplantation},
journal = {Kidney Medicine},
volume = {1},
number = {4},
pages = {171-179},
year = {2019},
issn = {2590-0595},
doi = {https://doi.org/10.1016/j.xkme.2019.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2590059519300482},
author = {Nicole DePasquale and Ashley Cabacungan and Patti L. Ephraim and LaPricia Lewis-Boyér and Neil R. Powe and L. Ebony Boulware},
keywords = {End-stage kidney disease treatments, unexpected experiences, families, dialysis, living-donor kidney transplantation},
abstract = {Rationale & Objective
Understanding whether family members’ experiences with patients’ treatment for end-stage kidney disease (ESKD) were expected could guide the development of family-centered interventions that enhance the preparedness of patients and their care partners for kidney replacement therapies. We explored unexpected negative experiences with ESKD treatments among family members of dialysis and posttransplantation patients to identify meaningful directions for family-centered research and clinical care.
Study Design
Qualitative study.
Setting & Participants
8 focus groups comprising 49 family members of dialysis patients and living donor kidney transplant recipients undergoing medical care in Baltimore, MD.
Analytical Approach
Focus groups were stratified by patients’ treatment (in-center hemodialysis, home hemodialysis, peritoneal dialysis, or living donor kidney transplantation) and family members’ self-reported race (African American vs non–African American), resulting in 2 groups per treatment experience. Inductive thematic analysis was used to identify themes in focus group transcripts. Themes shared across different treatment groups were highlighted to provide insight into common experiences.
Results
We identified 4 themes that described family members’ unexpected negative treatment experiences: becoming a care partner (unanticipated responsibilities and sleep disruptions), adverse psychological treatment responses in patients (eg, depression) and family members (eg, anxiety), treatment delivery and logistics (insufficient information, medication regimen, and logistical inconveniences), and patient morbidity (dialysis-related health problems and fatigue). All themes were relevant to discussions in the in-center hemodialysis, peritoneal dialysis, and transplantation groups, whereas psychological responses and morbidity themes did not reflect discussions in home hemodialysis groups.
Limitations
Data collection occurred from 2008 to 2009; family members were recruited through patients undergoing care in 1 geographic area; 1 family member participant per patient.
Conclusions
Family members described a broad range of unexpected negative experiences with ESKD treatments. Efforts to prepare families for ESKD treatments through more family-centered care, early and tailored education, and interventions targeting care partner preparedness, health provider–family member communication, and relationship dynamics in family member–patient dyads are needed.}
}
@article{MOORE2019267,
title = {Undisciplining environmental justice research with visual storytelling},
journal = {Geoforum},
volume = {102},
pages = {267-277},
year = {2019},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2017.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016718517300520},
author = {Sarah A. Moore and Robert E. Roth and Heather Rosenfeld and Eric Nost and Kristen Vincent and Mohammed {Rafi Arefin} and Tanya M.A. Buckingham},
keywords = {Visualization, Waste geographies, Environmental justice, Critical cartography, Visual storytelling, Uncertainty},
abstract = {Environmental justice research has used maps to make visible the spatial correlations between hazardous waste disposal sites and poor and minority communities since the 1970s. No doubt, such visual evidence of marginalized communities disproportionately burdened with noxious facilities has been an important and powerful tool for activists, regulators, and educators. Despite the efficacy of such mappings in demonstrating unjust distributions of waste, critics argue that they do not capture the complicated processes behind this spatial phenomenon. In this paper, we discuss our pursuit of an “undisciplined” environmental justice project by using visualization, not solely as the traditional product of research, but also as a process for raising new lines of inquiry into the social and environmental dynamics at work in the landscape. To this end, we present one strategy we have used in our project to construct and creatively visualize a novel dataset on the transnational hazardous waste trade in North America. Specifically, we convened a one-day “Design Challenge” with geography students from several sub-disciplines. This event yielded new avenues for international environmental justice research on and visualization of the transnational waste trade, identified methods for and concerns about critical storytelling with large datasets, and highlighted the opportunities and challenges of using critical storytelling to undiscipline EJ research. The paper presents logistics leading up to the Design Challenge, key insights and critical discussion resulting from the day, and interviews conducted one year after the Design Challenge on enduring lessons from the process.}
}
@article{SHEVTSHENKO20192425,
title = {Enhancing the partner selection process in a Sustainable Partner Network},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {13},
pages = {2425-2430},
year = {2019},
note = {9th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.570},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319315575},
author = {Eduard Shevtshenko and Kashif Mahmood and Tatjana Karaulova},
keywords = {Sustainable Partner Network (SPN), Supply Chain (SC), Value-Added activities (VA), Enterprise Architect (EA), Virtual Enterprise (VE), KPI (Key Performance Indicators), Supply Chain Operations Reference (SCOR) model, SIPOC, Suppliers, Inputs, Process, Outputs, Customers},
abstract = {Purpose: The purpose of this paper is to introduce how to describe in a unified way the business models of different sectors companies based on VAC/EPC notations, and to contribute to the lean based partner selection mechanism for sustainable partner network. Design/methodology/approach: The authors introduce the unified business process modelling approach for collaborative companies modelling, which supports the lean based sustainable partner selection. Where lean correspond to the characteristics of cheap (cost effective), better (lower risk) and fast (less time). Findings: The authors defend that appropriate partner selection is a vital success factor in any collaboration. Existing supplier (partner selection) tools do not include the unified approach for business processes modelling of partners organisations and do not apply the lean principles for sustainable partner selection. Existing collaborative networks such as conventional supply chains spend considerable time and money to search for suitable partners, decrease the number of successful initiation of a project and completed collaborative projects. Research limitations/implications: The authors have designed a unified methodology for the business process modelling of manufacturing and machinery sectors companies applied for the formation of a sustainable partner network. After implementation, the solution applies the lean based approach for partner selection, to decrease the time and cost spend with simultaneous improvement of collaborative project sustainability. Nevertheless, the proposed approach is adaptable to other fields. Practical implications: To evaluate the achieved results the authors have performed the simulation study of Sustainable Partner Network (SPN) formation followed by partner’s selection that supports lean principles. The paper includes a feasibility case study for the approval of findings, where twenty-seven small and medium enterprises (SMEs) from the manufacturing and logistics fields collaborate to achieve a common goal. The time required for collaborative partner selection in the conventional supply chain is compared to the partner selection in Sustainable Partner Network was found to less. Originality/value: The main idea is to collect information about the available resources of SMEs into a new temporary entity and to utilise those resources for the realisation of the tasks of a particularly large project while meeting customer expectations. This work also suggests a methodology for faster business process modelling and evaluation (assessment) based on lean principles for a particular business process. Partners can use the SPN resources with the attributes of fast, cheap and less risk. The suggested solution enables to select the most reliable partners and contributes to the improvement of collaborative networks sustainability.}
}
@article{BENAZZOUZ201919,
title = {Risks related to the medical supply chain in public hospitals in Morocco: Qualitative study},
journal = {Le Pharmacien Hospitalier et Clinicien},
volume = {54},
number = {1},
pages = {19-29},
year = {2019},
issn = {2211-1042},
doi = {https://doi.org/10.1016/j.phclin.2018.10.058},
url = {https://www.sciencedirect.com/science/article/pii/S2211104218301917},
author = {T. Benazzouz and A. Charkaoui and A. Echchatbi},
keywords = {Hospital, Pharmaceutical products, Qualitative study, Risks, Supply, Hôpital, Produits pharmaceutiques, Étude qualitative, Risques, Approvisionnement},
abstract = {Summary
Objective
To classify the risks and errors which negatively influence the availability of pharmaceutical products at public hospitals in Morocco.
Method
Qualitative study that explores the problem studied, these processes and the people involved. It is therefore interesting to meet the actors in the pharmaceutical chain and let them freely express themselves through structured interviews. The study will be applied at the level of three main actors of the chain, namely: the central structures involved in the logistics chain, CHR and CHP and CHU.
Results
The results obtained in the field revealed several errors, problems and risks in the pharmaceutical supply chain that negatively influence the availability of these products from selection to delivery to the level of hospital services. Out of stock and the lack of management software are common risks and the most frequent in the speeches of managers at different sites of the study. Ruptures can occur due to delayed deliveries, rough choices of suppliers, the method of acquisition and non-control and the lack of safety stock and also the overuse of pharmaceuticals.
Résumé
Objectif
Classifier les risques et erreurs qui influencent négativement sur la disponibilité des produits pharmaceutiques au niveau des hôpitaux publics du Maroc.
Méthode
Étude qualitative qui explore la problématique étudiée, les processus et les personnes qui y ont participé. Il est donc intéressant d’aller à la rencontre des acteurs de la chaîne des produits pharmaceutiques et de les laisser librement s’exprimer à travers des entretiens structurés. L’étude va être appliquée au niveau de trois acteurs principaux de la chaîne, à savoir : les structures centrales impliquées dans la chaîne logistique, les CHR et CHP et le CHU.
Résultats
Les résultats obtenus sur le terrain ont révélé plusieurs erreurs, problèmes et risques dans la chaîne logistique des produits pharmaceutiques qui influencent négativement la disponibilité de ces produits en allant de la sélection jusqu’à la livraison au niveau de services hospitaliers. La rupture de stock et le manque d’un logiciel de gestion sont les risques les plus fréquemment mentionnés dans les discours de responsables au niveau de différents sites de l’étude. Les ruptures peuvent survenir à cause de retard des livraisons, de choix approximatifs des fournisseurs, de la méthode d’acquisition et de la non maîtrise et de l’absence du stock de sécurité et aussi de la sur-utilisation des produits pharmaceutiques.
Conclusion
De cette étude, il ressort que la gestion de la chaîne des produits pharmaceutiques connaît des dysfonctionnements qui peuvent être liés principalement à l’absence d’un système d’information intégré qui permet une informatisation du processus allant de l’expression du besoin à la livraison. Ces dysfonctionnements se situent également au niveau de l’organisation actuelle du système d’approvisionnement centralisé. Cette situation génère souvent des ruptures de stock qui peuvent durer jusqu’à 3 mois, des surstocks, des sous-estimations et surestimations des besoins et une mauvaise gestion d’espace de stockage.}
}
@article{DERPOEL2020114692,
title = {Future directions of animal feed technology research to meet the challenges of a changing world},
journal = {Animal Feed Science and Technology},
volume = {270},
pages = {114692},
year = {2020},
issn = {0377-8401},
doi = {https://doi.org/10.1016/j.anifeedsci.2020.114692},
url = {https://www.sciencedirect.com/science/article/pii/S0377840120305964},
author = {A.F.B. van {der Poel} and M.R. Abdollahi and H. Cheng and R. Colovic and L.A. {den Hartog} and D. Miladinovic and G. Page and K. Sijssens and J.F. Smillie and M. Thomas and W. Wang and P. Yu and W.H. Hendriks},
keywords = {Feed technology, Industry, Research, Future directions},
abstract = {Feed technology involves the processing of ingredients and the manufacture of animal feeds and is an integral part of animal production systems to provide high quality and nutritious food. The objective is to transform low quality ingredients into higher value feed components, and improve nutrient utilization of compound feeds. Animal feed, therefore, has a social responsibility to contribute to more sustainable food production systems. Further understanding of the structures and functional properties of feed components, their changes with different primary and secondary processing and their conditions, are essential to more accurately meet nutrient requirements of animals. In addition, it will enable a more accurate assessment of overall costs of processing or production with respect to the societal responsibility of feed processing; this may include energy use, carbon footprint, use of water resources and life cycle assessment. Accurate and fast testing technologies should account for the variability within ingredients and the different practices used in the equipment and raw material processing, as well as those in feed mills. Big data will play a pivotal role to model specific aspects of feed manufacturing and could enable the development of a model integrating characteristics of diet ingredients, recipe and processing conditions, whilst optimizing energy consumption, (physical) feed quality and production rate. Collaboration between skilled data scientists, machine experts, feed manufacturing technologists and nutritionists, using advanced data analytics is, therefore, required for future process optimisation. An improved interaction between those responsible for the actual formulation of animal diets, feed technologists and mill operators may result in a more constant final feed product quality and the lowest electrical and fossil energy consumption during manufacture, despite inclusion of alternative/substitute ingredients. Lesser known, novel processing techniques may significantly contribute to improve the nutritional value of raw materials and complete feeds. However, only a few techniques may be scalable to economically feasible processes, while others may only be applicable to one animal species and not usable as a general process. In addition, modern feed mills need flexibility and the ability to switch to serve customer wishes and logistics where feed recipes and feed forms are concerned. A major constraint to conduct research in feed processing is the difficulty to acquire attention and funding. More attention should be given to feed additives in processed feed (mainly in pellet form), with research focused on the interaction effects between feed processing conditions, feed components and feed additives. Finally, future feed technologists will require recognized qualifications, possibly to a diploma level. Courses must be successfully completed and include knowledge on smart manufacturing and integrated process control systems. From a feed industry perspective, success of participation in the next industrial feed mill development will be determined by how well staff are prepared and trained.}
}
@incollection{MANDICRAJCEVIC2021199,
title = {Chapter 9 - Exposure and risk profiles: From field studies to typical exposure and risk scenarios},
editor = {Claudio Colosio and Aristidis M. Tsatsakis and Stefan Mandić-Rajćević and Athanasios Alegakis},
booktitle = {Exposure and Risk Assessment of Pesticide Use in Agriculture},
publisher = {Academic Press},
pages = {199-224},
year = {2021},
isbn = {978-0-12-812466-6},
doi = {https://doi.org/10.1016/B978-0-12-812466-6.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128124666000105},
author = {Stefan Mandić-Rajčević and Federico Maria Rubino and Claudio Colosio},
keywords = {Pesticides, Fungi, Pests, Personal protective devices (PPD), Plant protection products (PPP), Tebuconazole, Exposure assessment, Risk assessment},
abstract = {Pesticides are intrinsically toxic, and their manipulated quantity and wide use requires adequate protection to reduce the potential impact on applicators’ health. Before marketing the exposure-related health risk of each active substance is assessed through models, to demonstrate that at least in one application scenario its use does not cause an unacceptable health risk to the exposed workers. This reasonably safe scenario identifies the modalities for an effective and safe use that are coded as “Good Agricultural Practices” (GAP) and summarized in the label's instructions. However, real-life work may be conducted out of the frame of GAP, with a consequent health risk for the exposed workers, which must be assessed and managed. In real-life working conditions, risk assessment is seldom, if at all, performed since the task is linked to economic cost, the limited availability of trained personnel and logistics necessary to reach small, family-based enterprises, which are poorly covered by occupational health services. Additional difficulties are represented by the variability of working patterns, climatic conditions, and the frequent use of mixtures of pesticides. The main tools currently available for the exposure and risk assessment “in the field,” namely, biological and environmental monitoring, show important limits for their use in agriculture. In particular, assessment of dermal contamination involves very complicated and expensive procedures that cannot be carried out on a routine basis. Biological monitoring faces strong limitations, including lack of fully validated biomarkers and biological exposure limits. The exposure estimate and risk estimate done for a specific worker at a specific time during one of his workdays using any of the aforementioned methods represent only one point on a map of exposures and risk for workers applying pesticides. Instead of a point, we are interested in the whole map of exposure and risk. To make risk assessment available to all workers in various working conditions, there is a need of simple, user-friendly, and reliable approaches to estimate the levels of exposure (and of related occupational risk) experienced by the workers during typical, rather than actual, activities. We refer to these typical conditions as exposure and risk profiles. This chapter underlines the variables influencing exposure and exposure assessment in real-life work scenarios, reviews the drawback and difficulties of performing exposure assessment using environmental and/or biological monitoring, introduces the concept of exposure scenarios and risk profiles, reviews the current state of risk profile development and their main characteristics, and presents a way forward to integrate the exposure assessment through the exposure score (or index) and the toxicity score to create a risk assessment scheme or a map of exposure and risk in typical exposure scenarios.}
}