@article{HAN201841,
title = {Glacial and tidal strain of landfast sea ice in Terra Nova Bay, East Antarctica, observed by interferometric SAR techniques},
journal = {Remote Sensing of Environment},
volume = {209},
pages = {41-51},
year = {2018},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.02.033},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718300452},
author = {Hyangsun Han and Hoonyol Lee},
keywords = {Fast ice, Strain, Campbell Glacier Tongue, Terra Nova Bay, COSMO-SkyMed, InSAR, DDInSAR},
abstract = {The dynamics of landfast sea ice, also called fast ice for short, has a large influence on the variability of polynyas and marine ecosystems, and the logistics for research stations near the Antarctic coast. Therefore, it is important to accurately measure the strain of fast ice and its seasonal variations, and to identify the cause of stresses on the ice. In this paper, we separate the strains from glacial stress and tidal stress of fast ice near the Campbell Glacier Tongue (CGT) in Terra Nova Bay, East Antarctica. This was done using observations from a series of one-day tandem COSMO-SkyMed Interferometric Synthetic Aperture Radar (InSAR) images obtained from December 2010 to January 2012. Firstly, we discriminated fast ice from pack ice and open water by analyzing the interferometric coherence values. We then identified the characteristics of the strains by investigating the equi-displacement lines of fringes in weekly InSAR and double-differential InSAR (DDInSAR) images. The weekly InSAR images predominantly showed glacial shear strain of the fast ice with fringes parallel to the sides of the CGT. This was due to the cumulative flow of the CGT for a week, while oscillating tidal signals were relatively small. The DDInSAR images, which cancelled glacial strain rates in two one-day InSAR images, showed a deformation of the fast ice by tidal sea surface tilt, with the fringes parallel to the coastline. Based on the unique characteristics of these strains, we separated them from the one-day InSAR images by decomposing the fringe patterns into glacial and tidal strain. Glacial shear strain rates of fast ice attached to the east of the CGT decreased from May to August owing to ice thickening and then stabilized until December. Those to the west of the CGT increased from May to July. This was possibly due to bottom melting of the ice by the increased ocean circulation during the expansion period of the nearby polynya. The glacial strain then decreased until December because of reduced polynya activity. The fast ice near the Jang Bogo Station (JBS) only showed tidal strain as it was isolated from the CGT by cracks and leads. Tidal strain rates of the fast ice were strongly correlated with the magnitude of tidal variations in all these regions, which represents shows that the tidal strain represents tidal sea surface tilt. The tidal response of fast ice to the west of the CGT and near the JBS was stronger than that to the east of the CGT, probably owing to thinner ice thickness there.}
}
@article{SCOTTPARKER2018508,
title = {“You’re so used to having someone tell you what to do”: Experiences of young drivers during the provisional licence phase},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {56},
pages = {508-521},
year = {2018},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2018.03.027},
url = {https://www.sciencedirect.com/science/article/pii/S1369847818302432},
author = {B. Scott-Parker},
keywords = {Young driver, Learner, Provisional licence, Vehicle ownership, Driving skills},
abstract = {Objective
Young drivers are at considerable risk of injury and fatality during the earliest years of independent driving (provisional/intermediate/restricted/probationary licence). Interventions such as graduated driver licensing (GDL) are designed to ameliorate this risk by allowing young drivers to gain on-road driving experience under conditions of reduced risk (eg., night-time passenger restrictions in Queensland, Australia). Consistent with systems thinking, to maximise the effectiveness of interventions such as GDL it is essential that experiences of young drivers is understood. The aim of the research is to explore the experiences of young drivers with a provisional driver’s licence, within the current young driver road safety system in Queensland.
Methods
Thirty-four drivers (17–18 years; mean = 17.6, mode = 17, 14 males) with a provisional licence attending two high schools (one public, n = 21, 9 males; one private) participated in a 45-minute group discussion during the school day.
Results
Two themes emerged: (1) independence and (2) driving logistics. A wealth of experiences and advice pertaining to the sub-themes of psychosocial independence, transportation independence, driving skills and knowledge, interacting with other drivers, driving mistakes, and owning a vehicle were shared by young drivers. Numerous recommendations are made pertaining to each sub-theme, such as informing young drivers of the expense associated with independent mobility, effectively managing a road crash, and interacting safely with other drivers now there is no longer a driving supervisor sharing the journey with them.
Conclusions
Importantly these findings apply to young drivers in all motorised jurisdictions, irrespective of whether they have implemented a graduated driver licensing program. The breadth of experiences – many of which placed the young driver at increased risk of harm – shared by the young drivers should be considered in refining the content and process not only of any novice licence phase during which independent driving occurs, such as the provisional phase, but also of the preceding learning-to-drive licence phase. To illustrate, greater exposure to driving hazards like driving with peer passengers and sharing the road with larger vehicles can be undertaken in circumstances of increased driving ‘independence’ (that is, under less direction) during the final stages of the learner licence. This pseudo-independent driving is an opportunity to develop skills and capabilities in the potentially-risky circumstances which the novice will soon traverse without a supervisor’s support.}
}
@article{ALADAS2018739,
title = {Long-term decline in renal function is more significant after endovascular repair of infrarenal abdominal aortic aneurysms},
journal = {Journal of Vascular Surgery},
volume = {68},
number = {3},
pages = {739-748},
year = {2018},
issn = {0741-5214},
doi = {https://doi.org/10.1016/j.jvs.2017.12.051},
url = {https://www.sciencedirect.com/science/article/pii/S0741521418301691},
author = {Ziad {Al Adas} and Alexander D. Shepard and Timothy J. Nypaver and Mitchell R. Weaver and Thomas Maatman and Lenar T. Yessayan and Praveen Balraj and Loay S. Kabbani},
abstract = {Objective
It is not clear whether endovascular aneurysm repair (EVAR) of abdominal aortic aneurysms (AAAs) results in an increase in renal insufficiency during the long term compared with open repair (OR). We reviewed our experience with AAA repair to determine whether there was a significant difference in postoperative and long-term renal outcomes between OR and EVAR.
Methods
A retrospective cohort study was conducted of all patients who underwent AAA repair between January 1993 and July 2013 at a tertiary referral hospital. Demographics, comorbidities, preoperative and postoperative laboratory values, morbidity, and mortality were collected. Patients with ruptured AAAs, preoperative hemodialysis, juxtarenal or suprarenal aneurysm origin, and no follow-up laboratory values were excluded. Preoperative, postoperative, 6-month, and yearly serum creatinine values were collected. Glomerular filtration rate (GFR) was calculated on the basis of the Chronic Kidney Disease Epidemiology Collaboration equation. Acute kidney injury (AKI) was classified using the Kidney Disease: Improving Global Outcomes guidelines. Change in GFR was defined as preoperative GFR minus the GFR at each follow-up interval. Comparison was made between EVAR and OR groups using multivariate logistics for categorical data and linear regression for continuous variables.
Results
During the study period, 763 infrarenal AAA repairs were performed at our institution; 675 repairs fit the inclusion criteria (317 ORs and 358 EVARs). Mean age was 73.9 years. Seventy-nine percent were male, 78% were hypertensive, 18% were diabetic, and 31% had preoperative renal dysfunction defined as GFR below 60 mL/min. Using a multivariate logistic model to control for all variables, OR was found to have a 1.6 times greater chance for development of immediate postoperative AKI compared with EVAR (P = .038). Hypertension and aneurysm size were independent risk factors for development of AKI (P = .012 and .022, respectively). Using a linear regression model to look at GFR decline during several years, there was a greater decline in GFR in the EVAR group. This became significant starting at postoperative year 4. AKI and preoperative renal dysfunction were independent risk factors for long-term decline in renal function.
Conclusions
Although AKI is less likely to occur after EVAR, patients undergoing EVAR experience a significant but delayed decline in GFR over time compared with OR. This became apparent after postoperative year 4. Studies comparing EVAR and OR may need longer follow-up to detect clinically significant differences in renal function.}
}
@article{TSERTOU20162805,
title = {Dynamic and Synchromodal Container Consolidation: The Cloud Computing Enabler},
journal = {Transportation Research Procedia},
volume = {14},
pages = {2805-2813},
year = {2016},
note = {Transport Research Arena TRA2016},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2016.05.345},
url = {https://www.sciencedirect.com/science/article/pii/S2352146516303519},
author = {Athanasia Tsertou and Angelos Amditis and Evangelia Latsa and Ioannis Kanellopoulos and Michael Kotras},
keywords = {Container, consolidation, cloud computing, palette, supply chain, multimodality},
abstract = {Since the container became the dominant unit and driver of change in world-wide freight transport, the optimal utilization of container capacities has become a key challenge of the supply chain management. Fragments of customer orders often arrive to the final destination via different, sub-optimal routes which impose increased delivery times, costs and CO2 emissions to the global supply chain. This work describes how cloud computing is an enabler for addressing the issue of dynamic and synchro-modal container consolidation at the Piraeus Container Terminal, the fastest growing port in Europe according to recent studies. A significant barrier to an efficient container consolidation at port terminals is the reduced visibility and information exchange between related stakeholders on real-time location and status of a container and its contents. This is due to a multitude of reasons: the lack of a common standard for information exchange, competition matters, absence of trusted service providers collecting data, information shared on a next carrier basis without disseminating information to the rest stakeholders. Well-defined trigger points on standard routes may be reported by the carriers (e.g. arrival and shipment of goods, credit releases) and will allow for better monitoring of shipments and introduction of Key Performance Indicators for route evaluation and carrier performance. This work proposes a cloud-based information portal as an ICT enabling technology used as a single point of reference by supply chain stakeholders; the latter will use this portal to feed it with real-time information from existing platforms so that a better visibility for all parties is enabled. This portal will implement accessible interfaces with parties of each step of the transport process (e.g. interface with the customer, warehouse, next-leg carrier) using standardized formats as far as possible. It will allow for a flexible parameterization per customer and for a straightforward incorporation of regional special requirements, as is the constraint of single customer per container applicable in some countries. This portal will permit a better visibility level for end-customers, promote standardization of logistics processes, offer an increased profitability for cloud services providers, improve their activities expansion, as well as accelerate customs process handling. Nevertheless, even though cloud technology is mature enough, the trust level of stakeholders in security and reliability of such solutions needs to increase for a wide deployment.}
}
@article{FELDMAN20161535,
title = {Routine chlorhexidine gluconate use onboard navy surface vessels to reduce infection: A cluster randomized controlled trial},
journal = {American Journal of Infection Control},
volume = {44},
number = {12},
pages = {1535-1538},
year = {2016},
issn = {0196-6553},
doi = {https://doi.org/10.1016/j.ajic.2016.04.233},
url = {https://www.sciencedirect.com/science/article/pii/S0196655316304801},
author = {Lior Feldman and Eran Galili and Yuval Cohen and Michael Hartal and Nirit Yavnai and Itamar Netzer},
keywords = {Hand sanitizer, Infection prevention, Navy, Hand hygiene},
abstract = {Background
Hand disinfection with chlorhexidine gluconate (CHG) is commonly used for preventing the spread of infection in medical institutions and the community, but studies on its use in military settings have been inconclusive. We examined the effects of CHG on morbidity in Israeli Navy ships.
Methods
This was a controlled, cluster randomized study that took place at a major naval base in Israel. Ships were randomly selected into the study (347 sailors) and primary control (350 sailors) groups. Additional nonintervention control groups included other sailors serving on the base (n = 360) and logistics and support personnel (n = 859). CHG disinfection devices were installed on all ships in the study group, alongside soap and water. Morbidity was analyzed using a computerized patient record, subjective self-report questionnaires, and a sample of hand cultures. Compliance with hand hygiene was analyzed using a self-report hygiene attitudes questionnaire at the beginning of the trial and after 3 months. The study took place between May and September 2014.
Results
No significant differences were found between the groups in terms of sick days or light-duty days or in the number of acute gastrointestinal or respiratory cases. Sailors were found to have more skin infections than controls, but this was not significantly reduced by CHG. Hand cultures demonstrated that continuous use of CHG did not cause a reduction in colonization. There were no statistically significant differences in self-reported hygiene practices.
Conclusions
CHG did not demonstrate any medical benefit over the use of soap and water onboard Israeli Navy ships.}
}
@article{RENAUD20176862,
title = {Management practices for male calves on Canadian dairy farms},
journal = {Journal of Dairy Science},
volume = {100},
number = {8},
pages = {6862-6871},
year = {2017},
issn = {0022-0302},
doi = {https://doi.org/10.3168/jds.2017-12750},
url = {https://www.sciencedirect.com/science/article/pii/S0022030217305337},
author = {D.L. Renaud and T.F. Duffield and S.J. LeBlanc and D.B. Haley and D.F. Kelton},
keywords = {male calf, management, welfare},
abstract = {ABSTRACT
Morbidity, mortality, and antimicrobial use and resistance are major concerns in the rearing of male dairy calves, so information to support disease prevention is important. The objective of this cross-sectional study was to describe management practices associated with the care of male calves during their first days of life on Canadian dairy farms. A survey was completed by dairy producers across Canada between March 1 and April 30, 2015. The survey included 192 questions covering producer background, farm characteristics, biosecurity practices, disease prevalence, calf health, animal welfare, lameness, milking hygiene, reproduction, and Internet and social media use. A total of 1,025 surveys were completed online, by telephone, or by mail, representing 9% of all dairy farms in Canada. Five percent of respondents (n = 49) answered that they had euthanized at least 1 male calf at birth in the previous year, and blunt force trauma was commonly used in these cases. The majority of respondents always fed colostrum to male calves; however, 9% (n = 80) did not always feed colostrum. Almost 40% (n = 418) of respondents reported always dipping the navels of male calves, 12% (n = 123) vaccinated male calves, and 17% (n = 180) did not provide the same quantity of feed to male calves as heifer calves. The care of male calves differed greatly depending on the geographical region of the respondents. However, some regional effects may be confounded by economic conditions and the logistics of marketing male dairy calves in different parts of the country. Herd size was another important variable in many aspects of the management of male calves on dairy farms. Larger herd sizes were more likely to use an appropriate method of euthanasia at birth but were less likely to always feed colostrum to their male calves or feed them the same as female calves. Familiarity with the Code of Practice for the Care and Handling of Dairy Cattle (National Farm Animal Care Council) by respondents was associated with better care of male calves on dairy farms. The results of this survey suggest that the treatment of male dairy calves on Canadian dairy farms varies and that there are opportunities to improve the health management of male calves on the farms of origin.}
}
@article{LLORACHMASSANA2017121,
title = {Technical feasibility and carbon footprint of biochar co-production with tomato plant residue},
journal = {Waste Management},
volume = {67},
pages = {121-130},
year = {2017},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2017.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X17303422},
author = {Pere Llorach-Massana and Elisa Lopez-Capel and Javier Peña and Joan Rieradevall and Juan Ignacio Montero and Neus Puy},
keywords = {Tomato plant feedstock, Biochar, Carbon footprint, Heavy metals, Urban agriculture},
abstract = {World tomato production is in the increase, generating large amounts of organic agricultural waste, which are currently incinerated or composted, releasing CO2 into the atmosphere. Organic waste is not only produced from conventional but also urban agricultural practices due recently gained popularity. An alternative to current waste management practices and carbon sequestration opportunity is the production of biochar (thermally converted biomass) from tomato plant residues and use as a soil amendment. To address the real contribution of biochar for greenhouse gas mitigation, it is necessary to assess the whole life cycle from the production of the tomato biomass feedstock to the actual distribution and utilisation of the biochar produced in a regional context. This study is the first step to determine the technical and environmental potential of producing biochar from tomato plant (Solanum lycopersicum arawak variety) waste biomass and utilisation as a soil amendment. The study includes the characterisation of tomato plant residue as biochar feedstock (cellulose, hemicellulose, lignin and metal content); feedstock thermal stability; and the carbon footprint of biochar production under urban agriculture at pilot and small-scale plant, and conventional agriculture at large-scale plant. Tomato plant residue is a potentially suitable biochar feedstock under current European Certification based on its lignin content (19.7%) and low metal concentration. Biomass conversion yields of over 40%, 50% carbon stabilization and low pyrolysis temperature conditions (350–400°C) would be required for biochar production to sequester carbon under urban pilot scale conditions; while large-scale biochar production from conventional agricultural practices have not the potential to sequestrate carbon because its logistics, which could be improved. Therefore, the diversion of tomato biomass waste residue from incineration or composting to biochar production for use as a soil amendment would environmentally be beneficial, but only if high biochar yields could be produced.}
}
@article{GUNAY2016102,
title = {Conditional Freight Trip Generation modelling},
journal = {Journal of Transport Geography},
volume = {54},
pages = {102-111},
year = {2016},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2016.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0966692316302745},
author = {Gürkan Günay and Gökmen Ergün and Ilgın Gökaşar},
keywords = {Freight transportation planning, Freight trip generation, Tractor-trailer, Binary logit},
abstract = {Freight Trip Generation (FTG) in general and FTG modelling in particular are fields that are not concentrated upon as much as passenger trip generation. Therefore, the main objective of this work was to improve the understanding of the underlying processes that generate freight trips and through this understanding, to improve the modelling of FTG. To achieve this goal, the authors first had an extensive literature review to understand the reasons for the weaknesses of the current FTG modelling approaches. After identifying these weaknesses, some of them were brought to a focus in this work. One of the main weaknesses was the inadequacy of the classification system which was used to group commercial establishments in a set of standardized classes. Hence, firstly an experiment was conducted to create groups of logistical sites that had homogeneous FTG characteristics. It was observed that one of these segments had too many zero trips for a particular vehicle category, namely tractor-trailers. Then, to solve this problem, a new ‘conditional’ modelling approach for FTG modelling of this group and this vehicle category was proposed and tested using the data obtained from Kocaeli City Logistics Master Plan. This new hypothesised conditional approach aimed to find the probability of the segment generating tractor-trailer trips using the binary logit model and the generated trips given that the sites produced tractor-trailer trips using the regression technique. Afterwards, the models developed using the new approach were compared with the models obtained using only the common modelling approach of the regression analysis. The results indicated that creating homogeneous groups of logistical sites was possible and the new conditional modelling approach which was applied to one segment of the logistical sites for FTG of tractor-trailers, performed better than the regular regression modelling. Lastly, some recommendations for further improvement of this modelling approach were provided.}
}
@article{MATSUBAYASHI20173526,
title = {A Moving Source of Matrix Components Is Essential for De Novo Basement Membrane Formation},
journal = {Current Biology},
volume = {27},
number = {22},
pages = {3526-3534.e4},
year = {2017},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2017.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0960982217312691},
author = {Yutaka Matsubayashi and Adam Louani and Anca Dragu and Besaiz J. Sánchez-Sánchez and Eduardo Serna-Morales and Lawrence Yolland and Attila Gyoergy and Gema Vizcay and Roland A. Fleck and John M. Heddleston and Teng-Leong Chew and Daria E. Siekhaus and Brian M. Stramer},
keywords = {basement membrane, extracellular matrix, macrophage, hemocyte, cell migration, , morphogenesis, collagen IV, laminin, perlecan},
abstract = {Summary
The basement membrane (BM) is a thin layer of extracellular matrix (ECM) beneath nearly all epithelial cell types that is critical for cellular and tissue function. It is composed of numerous components conserved among all bilaterians [1]; however, it is unknown how all of these components are generated and subsequently constructed to form a fully mature BM in the living animal. Although BM formation is thought to simply involve a process of self-assembly [2], this concept suffers from a number of logistical issues when considering its construction in vivo. First, incorporation of BM components appears to be hierarchical [3, 4, 5], yet it is unclear whether their production during embryogenesis must also be regulated in a temporal fashion. Second, many BM proteins are produced not only by the cells residing on the BM but also by surrounding cell types [6, 7, 8, 9], and it is unclear how large, possibly insoluble protein complexes [10] are delivered into the matrix. Here we exploit our ability to live image and genetically dissect de novo BM formation during Drosophila development. This reveals that there is a temporal hierarchy of BM protein production that is essential for proper component incorporation. Furthermore, we show that BM components require secretion by migrating macrophages (hemocytes) during their developmental dispersal, which is critical for embryogenesis. Indeed, hemocyte migration is essential to deliver a subset of ECM components evenly throughout the embryo. This reveals that de novo BM construction requires a combination of both production and distribution logistics allowing for the timely delivery of core components.}
}
@article{BERSTEIN2017S367,
title = {M2 - Rare Variant Detection In Complex Disorders Using The Birthday Model},
journal = {European Neuropsychopharmacology},
volume = {27},
pages = {S367-S368},
year = {2017},
note = {Abstracts of the XXIV World Congress of Psychiatric Genetics (WCPG), 30 October - 4 November 2016, Jerusalem, Israel},
issn = {0924-977X},
doi = {https://doi.org/10.1016/j.euroneuro.2016.09.393},
url = {https://www.sciencedirect.com/science/article/pii/S0924977X16305892},
author = {Yael Berstein and Shane McCarthy and Melissa Kramer and Peter Zandi and Fernando Goes and James Potash and Richard McCombie},
abstract = {Background
Exome sequencing is a powerful technique for the identification of disease-causing genes. A number of disease genes with mendelian inheritance were already identified through this method. It nonetheless remains a challenge to leverage exome sequencing for the study of complex disorders, e.g. schizophrenia and bipolar disorder. The genetic and phenotypic heterogeneity of the data is a barrier to the detection of causative genes in complex disorders. For example, the aggregation of different rare variants associated with a given disease can make the identification of causal genes statistically challenging. Large sample sizes with >10,000 individuals were suggested as a mean to improve statistical power, although this may be sometimes unfeasible due to cost and logistics constrains. Therefore, new methods for detecting rare variants are imperative to identify causative genes of complex disorders.
Methods
Here we propose a probabilistic method to predict causative rare variants. This model is based on general analysis of coincidences based on a popular probabilistic problem: the birthday problem. Analogically, we consider the probability of samples sharing a variant, as the chance of individuals sharing the same birthday.
Results
We evaluated the performance of our method through simulations for identifying causal rare variants in complex disorders. We investigated the effect of the parameters of our model, providing guidelines for its use and interpretation of the results. We implemented this probabilistic method to published data on autism spectrum disorder, hypertriglyceridemia, schizophrenia, and also on a current case-control study on bipolar disorder. The top results based on our method were Sanger validated. Several genes in the top results were associated with psychiatric disorders in published studies.
Discussion
Given that the core probability based on the birthday model is very sensitive to low recurrence, the method successfully detect rare variants, which generally do not provide enough signal in existing statistical tests. The simplicity of the model allows quick interpretation of genomic data, enabling users to select gene candidates for further biological validation of specific mutations.}
}
@article{YUNE201654,
title = {Greening Chinese chemical industrial park by implementing industrial ecology strategies: A case study},
journal = {Resources, Conservation and Recycling},
volume = {112},
pages = {54-64},
year = {2016},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0921344916301033},
author = {Jeremy H. Yune and Jinping Tian and Wei Liu and Lujun Chen and Cathy Descamps-Large},
keywords = {Chemical industry park, Eco-industrial park, Green development, Economic and environmental assessment, Industrial ecology, China},
abstract = {China has witnessed a rapid development of the chemical industry and has become the largest chemicals producing country in the last decade, where more than 45% of the companies above designated-size have been clustered into a large number of chemical industrial parks. Greening the development of chemical industrial parks in China is crucial to local environment and has long been a big challenge. Deploying industrial ecology strategies in chemical industrial park will enhance both economic and environmental performances. This study reviewed the eco-industrial development in the Shanghai Chemical Industrial Park (SCIP) and its performance. SCIP is a newly established industrial park producing petrochemicals and downstream fine chemicals and is considered as a hallmark of the chemical industrial parks in China, in regards to eco-industrial development from the scratch and its good economic and environmental performances. The key lessons drawn from SCIP are as follows: (1) Its design and construction complies with a top-down and environmentally friendly pattern in line with industrial ecology strategy by integrating upstream and downstream chemicals, utilities and infrastructure, logistics, safety and environmental management, and public services within the park holistically, (2) SCIP created a vertically integrated chemicals manufacturing network, from naphtha to polymers, to extend the value chain as much as possible, via the geographical proximity of upstream-downstream linkage and economy of scale, (3) A delicately designed infrastructure and utility symbiotic network, logistic system, and 24-7 online safety and environmental management system sustained the food web efficiently. The implementation of top-down eco-industrial development planning and rich experience cumulated thereof in SCIP will be a benchmark and enlightenment of key factors for facilitating green development of other chemical industrial parks in China.}
}
@article{VAZQUEZ2016302,
title = {Automatic optimization of oilfield scale inhibitor squeeze treatment designs},
journal = {Journal of Petroleum Science and Engineering},
volume = {147},
pages = {302-307},
year = {2016},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2016.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0920410516302431},
author = {Oscar Vazquez and Ilya Fursov and Eric Mackay},
keywords = {Optimization, Squeeze treatments, Scale},
abstract = {Squeeze treatments are one of the most common methods to prevent oilfield scale deposition, which in turn is one of the most significant flow assurance challenges in the oil industry. Squeeze treatments consist of the batch injection of a chemical scale inhibitor (SI), which above a certain concentration, commonly known as MIC (Minimum Inhibitor Concentration), prevents scale deposition. The most important factor in a squeeze treatment design is the squeeze lifetime, which is determined by the volume of water or days of production where the chemical return concentration is above MIC, which commonly is between 1 and 20ppm. Typically, squeeze treatment designs include the following four stages: a preflush, acting as a buffer; the main slug, where the main chemical slug is injected; the overflush, which will displaced the chemical pill deeper into the formation and finally, a shut-in stage, which allows the chemical to be further retained in the formation. The main purpose of this paper is to describe the automatic optimization of squeeze treatment designs using an optimization algorithm, in particular, using particle swarm optimization (PSO). The algorithm provides the optimum design for a given set of criteria that are used in a purpose built reactive transport model of the near-wellbore area. Every squeeze design is fully determined by a number of parameters; namely, injected inhibitor concentration, main slug volume, overflush volume and shut-in time. The parameter space is bound to certain limits, which will be determined by the maximum injected concentration, main slug and overflush volumes. The maximum injected concentration might be determined by, amongst other issues, logistics, economics and/or compatibility with other chemicals. The main slug and overflush maximum volumes may be identified by the well engineer based on concerns of water formation damage, hydrate formation and/or gas lifting limitations, which might be lower for high value wells. This approach still requires engineering input and review, but speeds up the process of finding an optimum design, and reduces risk of non-optimal squeeze treatments being performed.}
}
@article{BOGATAJ201751,
title = {Mitigating risks of perishable products in the cyber-physical systems based on the extended MRP model},
journal = {International Journal of Production Economics},
volume = {193},
pages = {51-62},
year = {2017},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317302013},
author = {David Bogataj and Marija Bogataj and Domen Hudoklin},
keywords = {Cyber-physical systems, Smart home, Smart container, Food delivery, Post-harvest loss prevention, IoT, Material requirements planning theory, Collaborative cities},
abstract = {In the supply chain of fresh fruit and vegetables, large losses may incurred throughout the whole farm to fork route. Food supply chain management is faced with challenges of minimizing the post-harvest loss, while delivering the items directly to the refrigerators in smart homes (i.e. domotics). A substantial value can therefore be added to the criterion function by an immediate, real-time detection of changes in perishability dynamics, including a real-time calculation and communication of the remaining shelf life during transportation from one chain node to another. The changes in the estimated remaining shelf life can, therefore, be matched with the expected remaining transportation time, and so the critical moment can be avoided with a given probability. This can be done by dynamic rerouting in real time, based on previous net present value (NPV) criteria. Such criteria could then we include in the contractually stipulated remaining shelf life requirements at the delivery point. This paper focuses on a novel concept of moving activity cells which represent the moving cargo between the fixed activity cells in the extended material requirements planning (EMRP) model. The changes in NPV are calculated dynamically from the expected shelf life changes. Such real-time calculations and early reports are enabled by the Internet of Things (IoT) infrastructure, where there is a smart device that tracks ambient conditions like temperature, humidity, and gas concentrations. These early estimations allow a better decision making based on first-expired-first-out (FEFO) cold chain management strategies for perishable products. Therefore, the model includes the possibility to deliver the items to the local market if the expected contractually stipulated shelf-life losses become too high. The paper does not intend to discuss the details of IoT or analyse different sensors, but it wishes to show how the EMRP theory can be used to estimate the changes in NPV when moving activity cells are included in the model. The smart measurement devices embedded in moving activity cells of cyber-physical system measure the ambient data and broadcast decay acceleration factors and postharvest loss of cargo to the decision support system. The numerical example shows how smart measurement devices embedded in moving activity cells of cyber-physical system help to reduce the post-harvest loss in a supply chain by rerouting when necessary. The paper additionally shows how much such a cyber-physical system improves NPV by the development of decision-making processes in the real-time, using the IoT as infrastructure, including automatic rerouting in postharvest logistics.}
}
@article{PRINSEN2018A211,
title = {PO-484 Development of a two-step screening-and-confirmation approach to efficiently identify synergistic drug combinations with the PARP inhibitor niraparib},
journal = {ESMO Open},
volume = {3},
pages = {A211-A212},
year = {2018},
note = {Abstracts of the 25th Biennial Congress of the European Association for Cancer Research, Amsterdam, The Netherlands, 30 June – 3 July 2018},
issn = {2059-7029},
doi = {https://doi.org/10.1136/esmoopen-2018-EACR25.502},
url = {https://www.sciencedirect.com/science/article/pii/S2059702920305263},
author = {M.B.W. Prinsen and J.R.F. {De Vetter} and J. Dylus and J.A.D.M. De Roos and S.J.C. Van Gerwen and R.C. Buijsman and J.C.M. UItdehaag},
abstract = {ABSTRACT
Introduction
Poly (ADP-ribose) polymerases (PARPs) are important players in DNA damage repair. Inhibition of PARP activity is highly effective against cancers deficient in homologous recombination repair due to, a.o., BRCA1/2 mutations. Clinically, PARP inhibitors (PARPi) are used to treat, a.o., ovarium cancers. Although effective, repeated treatment with PARPi may lead to resistance. To identify new synergistic drug combinations, we developed a two-step approach of screening and confirmation using two of our platform technologies SynergyScreen and SynergyFinder. We first screen for synergy in presence of a fixed concentration of compound (e.g., PARPi), followed by confirmation using dose response curves. The PARPi niraparib was used as a proof-of-concept combinatorial drug at a fixed concentration, and combined with over 150 anti-cancer agents.
Material and methods
Proliferation of cell lines and patient derived primary ovarium cancer cells was measured using ATPLite 1 Step after 120 hours compound incubation. Growth was calculated relative to vehicle treated cells; relative IC50s were calculated from a four parameter logistics curve. The fixed concentration niraparib used in the SynergyScreen represented 80% viability. Anti-cancer agents were screened in absence and presence of niraparib, followed by analysis of IC50 shifts. Combinations with IC50shifts>2 fold indicated a synergistic hit and were re-examined using equipotent mixtures and calculation of Combination Index (CI) within our SynergyFinder platform.1 CI <1 indicates synergy. As a control, the combinatorial drug was tested against itself.
Results and discussions
Results of the SynergyScreen showed various synergistic drug combinations from the high-throughput setup, i.e. niraparib in combination with the topoisomerase I inhibitor irinotecan (CI0.5=0.70) and the DNA alkylating agent temozolomide (CI0.5=0.42). These and other synergies were confirmed in patient samples. Independently from niraparib, the bromodomain inhibitor JQ1 and the histone acetyltransferase inhibitor anacardic acid showed synergy (CI0.5 0.42), which was not demonstrated before.
Conclusion
Our Synergy platforms can identify novel and reproducible synergistic drug combinations in an unbiased and efficient manner. Proof-of-concept was demonstrated and new synergistic drug combinations were found. Our method is therefore excellently suited for the in vitro discovery and validation of synergistic combinations.
Reference
1.Uitdehaag, et al. PLoS ONE 2015;10(5): e0125021.}
}
@article{POUW2016497,
title = {The hidden sentinel node in breast cancer: Reevaluating the role of SPECT/CT and tracer reinjection},
journal = {European Journal of Surgical Oncology (EJSO)},
volume = {42},
number = {4},
pages = {497-503},
year = {2016},
issn = {0748-7983},
doi = {https://doi.org/10.1016/j.ejso.2015.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0748798316000354},
author = {B. Pouw and D. Hellingman and M. Kieft and W.V. Vogel and K.J. {van Os} and E.J.T. Rutgers and R.A. {Valdés Olmos} and M.P.M. Stokkel},
keywords = {SPECT/CT, Breast cancer, Sentinel node, SLNB, Non-visualisation},
abstract = {Introduction
Lymphoscintigraphy with planar imaging is considered a helpful tool to depict lymph node drainage in patients with invasive breast cancer. Single Photon Emission Computed Tomography with integrated CT (SPECT/CT) is usually performed to detect sentinel nodes (SN)s in breast cancer patients showing non-visualisation on lymphoscintigraphy. Incorporation of new SN indications (recurrent surgery, previous radiotherapy, or neo-adjuvant chemotherapy) has led to an increase of non-visualisation rates. The present study evaluates the contribution of SPECT/CT and tracer reinjection for SN-visualisation in breast cancer patients without drainage on lymphoscintigraphy.
Methods
Between 1st of July 2008 and 6th of November 2014 in total 1968 patients underwent a SN breast procedure, using intra-tumoural tracer administration. SPECT/CT was performed in 284 breast cancer patients with non-visualisation of SNs on lymphoscintigraphy. If SN non-visualisation persisted, a second radiotracer injection with repeated imaging was performed when logistics allowed this. Univariate analysis was applied to evaluate SPECT/CT visualisation rates in specific subgroups.
Results
The SPECT/CT visualisation rate was 23.2% (66/284). Univariate analysis revealed no significant subgroups influencing SPECT/CT visualisation. In patients receiving reinjection after persistent SPECT/CT non-visualisation the SN-visualisation rate reached 62.1% (36/58). Intraoperatively, the SN-identification rate using a gamma probe and blue dye was 87.9% (175/199) and 32.9% (28/85) for, respectively, primary and recurrent surgery after non-visualisation on lymphoscintigraphy.
Conclusion
In this evaluation including new breast cancer SN indications, SPECT/CT scored lower than reinjection to visualise SNs in patients with non-visualisation on lymphoscintigraphy. Consequently, our institutional protocol has been readjusted.}
}
@article{WANG2018244,
title = {Two-echelon location-routing optimization with time windows based on customer clustering},
journal = {Expert Systems with Applications},
volume = {104},
pages = {244-260},
year = {2018},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0957417418301581},
author = {Yong Wang and Kevin Assogba and Yong Liu and Xiaolei Ma and Maozeng Xu and Yinhai Wang},
keywords = {Location routing optimization with time windows, Periodic demand forecasting, Customer clustering, Validity measurement function, Non-dominated Sorting Genetic Algorithm-II (NSGA-II)},
abstract = {This paper develops a three-step customer clustering based approach to solve two-echelon location routing problems with time windows. A bi-objective model minimizing costs and maximizing customer satisfaction is formulated along with an innovative measurement function to rank optimal solutions. The proposed methodology is a knowledge-based approach which considers customers locations and purchase behaviors, discovers similar characteristics among them through clustering, and applies exponential smoothing method to forecast periodic customers demands. We introduce a Modified Non-dominated Sorting Genetic Algorithm-II (M-NSGA-II) to simultaneously locate logistics facilities, allocate customers, and optimize the vehicle routing network. Different from many existing version of NSGA-II, our algorithm applies partial-mapped crossover as genetic operator, instead of simulated binary crossover, in order to properly handle chromosomes. The initial population is generated through a nodes’ scanning algorithm which eliminates sub-tours. Finally, to demonstrate the applicability of our mathematical model and approach, we conduct two empirical studies on generated benchmarks and the distribution network of a company in Chongqing city, China. Further comparative analyses with multi-objective genetic algorithm (MOGA) and multi-objective particle swarm optimization (MOPSO) algorithm indicate that M-NSGA-II performs better in terms of solution quality and computation time. Results also support that: (1) the formation of clusters containing highly similar customers improves service reliability, and favors a productive customer relationship management; (2) considering product preference contributes to maximizing customer satisfaction degree and the effective control of inventories at each distribution center; (3) clustering, instead of helping to improve services, proves detrimental when too many groups are formed. Thus, decision makers need to conduct series of simulations to observe appropriate clustering scenarios.}
}
@article{KHAN20162074,
title = {Challenges to health workers and their opinions about parents’ refusal of oral polio vaccination in the Khyber Pakhtoon Khawa (KPK) province, Pakistan},
journal = {Vaccine},
volume = {34},
number = {18},
pages = {2074-2081},
year = {2016},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X1600298X},
author = {Tahir Mehmood Khan and Muhammad Umar Khayam Sahibzada},
keywords = {Polio, Vaccination, Health workers, Challenges, Parent's attitude, Vaccination refusal},
abstract = {A qualitative study design was adapted to explore the challenges faced by health workers (HWs) during the polio health campaign. In addition, HWs’ opinions about the factors causing parents to refuse oral polio vaccination (OPV) were also explored. Four focus group discussions (FGDs) were held (from 1st January 2015–31st March 2015) with the HWs who participated in the OPV campaigns in the polio red zones of Khyber Pakhtoon Khawa (KPK) province of Pakistan, namely Kohat (FG 1), Domel and Bannu (FG 2), Hangoo (FG 3), and Peshawar (FG 4). A total of N=42 HWs (10–11 in each FG) agreed to participate in this study. Overall, HWs disclosed that public attitude and harsh behaviour towards the HWs and security threats are the two main challenges they face. Common issues hindering parents’ willingness to vaccinate their children against OPV are: OPV is seen as haram and not permitted in Islam, it is said to contain the blood of pigs (Khinzir) and monkeys, and parents are afraid that it is done to induce sterility among their children. HWs also shared that parents have a strong belief in the conspiracies that are associated with OPV, i.e. the USA and CIA, are spying on us and our government is helping them to achieve their agenda. Furthermore, HWs revealed that frequent visits may further strengthen parents’ perceptions and make them more resistant to OPV. The common side effects of OPV reported by parents were mainly gastro-intestinal problems and in some cases mild to moderate fever with some respiratory symptoms. There is a great need to improve the logistics and facilities for HWs assisting in vaccination programmes. Furthermore, it is necessary to improve education, so people understand the basic concept of revaccination and booster doses, thereby assisting in creating a basic understanding of vaccinations, which may trigger changes in attitudes and make people believe in the benefits of OPV rather than following the conspiracies that lead them to refuse it.}
}
@article{SHARAIHA2017904,
title = {Efficacy and safety of EUS-guided biliary drainage in comparison with percutaneous biliary drainage when ERCP fails: a systematic review and meta-analysis},
journal = {Gastrointestinal Endoscopy},
volume = {85},
number = {5},
pages = {904-914},
year = {2017},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2016.12.023},
url = {https://www.sciencedirect.com/science/article/pii/S0016510716309002},
author = {Reem Z. Sharaiha and Muhammad Ali Khan and Faisal Kamal and Amy Tyberg and Claudio R. Tombazzi and Bilal Ali and Claudio Tombazzi and Michel Kahaleh},
abstract = {Background and Aims
EUS-guided biliary drainage (EUS-BD) is increasingly used as an alternate therapeutic modality to percutaneous transhepatic biliary drainage (PTBD) for biliary obstruction in patients who fail ERCP. We conducted a systematic review and meta-analysis to compare the efficacy and safety of these 2 procedures.
Methods
We searched several databases from inception to September 4, 2016 to identify comparative studies evaluating the efficacy and safety of EUS-BD and PTBD. Primary outcomes of interest were the differences in technical success and postprocedure adverse events. Secondary outcomes of interest included clinical success, rate of reintervention, length of hospital stay, and cost comparison for these 2 procedures. Odds ratios (ORs) and standard mean difference were calculated for categorical and continuous variables, respectively. These were analyzed using random effects model of meta-analysis.
Results
Nine studies with 483 patients were included in the final analysis. There was no difference in technical success between 2 procedures (OR, 1.78; 95% CI, .69-4.59; I2 = 22%) but EUS-BD was associated with better clinical success (OR, .45; 95% CI, .23-.89; I2 = 0%), fewer postprocedure adverse events (OR, .23; 95% CI, .12-.47; I2 = 57%), and lower rate of reintervention (OR, .13; 95% CI, .07-.24; I2 = 0%). There was no difference in length of hospital stay after the procedures, with a pooled standard mean difference of –.48 (95% CI, –1.13 to .16), but EUS-BD was more cost-effective, with a pooled standard mean difference of –.63 (95% CI, –1.06 to –.20). However, the latter 2 analyses were limited by considerable heterogeneity.
Conclusions
When ERCP fails to achieve biliary drainage, EUS-guided interventions may be preferred over PTBD if adequate advanced endoscopy expertise and logistics are available. EUS-BD is associated with significantly better clinical success, lower rate of postprocedure adverse events, and fewer reinterventions.}
}
@article{FERNANDES2017107,
title = {Increasing the stamping tools lifespan by using Mo and B4C PVD coatings},
journal = {Surface and Coatings Technology},
volume = {325},
pages = {107-119},
year = {2017},
issn = {0257-8972},
doi = {https://doi.org/10.1016/j.surfcoat.2017.06.043},
url = {https://www.sciencedirect.com/science/article/pii/S0257897217306473},
author = {L. Fernandes and F.J.G. Silva and M.F. Andrade and R. Alexandre and A.P.M. Baptista and C. Rodrigues},
keywords = {Stamping, Friction, Tool lifespan, Tinplate,  coating,  coating},
abstract = {Prestigious brands of cookies usually use metallic tins as packaging to distribute and sell their products, trying to impress the customer through the appearance of the packaging and avoiding smashing or damages to the cookies during logistics operations. These packages are commonly made in a tin coated (2.8g/m2) thin steel sheet (ARCELOR electrolytic Tin plate), which causes severe wear problems on both die and punch tool components during the stamping process at room temperature. The border of the package presents an inconsiderable deformation, despite its almost perpendicular orientation to the top surface, but this top is usually patterned, which also implies the flow of the sheet between the top and bottom die surfaces. Due to the softness of the Tin coating, it easily adheres to the die, generating premature wear and several other concerns in maintaining the required final shape of the tin lid. Lubrication would be an easy way to solve the problems referred above, but lubrication operations should be avoided because these kind of packages are for food purposes. This study started by identifying the main wear mechanism developed in the stamping tool main surfaces, characterized by the Tin coated steel sheet used in the packages and testing two advanced PVD coatings (B4C and Mo) leading to the improvement of punch and die wear behavior under these work conditions. The transfer of Tin material from the metallic sheet to the punch and die was also studied, as well as the friction coefficient of this sheet against some selected coatings, while also trying to minimize the Tin adherence to the tool surfaces. Tribological tests under medium loads were carried out in order to ascertain what kind of coating presents better wear behavior in those work conditions. Regarding the results obtained, some improvements will be applied to the coating structure to adjust the deposition parameters in order to go forward to industrial tests. Worn surfaces were studied by Scanning Electron Microscopy (SEM) and material transfer was analyzed by Energy Dispersive Spectroscopy (EDS). Results obtained with some of the tested coatings confirm that it is possible to minimize the Tin transfer from the covered steel sheet to the die and punch, ensuring a longer life of these parts, decreasing the tool maintenance operations and improving the Overall Equipment Efficiency (OEE) of that stamping process.}
}
@article{YU20166,
title = {Open vehicle routing problem with cross-docking},
journal = {Computers & Industrial Engineering},
volume = {94},
pages = {6-17},
year = {2016},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2016.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0360835216300110},
author = {Vincent F. Yu and Parida Jewpanya and A.A.N. Perwira Redi},
keywords = {Cross-docking, Open vehicle routing problem, Simulated annealing},
abstract = {The advantages of the cross-docking technique have been increasingly appreciated in literature and in practice. This appreciation, coupled with the advances of numerous applications in the vehicle routing problem (VRP) across numerous practical contexts, presents an opportunity to explore the open VRP with cross-docking (OVRPCD). We introduce a general example in retail wherein the capital expenditure necessary in vehicle acquisition can become a burden for the retailer, who then needs to consider outsourcing a logistics service as a cost-effective option. This practical scenario can be applied to create an open flow network of routes. This study considers a single product and single cross-dock wherein capacitated homogeneous vehicles start at different pickup points and times during pickup operations. The vehicles are scheduled to route in the network synchronously to arrive at the cross-dock center simultaneously. In the delivery operations, all customers must be served at most once and deliveries should be finished within a predetermined duration. We model OVRPCD as a mixed-integer linear program that minimizes the total cost (vehicle hiring cost and transportation cost). A simulated annealing (SA) algorithm is proposed to solve the problem. SA is first verified by solving benchmark instances for the vehicle routing problem with cross-docking and comparing the results with those obtained by existing ​state-of-art algorithms. We then test SA on three sets of OVRPCD benchmark instances and the results are compared with those obtained by CPLEX. Computational results show that both CPLEX and SA can obtain optimal solutions to all small and medium instances. However, the computational time required by SA is shorter than that needed by CPLEX. Moreover, for large instances, SA outperforms CPLEX in both solution value and computational time.}
}
@article{ALWAN2017349,
title = {Strategic sustainable development in the UK construction industry, through the framework for strategic sustainable development, using Building Information Modelling},
journal = {Journal of Cleaner Production},
volume = {140},
pages = {349-358},
year = {2017},
note = {Systematic Leadership towards Sustainability},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2015.12.085},
url = {https://www.sciencedirect.com/science/article/pii/S0959652615019101},
author = {Zaid Alwan and Paul Jones and Peter Holgate},
keywords = {Framework for strategic sustainable development, Sustainability principles, Modern methods of construction, Building Information Modelling, Waste and energy reduction},
abstract = {The UK Government has set out ambitious plans for all new domestic and commercial buildings to be zero carbon rated by 2016 and 2020 respectively. These are some of the most progressive environmental targets for the built environment in the western world. However, there are also other sustainability issues that need to be addressed by the UK construction industry, particularly negative impacts from the generation of waste. Currently, 100 million tonnes of construction waste, including 13 million tonnes of unused materials, is generated each year, with only 20% currently capable of being recycled. The majority of this waste ends up in landfill, contributing to further pollution of the biosphere. The literature suggests that these negative impacts result from a variety of causes, including ineffective leadership, ingrained cultures, outdated technologies and poor logistics. There are a number of innovative projects within the UK, particularly at a local level, that pose the question as to whether bottom up approaches may be more successful than top down policies, as set by national and local government. This paper presents a case study demonstrating the former approach within the construction industry. Research and consultancy has been undertaken collaboratively between industry, academia and professional practice in the production of 15 individually designed sustainable dwellings in the North East of England. This project has employed Building Information Modelling (BIM) as a new collaborative working platform, aligned to the Modern Method of Construction (MMC). By situating this inquiry within an authentic case study it has highlighted ineffective strategies, policies and leadership, which have prevented full exploitation of the potential of BIM and MMC towards sustainable production. This inquiry supports the integration of the Framework for Sustainable Strategic Development (FSSD) into construction procurement, as a method for implementing bottom up leadership in a value driven project.}
}
@incollection{LAZAR2017493,
title = {Chapter 16 - Working with research participants with disabilities},
editor = {Jonathan Lazar and Jinjuan Heidi Feng and Harry Hochheiser},
booktitle = {Research Methods in Human Computer Interaction (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {493-522},
year = {2017},
isbn = {978-0-12-805390-4},
doi = {https://doi.org/10.1016/B978-0-12-805390-4.00016-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128053904000169},
author = {Jonathan Lazar and Jinjuan Heidi Feng and Harry Hochheiser},
keywords = {Perceptual impairment, Motor impairment, Cognitive impairment, Accessibility, Blind, Deaf, Captioning, Situational impairment, Deaf culture, Visual impairment, Inclusion criteria, Web Content Accessibility Guidelines, Employment, Modifications, Accommodations, Barriers, Interventions, Advocacy groups, Interpreter, Sign language, Augmentative and alternative communication (AAC) device, Proxy users, Caregivers, Braille, Sample sizes, Distributed research, Case study, Pilot studies, Screen readers, Intellectual disabilities, Signature guide},
abstract = {It is important that users with disabilities be involved with all types of human-computer interaction (HCI) research. Furthermore, many technologies that start out as designed for people with disabilities, later become mainstream technologies enjoyed by all (e.g., captioning, e-books, and voice recognition), and therefore, HCI research involving people with disabilities, has an impact on all HCI research. It is therefore important to pay close attention to the best practices in doing HCI research involving people with disabilities. This chapter describes how research involving people with disabilities, may differ from research with the general population. This chapter describes three areas which researchers need to pay careful attention to: (1) participants, (2) logistics, and (3) research methodology. Due to the diversity of disability, researchers need to pay careful attention to ensuring that the participants are the “right” ones for a study, meaning that the participants meet all of the inclusion criteria, including type of employment, technology experience, and specific qualities of their disability and their related skills (e.g., sign language, Braille, etc.). Participant recruitment may be challenging, and the chapter describes some possible techniques for recruitment, such as partnering with advocacy organizations, and doing distributed research. When recruiting participants with disabilities, it is important to ensure that your facilities and materials are fully accessible for your participants. For instance, you need to ensure that the building and any rooms where the research will take place, are accessible for wheelchairs, there is appropriate Braille signage on the doorways, and sign language interpreters are available when needed. The materials, such as any handouts, or institutional review board forms, as well as payment details, must also be accessible. The overall research methods (experimental design, surveys, time diaries, case studies, etc.) are typically the same as for research involving other users. However for people with cognitive disabilities, individual modifications to the research methods may sometimes need to be made. This chapter provides a step-by-step guide to creating successful HCI research involving people with disabilities.}
}
@article{CHEN2017111,
title = {A particle swarm approach for optimizing a multi-stage closed loop supply chain for the solar cell industry},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {43},
pages = {111-123},
year = {2017},
note = {Special Issue: Extended Papers Selected from FAIM 2014},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2015.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0736584515001180},
author = {Yi-Wen Chen and Li-Chih Wang and Allen Wang and Tzu-Li Chen},
keywords = {Closed-loop supply chain design, Multi-objective searching, Particle swarm optimization, Solar energy industry},
abstract = {In order to implement sustainable strategies in a supply chain, enterprises should provide highly favorable and effective solutions for reducing carbon dioxide emissions, which brings out the issues of designing and managing a closed-loop supply chain (CLSC). This paper studies an integrated CLSC network design problem with cost and environmental concerns in the solar energy industry from sustainability perspectives. A multi-objective closed-loop supply chain design (MCSCD) model has been proposed, in consideration of many practical characteristics including flow conservation at each production/recycling unit of forward/reverse logistics (FL/RL), capacity expansion, and recycled components. A deterministic multi-objective mixed integer linear programming (MILP) model capturing the tradeoffs between the total cost and total CO2 emissions was developed to address the multistage CSLC design problem. Subsequently, a multi-objective PSO (MOPSO) algorithm with crowding distance-based nondominated sorting approach is developed to search the near-optimal solution of the MCSCD model. The computational study shows that the proposed MOPSO algorithm is suitable and effective for solving large-scale complicated CLSC structure than the conventional branch-and-bound optimization approach. Analysis results show that an enterprise needs to apply an adequate recycling strategy or energy saving technology to achieve a better economic effectiveness if the carbon emission regulation is applied. Consequently, the Pareto optimal solution obtained from MOPSO algorithm may give the superior suggestions of CLSC design, such as factory location options, capacity expansion, technology selection, purchasing, and order fulfillment decisions in practice.}
}
@article{MOZOSBLANCO201845,
title = {The way to sustainable mobility. A comparative analysis of sustainable mobility plans in Spain},
journal = {Transport Policy},
volume = {72},
pages = {45-54},
year = {2018},
issn = {0967-070X},
doi = {https://doi.org/10.1016/j.tranpol.2018.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0967070X17301300},
author = {Miguel Ángel Mozos-Blanco and Elisa Pozo-Menéndez and Rosa Arce-Ruiz and Neus Baucells-Aletà},
keywords = {Urban and metropolitan mobility, Evaluation, SUMP, Sustainable mobility, Indicators},
abstract = {After the approval and implementation of Sustainable Urban Mobility Plans (SUMP) in different cities of Spain, the evolution and the level of development of each one are still unknown. In fact, as many of them were approved before 2010, they didn't include a precise methodology for the further analysis of the proposed and/or implemented mobility measures. So, this evaluation of the mobility plans, their results and the comparison between cities and their evolution towards a more sustainable mobility represents nowadays a challenge in many cases. In 2011, the Spanish Law for a Sustainable Economy (Law 2/2011) was approved, which encouraged local administrations to create a SUMP. The approval of a SUMP was compulsory to local authorities to get any public funding for public transport projects. The main objectives of these plans were not only the reduction of the urban congestion and pollution, but also to encourage the citizens to change their habits so they are less car-dependent and more active in their daily trips. However, it is still necessary an evaluation to confirm that these SUMPs have represented a substantial change in terms of logistics and management of the transports and vehicles, both private and public, as well as of behaviour and habits of the citizens. The main objective of this paper is to show the results of a research conducted on 38 Sustainable Urban Mobility Plans. The cities are all members of the Spanish Network of Smart Cities (Red Española de Ciudades Inteligentes -RECI-). The SUMPs are analysed, addressing the identification and evaluation of the different specifically proposed mobility measures included in plans, the degree of definition of them, the costs, the implementation programs, etc. Also, follow-up programs were discussed. First, an analysis was made of the diagnosis of the mobility situation in each location according to the diagnosis document included in many of the SUMPs. The second stage consisted on the analysis of the measures in the plan, considering sixteen indicators, such as accessibility, intermodality, pedestrians or design of public space. Finally, it was also determined whether the document included a monitoring plan, a budget and a timeline. Through the comparison of the results, we obtain a brief overview about the evolution of efforts to get a more sustainable mobility in Spain. With these results, we finish our study proposing some guidelines for further analysis as well as for the new SUMPs that will be approved on the following years.}
}
@article{HESSLE2017105,
title = {Combining environmentally and economically sustainable dairy and beef production in Sweden},
journal = {Agricultural Systems},
volume = {156},
pages = {105-114},
year = {2017},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2017.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X17305437},
author = {Anna Hessle and Jan Bertilsson and Bo Stenberg and Karl-Ivar Kumm and Ulf Sonesson},
keywords = {Sustainable food chains, LCA, Food system scenarios, Cattle, Milk, Beef},
abstract = {To achieve a more sustainable food sector, a supply chain approach is needed. In this study, experts in different areas along supply chains co-operated in an interactive process to define future environmentally sustainable supply chains of milk and beef. The basis was to use existing techniques, to have production performance corresponding to the best quartile of today and to consider other sustainability aspects, such as economics. The work resulted in concrete descriptions of alternative product chains for delivered milk and beef. To also permit concrete descriptions of the latter part of the product chains, two consumer-packed end products were selected for monitoring, namely fresh milk and sirloin steak. The production systems investigated comprised cropping, livestock production, industrial processing and production, logistics, packaging and wastage and distribution, but not retailers or consumers. The study area was a Swedish county and the reference level was its production of milk and beef in 2012. The future product chains were assumed to deliver the same amounts of commodities as in 2012, but with reduced environmental impact. Primary production was required to be at least as profitable as today. Beside description of the current situation, three alternative scenarios were created, focusing on delivery of ecosystem services, plant nutrient circulation and minimising climate impact, respectively. Life cycle assessments were performed for these four scenarios (reference plus three alternative scenarios) for single-product chains and county-wide. Furthermore, production costs in primary production were calculated for the four scenarios. The results revealed great potential to reduce the negative environmental impact of Swedish dairy and beef production at current volumes, irrespective of whether ecosystem services, plant nutrient circulation or climate impact is in focus. The single most important factor for decreased environmental impact for livestock production was increased production efficiency. Measures in agriculture, especially concerning feeds, were critical, but actions in processing and distribution also contributed. All alternative scenarios resulted in lower production costs than at present. It was obvious that as dairy and beef systems are connected, the potential for their environmental improvement must be analysed together. In conclusion, increased efficiency can decrease the negative environmental impact of Swedish cattle production and also reduce costs to the farmer.}
}
@article{DIENER201648,
title = {Scrapping steel components for recycling—Isn’t that good enough? Seeking improvements in automotive component end-of-life},
journal = {Resources, Conservation and Recycling},
volume = {110},
pages = {48-60},
year = {2016},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2016.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0921344916300350},
author = {Derek L. Diener and Anne-Marie Tillman},
keywords = {Product end-of-life management, Functional recycling, ELV, Life cycle management (LCM)},
abstract = {Life cycle management (LCM) suggests that companies take responsibility for the entire lifecycle of their products, either alone or together with other lifecycle actors. This paper examines the case of an automotive component manufacturer that has committed to LCM and wants to investigate product end of life (EoL) management despite the fact that it is a couple stages removed from the vehicle end-user and EoL vehicle (ELV) handling. Material flow analysis (MFA) is used to estimate and create Sankey diagrams of the downstream flows of two components made of low-alloyed steel, one wheel component and one gearbox component. Product sales data was analyzed and composition and design trends were considered to add perspectives beyond those yielded by looking at the bulk material flow. The components of interest are not remanufactured themselves but the gearboxes in which they sit are. Remanufacturers of gearboxes visited indicated a great variability in how much they replace the components of interest suggesting an opportunity for the case company to support remanufacturers in quality control and extension of use life. In regards to component EoL, many components are sent through shredding as part of ELV treatment but a comparable amount is liberated from vehicles and scrapped during vehicle maintenance. Regardless, the components end up in mixed scrap and alloying elements are rarely functionally recycled. According to commodity experts, an alternative to handle such components separately for functional recycling is practically limited. Component quantities and their values do not appear to justify additional administration and transport that would be require to sort, store and collect them. Accordingly, when considering societal interest to increase functional recycling and to activate the circular economy, it seems warranted to investigate what a recycling program for similar material grades could yield and subsequently, to consider what collaborative efforts or policy intervention would be relevant.}
}
@article{KRISTENSEN2016899,
title = {Can thermostable vaccines help address cold-chain challenges? Results from stakeholder interviews in six low- and middle-income countries},
journal = {Vaccine},
volume = {34},
number = {7},
pages = {899-904},
year = {2016},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X16000189},
author = {Debra D. Kristensen and Tina Lorenson and Kate Bartholomew and Shirley Villadiego},
keywords = {Cold chain, Vaccine stability, Thermostable, Controlled-temperature chain},
abstract = {Introduction
This study captures the perspectives of stakeholders at multiple levels of the vaccine supply chain regarding their assessment of challenges with storing vaccines within recommended temperature ranges and their perceptions on the benefits of having vaccines with improved stability, including the potential short-term storage and transport of vaccines in a controlled-temperature chain.
Methods
Semi-structured interviews were undertaken with 158 immunization stakeholders in six countries. Interviewees included national decision-makers and advisors involved in vaccine purchasing decisions, national Expanded Programme on Immunization managers, and health and logistics personnel at national, subnational, and health facility levels.
Results
Challenges with both heat and freeze-exposure of vaccines were recognized in all countries, with heat-exposure being a greater concern. Conditions leading to freeze-exposure including ice build-up due to poor refrigerator performance and improper icepack conditioning were reported by 53% and 28% of participants, respectively. Respondents were interested in vaccine products with improved heat/freeze-stability characteristics. The majority of those involved in vaccine purchasing indicated they would be willing to pay a US$0.05 premium per dose for a freeze-stable pentavalent vaccine (68%) or a heat-stable rotavirus vaccine (59%), although most (53%) preferred not to pay the premium for a heat-stable pentavalent vaccine if the increased stability required changing from a liquid to a lyophilized product. Most respondents (73%) were also interested in vaccines labeled for short-term use in a controlled-temperature chain. The majority (115/158) recognized the flexibility this would provide during outreach or should cold-chain breaks occur. Respondents were also aware that possible confusion might arise and additional training would be required if handling conditions were changed for some, but not all vaccines.
Conclusion
Participating immunization stakeholders recognized the benefits of vaccine products with improved stability characteristics and of labeling vaccines for controlled-temperature chain use as a means to help address cold-chain issues in their immunization programs.}
}
@article{SEIBERT201791,
title = {Comparison of hydrogen and hydrogen-rich reformate enrichment of JP-8 in an open flame},
journal = {Fuel},
volume = {210},
pages = {91-97},
year = {2017},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2017.08.056},
url = {https://www.sciencedirect.com/science/article/pii/S0016236117310414},
author = {Michael Seibert and Sen Nieh},
keywords = {Hydrogen, Autothermal reforming, External combustion, Jet fuel},
abstract = {Hydrogen enhanced combustion of JP-8 provides an additional control parameter for external combustion based power sources. When supplied as part of a “reformer gas” mixture, hydrogen provides similar benefits as pure hydrogen, given sufficient oxygen mixing. Previous work showed benefits of hydrogen enhanced combustion for external combustion based power sources. As a step closer to practical applications, the present work examines the use of hydrogen rich reformate. This mixture of hydrogen, carbon monoxide, carbon dioxide, and nitrogen is produced by fuel reforming of JP-8 and other logistics fuels. Tests evaluated the temperature profiles of dual fueled flames using JP-8 and either hydrogen or a bottled mixture representing fuel reformate. Both supplemental fuels move combustion earlier, allowing more stable combustion and potential for reduced size. JP-8 flow rate was reduced to maintain fuel energy input at a constant 5.5kWth. In comparing two cases, the important factor was the total energy contribution. The ratio of hydrogen and carbon monoxide had little effect on the flame structure. This research also compared methods of hydrogen addition. It was added with either the atomizing air or the secondary air which reiterated the importance of oxygen availability. For example, hydrogen through the nozzle produces additional changes to the flame structure due to the combustible mixture of hydrogen and air in the nozzle. The equivalent flow rate of reformate in the nozzle does not produce the same effect because the air in the nozzle is replaced by the other gases in the reformate (CO, CO2, and N2). Hydrogen enrichment tests establish the benefit of dual firing hydrogen and JP-8. These reformate tests show the variables that must be considered in implementing this technique in a practical system.}
}
@article{THRAN2016184,
title = {Moving torrefaction towards market introduction – Technical improvements and economic-environmental assessment along the overall torrefaction supply chain through the SECTOR project},
journal = {Biomass and Bioenergy},
volume = {89},
pages = {184-200},
year = {2016},
note = {Biomass & Bioenergy special issue of the 23rd European Biomass Conference and Exhibition held in Vienna, June 2015},
issn = {0961-9534},
doi = {https://doi.org/10.1016/j.biombioe.2016.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0961953416300538},
author = {Daniela Thrän and Janet Witt and Kay Schaubach and Jaap Kiel and Michiel Carbo and Jörg Maier and Collins Ndibe and Jaap Koppejan and Eija Alakangas and Stefan Majer and Fabian Schipfer},
keywords = {Torrefaction, Solid biofuel, Sustainability, Standardization, Densification, Market implementation},
abstract = {The large-scale implementation of bioenergy demands solid biofuels which can be transported, stored and used efficiently. Torrefaction as a form of pyrolysis converts biomass into biofuels with according improved properties such as energy density, grindability and hydrophobicity. Several initiatives advanced this development. The first pilot-scale and demonstration plants displayed the maturity and potential of the technology. The European research project SECTOR intended to shorten the time-to-market. Within the project 158 Mg of biomass were torrefied through different technologies (rotary drum, toroidal reactor, moving bed). Their production led to process optimization of combined torrefaction-densification steps for various feedstocks through analysing changes in structure and composition. The torrefied pellets and briquettes were subjected to logistic tests (handling and storage) as well as to tests in small- and large-scale end-uses. This led to further improvement of the torrefied product meeting logistics/end-use requirements, e.g. durability, grindability, hydrophobicity, biodegradation and energy density. Durability exceeds now 95%. With these test results also international standards of advanced solid biofuels were initiated (ISO standards) as a prerequisite for global trade of torrefied material. Accompanying economic and environmental assessment identified a broad range of scenarios in which torrefied biomass perform better in these areas than traditional solid biofuels (e.g. white pellets), depending e.g. on feedstock, plant size, transport distances, integration of torrefaction in existing industries and end use. The implementation of industrial plants is the next step for the technology development. Different end user markets within and outside Europe can open opportunities here.}
}
@article{MCKENNA20161212,
title = {Key challenges and prospects for large wind turbines},
journal = {Renewable and Sustainable Energy Reviews},
volume = {53},
pages = {1212-1221},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.09.080},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115010503},
author = {R. McKenna and P. {Ostman v.d. Leye} and W. Fichtner},
keywords = {Onshore wind, Challenges, Prospects, Interviews},
abstract = {The so-called 20-20-20 targets for the European Union include a reduction in greenhouse gas emissions by 20% compared to 1990, 20% of primary energy from renewables, and a 20% reduction in primary energy demand through energy efficiency by 2020. Wind energy has played and will continue to play a significant role in progress towards meeting these goals; in 2012 it accounted for around 7% of total European electricity consumption. Against the background of the recent trend towards ever larger wind turbines at higher hub heights, this contribution explores the challenges to and prospects for a continued up-sizing of wind turbines in the future. Based on a literature review and interviews with experts in the European wind industry, the key challenges for large onshore wind turbines are identified and qualitatively analyzed in a European context. Further developments of large wind turbines depend on several components and related challenges rather than just one. The main challenges are thought to be related to social acceptance, the logistics of transport and erection, and the medium term sustainability of the political and economic support for wind energy. It seems likely that social acceptance will center around the issue of aerodynamic noise and the allowed distance from the turbine, although further research is required to fully understand the public perception of especially large wind power plants. In addition, the sheer size of larger wind turbines in the future presents significant challenges in terms of the materials and structures employed. There is little consensus on the likely development of drive train technologies, though a slight tendency towards direct drive systems with permanent magnet generators as well as multi-stage gearboxes was encountered, which could also serve to improve reliability. For the rotor blades, a trend towards fully carbon fiber blades is expected, and towers will continue to be constructed from steel and/or concrete, albeit both of these components increasingly in the form a modular construction.}
}
@article{FINKE2018141,
title = {The socially evaluated handgrip test: Introduction of a novel, time-efficient stress protocol},
journal = {Psychoneuroendocrinology},
volume = {87},
pages = {141-146},
year = {2018},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2017.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0306453017306030},
author = {Johannes B. Finke and Grit I. Kalinowski and Mauro F. Larra and Hartmut Schächinger},
keywords = {Stress, Handgrip, Social evaluation, Cortisol, Autonomic nervous system},
abstract = {Most widely-used stress-induction procedures (such as the TSST and the Cold Pressor Test) require considerable effort and overhead in terms of preparation, logistics, and staff recruitment. Moreover, while known to reliably induce HPA axis activation, especially when combined with social self-threat, most conventional laboratory stressors cannot be flexibly adapted to elicit either a mainly autonomic or an additional endocrine stress response. Being a promising alternative approach, a new version of the isometric handgrip test enriched by a social-evaluative component was evaluated in the present study. On two consecutive sessions, forty participants (20 women) performed a handgrip task at both 45% (stress) and 10% (control) of maximum voluntary isometric contraction lasting for 3min. During the stress test, continuous visual feedback on performance was given. Participants in the social-evaluative condition (50%) were observed and evaluated by a previously unknown person of the opposite sex, whereas in the standard condition feedback was provided via a computer monitor. Cardiovascular measures (heart rate, blood pressure) as well as additional indices of autonomic reactivity (skin conductance, heart-rate variability) were registered before, during, and after stress induction. Moreover, changes in salivary cortisol and in subjective well-being were assessed. Relative to control, significant increases in cardiovascular and sympathetic activity were found, irrespective of experimental group. Importantly, however, additional social evaluation resulted in elevated cortisol levels. Furthermore, evidence for reduced vagal tone during sustained socially evaluated handgrip emerged. In conclusion, the socially evaluated handgrip test represents a versatile, time-efficient method to induce stress in small laboratory settings.}
}
@article{JULIEN2016693,
title = {Introduction à la médecine de catastrophe},
journal = {Bulletin de l'Académie Nationale de Médecine},
volume = {200},
number = {4},
pages = {693-703},
year = {2016},
issn = {0001-4079},
doi = {https://doi.org/10.1016/S0001-4079(19)30697-1},
url = {https://www.sciencedirect.com/science/article/pii/S0001407919306971},
author = {Henri Julien},
keywords = {Médecine de catastrophe, Modèles logistiques, Formation par simulation, Disaster medicine, Logistic models, Simulation training},
abstract = {RÉSUMÉ
Par leurs conséquences sur les populations, les catastrophes ont conduit les médecins et les chirurgiens à adapter et à améliorer les secours et les soins d’urgence. Une première classification des catastrophes selon leur origine a conduit à déterminer des dominantes agressives et leurs traitements. Une seconde, qui analyse leurs conséquences, définit une organisation adaptée des secours : Plan Rouge (ou NoVi) ou envoi de colonnes de secours. La prise en compte du Syndrome post-traumatique du à la confrontation avec la mort, la survenue d’épidémies et de pandémies, la répétition des catastrophes chimiques et nucléaires, l’émergence du terrorisme atteignant les populations civiles ont renforcé la nécessité de disposer de techniques médicales appropriées, d’une organisation structurée des secours et soins d’urgence, d’un support logistique performant. Les personnels de santé et de secours doivent être formés pour travailler ensemble, leurs compétences entretenues. Initiée en France, diffusée et adoptée dans le monde entier, la médecine de catastrophe est une spécialité médicale jeune pour laquelle chaque engagement opérationnel doit être facteur de progrès et d’affirmation de ses bases scientifiques.
SUMMARY
The consequences on people of disasters have led doctors and emergency surgeons to specify their behavior and procedures for more effective rescues and emergency actions. A first classification of disasters based on their origin determines the dominant mode of aggression and their treatments. More recently an analysis of their consequences proposed two kinds of rescue organizations: Red Plan (or NoVi) or sending relief columns. Consideration of the Post Traumatic Syndrom due to confrontation with death, to the occurrence of epidemics and pandemics, to the repetition of chemical and nuclear disasters, and to the emergence of terrorism against civilians has increased the need for appropriate medical procedures, a structured rescue organization and emergency care and an efficient logistics support. Health and emergency staff must be trained to work together, contributing with their individual and collective skills. Disaster medicine, a recent branch of medicine, was initiated in France and had spread across the world. Each of its operational commitments must lead to progress and to the development of scientific basis.}
}
@article{SILVA201672,
title = {Individuals, populations and fluid approximations: A Petri net based perspective},
journal = {Nonlinear Analysis: Hybrid Systems},
volume = {22},
pages = {72-97},
year = {2016},
issn = {1751-570X},
doi = {https://doi.org/10.1016/j.nahs.2016.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1751570X16300036},
author = {Manuel Silva},
keywords = {Discrete event system, Petri net, Fluidization, Piecewise affine system, Symmetries, Decolorization},
abstract = {Discrete Event Systems (DES) theory and engineering are mainly driven by needs that arise in many different human-made systems (manufacturing, communications, logistics, workflow management, traffic, etc.). With the accelerated increase in the complexity and size of new technological constructions, the state explosion problem in DES analysis and synthesis becomes more and more acute. Two traditional conceptual and complementary ways of dealing with the computational complexities in the Petri nets (PN) framework are structure theory (that investigates the relationship between the behavior of a net system and its structure) and fluid relaxations, here leading to particular classes of hybrid systems. In the second case, the expected computational gains for analysis and synthesis problems are usually achieved at the expense of the fidelity or accuracy of the relaxed model. This invited overview will mainly focus on the second strategy, nevertheless always interspersed with basic structural concepts and methods. Using an example-driven approach, starting with a DES “view of the system”, the legitimization and improvement of fluidization process, the aggregation of local states by symmetries and the decolorization of models will be briefly addressed, together with reflections about the analysis of the new models obtained. As the linearization of a continuous dynamical system, the fluidization of a DES is a relaxation that has to be used with care, depending on the problem at hand. This abstraction is here considered from two complementary perspectives: at logical and at performance levels, both for untimed and timed PNs. On the one hand, the expressive power of timed fluid PNs under infinite server semantics is such that the simulation of Turing machines is possible. From a complementary perspective, the expression of modeling capabilities such as non-monotonicities and bifurcations may also be revealed for steady-state behaviors. Symmetries (more generally, lumping) seek to group together “equivalent” behaviors and decolorization seeks to abstract identities, in order to create new collectivities of processes and resources. The synergy between symmetry-decolorization state-aggregation approaches and fluid relaxations is highlighted. In fact, the first approaches not only reduce the state space, but also “produce” populations, thus proceed upgrading the applicability of fluidization. Opening the window, related issues such as control, optimization, observation or diagnosis are briefly pointed out. For conciseness, this work is limited to fully fluid (or continuous) PN models and their relationships with the corresponding discrete systems.}
}
@article{HEWINS2016253,
title = {Measuring the effect of freezing on hydrolytic and oxidative extracellular enzyme activities associated with plant litter decomposition},
journal = {Pedobiologia},
volume = {59},
number = {5},
pages = {253-256},
year = {2016},
issn = {0031-4056},
doi = {https://doi.org/10.1016/j.pedobi.2016.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0031405616300683},
author = {Daniel B. Hewins and Xiaozhu Chuan and Edward W. Bork and Cameron N. Carlyle},
keywords = {Exoenzyme, Carbon cycle, Nitrogen cycle, Phosphorous cycle, Biogeochemistry},
abstract = {Extracellular enzymes are the proximate drivers of biogeochemical cycling in ecosystems. In terrestrial environments, studies of extracellular enzyme activities (EEAs) in soils far outpace studies in substrates such as leaf litter. Despite recent methodological advances that have made EEA assays feasible for researchers conducting large-scale studies, there are still a number of methodological uncertainties that exist, particularly when working with less studied substrates (i.e. grassland leaf litter). These uncertainties are of particular importance when considering the logistics of sample processing after collecting samples in large numbers and/or from distant field sites. Studies of soil handling suggest that while assaying biochemical and molecular markers in fresh samples is ideal, that freezing samples is often a viable solution if the former is not feasible. Due to the inherent differences of litter and soil materials and associated microenvironments, we can draw only limited conclusions from the results of studies on sample handling using soil. As a result, we investigated the effect of two typical freezing temperatures (−20° and −80°C) on subsequent EEAs in decomposing leaf litter material. We incubated litter material from six grassland plant communities for 12 weeks at 25°C, then measured the EEA of five hydrolytic and two oxidative enzymes in fresh litter, and in litter that was frozen for four weeks at either −20° or −80°C. Results indicate that freezing only affected the activity of N-acetyl-β glucosaminidase (NAG), an enzyme that was affected by freezing in prior soil studies. We observed an approximate 35% increase in NAG activity with freezing. The remaining six EEAs measured were not observed to be affected by freezing, and the level of freezing (i.e. temperature) did not influence any of the seven EEAs measured, suggesting that freezing is a suitable alternative when laboratory analyses on fresh litter samples are not logistically possible.}
}
@incollection{MENDEZVAZQUEZ2016133,
title = {Mathematical Optimization of the Production of Fuel Pellets from Residual Biomass},
editor = {Zdravko Kravanja and Miloš Bogataj},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {38},
pages = {133-138},
year = {2016},
booktitle = {26th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-63428-3.50027-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444634283500278},
author = {M.A. Méndez-Vázquez and F.I. Gómez-Castro and J.M. Ponce-Ortega and A.H. Serafín-Muñoz and J.E. Santibañez-Aguilar and M.M. El-Halwagi},
keywords = {Pellets, clay industry, supply chain optimization},
abstract = {One of the main concerns of mankind in the last years is the availability of energy sources, which should have the lower environmental impact possible. In the state of Guanajuato, Mexico, clay industry burns each year about 15.000m3 of fuel oil and residual oils, and 96.000 tons of non-sustainable wood derivatives. In particular, wood derivatives are required in high quantities due to their low density and high humidity, with costs of about 3,4 USD/GJ. Two start-up companies, GEMAR & TODO PELLET, produce solid fuel pellets from vegetable residual material. This raw material is obtained from agribusiness and from the cities nearby. The solid biofuel pellet has high density, low content of humidity and a homogeneous shape. This pellet has an energy density of about 12 GJ/m3, which is 2.3 times the content of commonly used wood. To make the production of solid biofuels economically feasible, special care must be taken about the location of the production plants and hubs, to avoid excessive distances between the sources of the biomass and the facilities. Furthermore, to have a truly environmentally friendly fuel, the supply chain and the production process must minimize the global environmental impact. Thus, in this work a mathematical programming model to determinate the optimal location of the production plants, the collection centers, together with the optimal distribution logistics, is proposed. The multi-objective optimization problem involves the minimization of total annual costs and emissions of equivalent carbon dioxide for the whole supply chain. The problem is modeled following a general disjunctive programming approach, and then relaxed into a MINLP problem using the convex hull strategy. The problem is then solved using the GAMS software. The results show that, for the different scenarios analyzed, the optimal solution was always the same. The location of the main plant and the secondary plants has been determined, and it has been found that most of the raw material (40%) must consist on stover and straw, while the rest of the material requirement is satisfied by residues from pruning and from the agave industry. With this solution, reductions on about 18,600 ton of CO2 are expected for the main plant.}
}
@article{GASOVA2017219,
title = {Advanced Industrial Tools of Ergonomics Based on Industry 4.0 Concept},
journal = {Procedia Engineering},
volume = {192},
pages = {219-224},
year = {2017},
note = {12th international scientific conference of young scientists on sustainable, modern and safe transport},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.06.038},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817325845},
author = {Martina Gašová and Martin Gašo and Andrej Štefánik},
keywords = {Ergonomic, Industry 4.0 concept, electronic tools, virtual and augmented reality, CERAA},
abstract = {Over the years approach focusing in ergonomics has changed. We still talk about identification - analysis - elimination of the risks on the workplaces. But differences are at the possibilities of modern ergonomics, movement of science and technical possibilities. The options of using a mobile applications, Internet of Things, data gathering and their real time evaluation and their sharing. We present those solutions that combine traditional knowledge and modern technologies. The results are innovative and advanced ergonomic tools based on Industry 4.0 concept. Electronic tools are a new direction in ergonomics. With the support of mobile applications we see a way to create healthy conditions at work for production and also non-production workers, assembly and logistics. At the beginning of 20-th century, majority of us had no idea what the ergonomics is, how many risks occur during our job that they are connected with the health of employees and have not known that special methods and tools for their identification, analysis, evaluation and identification are developed. With the growing development of society we got to stadium when, luckily, majority of companies – employers even know the meaning of ergonomics or work risks, about risks at their workplaces and establish their evaluation and try to eliminate them. We have many methods and tools of modern ergonomics which enable us to realize analysis and optimization of employee's work to their benefit. Considering experience we can surely claim that we know the main problem of these days. It is requisite to realize ergonomic evaluation perfectly, extensively and mainly quickly. Slowness of some solutions discourages managers and directors and makes effective improving of work conditions impossible. The idea of mobile application developing which works as a screening tool came with demands from big companies that have dozens of workplaces and cannot identify work risks by themselves. Ceit ERgonomics Analysis Application, which is described in article, is output of our own research and development. It is a mobile application developed in CEIT Company in collaboration with the University of Žilina and Slovak ergonomic association. It is a screening evaluation of space conditions and work positions of workers at potentially risky workplaces. It is developed at the base of legislation and technical norms, at our own platform, with the support of virtual and augmented reality. The main goal of evaluation by the CERAA usage is to find out if the workplace is risky from the ergonomic view. It is an innovative way of applied augmented reality tools during the ergonomic evaluation of chosen workplaces. Nowadays, the new submodules are being developed. They will identify risks at administrative workplaces, submodule which will evaluate working with loads and other that will evaluate repetitive operations. CERAA is used in several industrial companies in Slovakia and Czech Republic from the second half of 2016.}
}
@article{MELO20173699,
title = {CO2MOVE Project: The New Brazilian Field Lab Fully Dedicated to CO2 MMV Experiments},
journal = {Energy Procedia},
volume = {114},
pages = {3699-3715},
year = {2017},
note = {13th International Conference on Greenhouse Gas Control Technologies, GHGT-13, 14-18 November 2016, Lausanne, Switzerland},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.03.1501},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217316958},
author = {Clarissa L. Melo and Andréa Cristina {de C.A. Moreira} and Flávio S. Goudinho and Lia W. Bressan and Marcelo J. Constant and Andresa Oliva and Hung K. Chang and Walter M. Nakaema and Daniel P. Vinter and João Marcelo M. Ketzer and Fátima do Rosário and Ana Paula S. Musse},
keywords = {Monitoring, CO, release, experiment},
abstract = {After the Ressacada Project experience acquired from 2011 to 2015 when PUCRS, UNESP and other institutions conducted three controlled CO2 release experiments, PETROBRAS, the national oil company that is sponsoring the project, has launched a new challenge to its partners. The company stimulated the implementation of a new Brazilian experimental site where there will be a deepening of studies in geologically more complex conditions and more challenging from a technological point of view. The choice of an area inside PUCRS campus, in Viamão - Rio Grande do Sul state, was motivated by a predominantly clay subsoil and the privileged location of the site in terms of ease logistics and security, which is required for a project of this size that houses high-tech equipment with significant cost. The CO2MOVE project started at 2015 with the subsurface characterization of the site and the assembly and manufacture of an automated system for CO2 and gas tracers with injection capacity for 5 to 50 kg/day. Based on physical characterization studies and on numerical modeling that is being developed, the site infrastructure will be completed in the next months with the positioning of vertical injection wells, monitoring wells, and other equipment and monitoring mesh. Monitoring tools should be arranged in an area of approximately 100m2, occupying the entire region surrounding the injection wells. Fieldwork involving CO2 injection and monitoring should have a 60 days duration of which 15 days are for preliminary surveys (pre-injection), 30 days for injection and CO2 monitoring and the last 15 days for post-injection measurements. Following this work, the collected data will be analyzed in the university labs. Similarly to Ressacada Project, this experiment will run measurements of soil CO2 flux with accumulation chambers, CO2 turbulent fluxes with Eddy Covariance, subsurface gases and groundwater monitoring, and resistivity measurements. Other monitoring methods still not tested by the research team will be held as gas tracers monitoring and laser measurements.}
}
@article{HEINZ20162785,
title = {Eco-optimisation of Goods Supply by Road Transport: From Logistic Requirements Via Freight Transport Cycles to Efficiency-maximised Vehicle Powertrains},
journal = {Transportation Research Procedia},
volume = {14},
pages = {2785-2794},
year = {2016},
note = {Transport Research Arena TRA2016},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2016.05.475},
url = {https://www.sciencedirect.com/science/article/pii/S2352146516304823},
author = {Dörr Heinz and Prenninger Peter and Huss Arno and Hörl Bardo and Marsch Viktoria and Toifl Yvonne and Berkowitsch Claudia and Wanjek Monika and Romstorfer Andreas and Bukold Steffen},
keywords = {Commercial vehicles, power train systems, freight transport cycles, traffic flow, table of indicators},
abstract = {Currently, only a small minority of commercial vehicles on the market are fitted with alternative powertrain systems, and they are mostly of the heavy-duty type. The “alternative” components required (in particular batteries) make these utility vehicles rather expensive for fleet operators. The return on investment seems to be still out of reach. Hence, it is necessary to cut down on operational costs. Given these facts, the starting point was to clarify the criteria of logistic services as needed by the customers. First and foremost this concerns the type of vehicle chosen for a given logistic task. Secondly, concern needs to be given to the factors which influence the dynamics of vehicle movements, such as the load factor in terms of the geographical sequence of the points of deliveries. Thirdly, the time windows available for delivery affect variations in the velocity dependent on the respective level of service of the traffic flow. This opens up some additional potential for optimisation aside from vehicle technology. Road network planning and traffic management can boost low-emission freight services by taking into consideration the performance of different powertrain systems. The object was to quantify effects of innovative powertrain technologies on freight transport fleets with respect to reducing energy consumption and CO2 equivalent emissions. We identified representative logistic services as framework conditions of their operations in correlation with vehicle classes (light, medium and heavy). The vehicles use routes from the outskirts to the core of a conurbation and vice versa. The roads used are defined in categories which allow estimates of their capacity to handle variable traffic flows depending on the time of the day. These boundary conditions were used for a comprehensive comparison (based on numerical simulations) of advanced powertrain systems for such commercial vehicles. Particularly, fuel types as well as electricity were taken into account along with some variation in gross vehicle weights and hybrid configurations. The investigations were carried out for 32 different powertrain architectures such as advanced diesel and CNG engines, also as baselines for different hybrid variants and even pure battery-powered commercial vehicles. The results should be of interest for fleet operators, and our interpretations regarding further energy and emission reductions in goods supply processes challenges the entire future system of logistics, traffic management, infrastructure planning and powertrain technologies.}
}
@article{GERRIE20163603,
title = {Implementation of a Physician-Prescribed Exercise Program As Standard of Care in Allogeneic Stem Cell Transplant (SCT) Patients (pts) in British Columbia: A Pilot Study},
journal = {Blood},
volume = {128},
number = {22},
pages = {3603},
year = {2016},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood.V128.22.3603.3603},
url = {https://www.sciencedirect.com/science/article/pii/S0006497119336043},
author = {Alina S. Gerrie and Pamela Plantinga and Kei Nishikawa and Stanley Hung and Jennifer Kadgien and Ben Chernoff and Valerie Burke and David Kendler and Don C McKenzie and Kristin L Campbell and Raewyn Broady},
abstract = {Background: There is compelling evidence that physical activity positively influences quality of life (QoL), and health-related outcomes including improved muscle mass and physical functioning in cancer pts. SCT pts however have unique barriers to exercise including isolation, restriction of activities, and treatment toxicity. In the early post SCT period, pts describe worsening fatigue, physical capacity and QoL. We sought to determine whether a partially supervised exercise intervention early post SCT would address these issues. Our primary objective was to determine the feasibility of delivering such an intervention at our institution. Secondary objectives were to assess changes as a result of the intervention in QoL, muscle mass and physical functioning. Methods: From Aug 2015-Jun 2016, we conducted a prospective single-arm study to evaluate feasibility of a 12 week partially supervised exercise program (1 supervised, 2 unsupervised sessions/week) for alloSCT pts with hematologic malignancies. The program consisted of 3 progressive endurance (stationary bike, walking) and 2 resistance training sessions/week, from hospital discharge (D/C) to Day (D) 100. Feasibility was defined as ability to recruit >65% of eligible pts, ≥70% retention and ≥70% adherence. Secondary outcomes were measured pre SCT (T0), at D/C (T1) and D100 (T2) and included QoL, muscle strength, mobility, aerobic fitness and body composition. Changes from T0 to T1 and T1 to T2 were compared using a paired sample t-test. Results: Of 43 consecutive alloSCT pts assessed for eligibility, 30 (70%) entered the study: 17 male (57%), median age 48 yrs (range 19-66 yrs). Transplants characteristics were: related 6; unrelated 24; myeloablative 23; reduced intensity 7. At baseline, SCT comorbidity index was 0 in 43%, 1-2 37%, ≥ 3 20%. Pts self-reported exercising enough to break a sweat (Godin et al) never 60%, sometimes 33%, often 7%. Median hospitalization was 29d (range 15-141); 9 pts developed grade II-IV acute graft-versus-host disease (skin 7, gut 5, liver 1). Overall retention to D100 was 80% (Figure 1). Two pts had complications during hospitalization and did not enter the program. Of the 24 pts who entered the program, adherence was 72% for supervised and 89% for unsupervised sessions. Logistics with scheduling around multiple medical appointments in the early post SCT period were the most common reasons for non-adherence. Other reasons included nausea, fatigue and weakness. One pt developed exercise-induced atrial fibrillation in week 3 requiring cessation of exercise. When comparing secondary outcomes from T0 to T1 (Table 1), pts had significantly decreased muscle strength (grip strength, 30-second chair stand), mobility (timed up-and-go [TUG]) and aerobic capacity (6-min walk test [6MWT]). At T2 after completion of the program, these measures all increased significantly when compared to T1. Global QoL scores on the EORTC measure decreased from T0 to T1 (P=.011) and were significantly improved by T2 (P<.001). Similar trends were seen across functional and symptom measure scales. Body composition comparisons between T0 and T2 demonstrated a trend towards increased appendicular lean mass (P<.059). Conclusion: Results of this pilot study demonstrate feasibility of a partially supervised exercise program post-alloSCT deemed by achieving the target recruitment rate, ≥70% adherence and ≥70% retention. Logistics were the most common reason for non-adherence, highlighting need for a multidisciplinary team with knowledge of the post SCT setting. Prior observational studies have shown significant declines in physical functioning and QoL within the first 100 days of SCT. In contrast we demonstrate significant improvements in these measures. Furthermore, we demonstrate a trend towards increased lean muscle mass, which is a novel secondary outcome that warrants further evaluation in this setting. Our findings support the need for this clinical intervention and will be evaluated in a larger randomized trial. 
Disclosures
Gerrie: Roche Canada: Research Funding. Plantinga: BCCA: Employment. Broady: Lotte & John Hecht Memorial Foundation: Research Funding.}
}
@article{GALLASSI201699,
title = {Characteristics of clients using a community-based drug treatment service (‘CAPS-AD’) in Brazil: An exploratory study},
journal = {International Journal of Drug Policy},
volume = {31},
pages = {99-103},
year = {2016},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2016.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S0955395916000529},
author = {Andrea Donatti Gallassi and Eduardo Yoshio Nakano and Gabriela Arantes Wagner and Maria de Nazareth Rodrigues Malcher {de Oliveira Silva} and Benedikt Fischer},
keywords = {Substance misuse, Community-based treatment, Retention, Barriers, Brazil},
abstract = {Background
Substance use is common in Brazil. In order to improve availability of substance misuse care services, over 400 Psycho-Social Care Centres for Alcohol and Drugs (CAPS-AD) – providing community-based care – have been established following mental health care reform (2001). Information on CAPS-AD clients and outcomes is limited. The present study examined select characteristics of local CAPS-AD clients.
Methods
N=143 adult CAPS-AD clients in Ceilândia (suburb of Brasília, Federal District) participated in a 1-week ‘snapshot’ assessment of service users (February 2015). Following consent, descriptive data were collected by a brief, anonymous interviewer-administered questionnaire that included socio-demographic, drug use, treatment history and needs/barriers information.
Results
Participants were predominantly male; middle-aged; unemployed; married; with middle-school education; primary problem drugs indicated were alcohol and cocaine/crack; half had prior treatment histories and indicated that treatment was externally motivated; 60% reported ways to improve treatment and possible reasons for treatment discontinuation; in multi-variate analyses, the latter was associated with employment and education status (both p<.05).
Conclusion
CAPS-AD services appear to have increased low-barrier substance misuse treatment availability in Brazil, as well as attract individuals new to the treatment system. Various potential barriers to continuing in treatment should be addressed and more research on CAPS-AD clients and outcomes is needed.}
}
@article{HALL201739,
title = {The 2015 Nepal earthquake disaster: lessons learned one year on},
journal = {Public Health},
volume = {145},
pages = {39-44},
year = {2017},
issn = {0033-3506},
doi = {https://doi.org/10.1016/j.puhe.2016.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0033350616304528},
author = {M.L. Hall and A.C.K. Lee and C. Cartwright and S. Marahatta and J. Karki and P. Simkhada},
keywords = {Nepal, Earthquake, Disaster},
abstract = {Introduction
The 2015 earthquake in Nepal killed over 8000 people, injured more than 21,000 and displaced a further 2 million. One year later, a national workshop was organized with various Nepali stakeholders involved in the response to the earthquake. The workshop provided participants an opportunity to reflect on their experiences and sought to learn lessons from the disaster.
Methods
One hundred and thirty-five participants took part and most had been directly involved in the earthquake response. They included representatives from the Ministry of Health, local and national government, the armed forces, non-governmental organizations, health practitioners, academics, and community representatives. Participants were divided into seven focus groups based around the following topics: water, sanitation and hygiene, hospital services, health and nutrition, education, shelter, policy and community. Facilitated group discussions were conducted in Nepalese and the key emerging themes are presented.
Results
Participants described a range of issues encountered, some specific to their area of expertize but also more general issues. These included logistics and supply chain challenges, leadership and coordination difficulties, impacts of the media as well as cultural beliefs on population behaviour post-disaster. Lessons identified included the need for community involvement at all stages of disaster response and preparedness, as well as the development of local leadership capabilities and community resilience. A ‘disconnect’ between disaster management policy and responses was observed, which may result in ineffective, poorly planned disaster response.
Conclusion
Finding time and opportunity to reflect on and identify lessons from disaster response can be difficult but are fundamental to improving future disaster preparedness. The Nepal Earthquake National Workshop offered participants the space to do this. It garnered an overwhelming sense of wanting to do things better, of the need for a Nepal-centric approach and the need to learn the lessons of the past to improve disaster management for the future.}
}
@article{ORLOWSKI20171,
title = {Design methodology for crash occupant protection in cabin design of the high speed vessel},
journal = {Marine Structures},
volume = {51},
pages = {1-20},
year = {2017},
issn = {0951-8339},
doi = {https://doi.org/10.1016/j.marstruc.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0951833916300843},
author = {Michał Orłowski and Christophe Bastien and Omid Razmkhah and Sean McCartan},
keywords = {Safety, Finite element, Human model, THUMS, HYBRID III dummy},
abstract = {Expansion of marine transport and growing number of high speed vessels travelling in the neighbourhood of the coastline significantly increase the risk of the crash on the sea. Within the existing high speed craft legislations there are no regulations related to prediction of the vessel occupants injury and trauma. Former research has exposed the similarities between the high speed vessel crash and automotive collision enabling the transfer of advanced crash safety technologies between the automotive and marine. This paper investigates the application of the most recent CAE automotive safety technologies to predict the injuries of high speed Cruise Logistics Ferry (CLF) occupants in 40 knots crash with a harbour peer. At first, the probability of occupant injuries was studied using a 50th percentile HYBRID III standing crash test dummy model. The study considered various occupant positions within the boat cabin for two different cabin orientations. The investigation was then followed by computer analyses utilising the state of the art Total Human computer Model for Safety (THUMS) to evaluate the localised passenger traumatology. This model is the most advanced human computer model available, capable of computing injury risks at organ levels. Results from the analyses using both models showed that the standing HYBRID III dummy was suitable to assess the overall risk of occupants' injuries in a cabin design context, while the THUMS model added detailed trauma injuries for selected occupant locations. The results of both investigation indicated very high risk of life changing injuries or even death to the boat occupant within the cabin. A strong relationship between the probability of severe injury and the distance between the passenger and any obstacle in the cabin was found. In conclusion, the research is proposing a design methodology for cabin occupant protection based on the location of each individual passenger relative to obstacles and the associate risk of injury. This is in stark contrast to the general design guidelines of the High Speed Craft code (2000) which are based on threshold values of a global collision design acceleration.}
}
@article{AMPATZIDIS2016161,
title = {Cloud-based harvest management information system for hand-harvested specialty crops},
journal = {Computers and Electronics in Agriculture},
volume = {122},
pages = {161-167},
year = {2016},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2016.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S0168169916300059},
author = {Yiannis Ampatzidis and Li Tan and Ronald Haley and Matthew D. Whiting},
keywords = {Labor management, Cloud-based software, RFID, Embedded systems, Arduino},
abstract = {The harvest process for specialty crops is generally one of intensive activity because many people are required for harvest and packing, and the harvest window is brief due to the high perishability of the produce. Herein we present a cloud-based Harvest Management Information System (HMIS) that combines a novel real-time Portable Labor Monitoring System (PLMS) with a cloud-based harvest management software. The PLMS comprised of three key elements (1) a self-leveling scale, (2) electronic control box, and (3) a frame that supports all hardware. The electronic control box includes: (i) a RFID reader, (ii) a LCD display, (iii) a thermal printer, (iv) a GPS module, and (v) a communication system. RFID tags, containing unique ID numbers, embedded within rubber wrist bands, are worn by pickers. This system can read a picker’s ID (RFID bracelet), measure the weight of fruit, and record the time and location (optional) of every fruit ‘transaction’ (i.e., every time a picker brings a bucket of fruit to the collection bin). The collected data can be transmitted wirelessly to the server in real-time. The cloud-based software receives and processes the PLMS data on labor activities, visualizes the collected data, and can extract the data necessary for management information and automated filling of documents (e.g. payroll, yield maps). The HMIS is unique in its ability to: (1) accurately credit pickers for the fruit they have harvested in the field without impeding or altering the harvest process, (2) streamline data entry to payroll, (3) provide real-time tracking of harvest, yield mapping, and traceability, and, (4) generate precise and reliable harvest efficiency data. This integrated system was evaluated in sweet cherry, blueberry and apple orchards in Washington, USA. The weight of harvested fruit, time and location of every fruit drop were calculated accurately; all the data were transmitted wirelessly to the server and no errors were recorded.}
}
@article{FUMAGALLI201639,
title = {Growing inter-Asian connections: Links, rivalries, and challenges in South Korean–Central Asian relations},
journal = {Journal of Eurasian Studies},
volume = {7},
number = {1},
pages = {39-48},
year = {2016},
issn = {1879-3665},
doi = {https://doi.org/10.1016/j.euras.2015.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1879366515000263},
author = {Matteo Fumagalli},
keywords = {South Korea, Central Asia, Resource diplomacy, New Asia initiative, Eurasia initiative},
abstract = {The geopolitical context, which emerged from the collapse of the Soviet Union and the end of the Cold War, combined with Korea's growing economic prowess, enabled greater dynamism and diversification in Seoul's foreign policy-making. Growing pressure from energy-intensive economies coupled with new developments and investment in logistics and infrastructure has brought different parts of the Eurasian landmass closer together in recent years. Inter-Asian connections are especially growing. This article uses the case of deepening relations between Korea and the post-Soviet Central Asian republics as a vantage point to reflect on one such example of unfolding Asian inter-connectedness. In addition it sees Seoul's engagement in the region as a fitting example of Korea's broader ambitions to assert itself as a global economic player. The article shows that Korea's policy toward Central Asia has been primarily driven by energy needs and is defined by pragmatism. It finds that the economic dimension of the relationship has greatly overshadowed other aspects such as politics and security. In its pursuit of closer ties with the region Seoul has sought to turn structural weaknesses into added value and has attempted to develop a distinctive, non-threatening profile built around the lack of a political baggage and geopolitical ambitions, and the desire to share its experience of formerly impoverished turned leading economy. In turn, Central Asia's selective integration in the world economy has continued, also thanks to its ties with Korea. The Central Asian republics welcomed the opportunity to diversify their foreign relations, the sources of foreign investment and export routes. At the same time the opaque business environment, a leadership succession, which cannot be postponed for much longer, and Seoul's “no-strings attached” approach expose Korea to some risks as regime stability might not last forever.}
}
@article{OSHAGBEMI2018238,
title = {Use of high-dose intermittent systemic glucocorticoids and the risk of fracture in patients with chronic obstructive pulmonary disease},
journal = {Bone},
volume = {110},
pages = {238-243},
year = {2018},
issn = {8756-3282},
doi = {https://doi.org/10.1016/j.bone.2018.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S8756328218300681},
author = {Olorunfemi A. Oshagbemi and Andrea M. Burden and Kimberly N. Shudofsky and Johanna H.M. Driessen and Peter Vestergaard and Andreas Krings and Frits M.E. Franssen and Joop {van den Bergh} and Frank {de Vries}},
keywords = {COPD, Fracture, Glucocorticoids, Epidemiology},
abstract = {Introduction
Chronic obstructive pulmonary disease (COPD) is characterised by persistent airflow obstruction and respiratory symptoms. While short course systemic GCs are prescribed in patients with acute COPD exacerbations, little is known of the risk of fractures with intermittent exposure to high-dose GC and the effect of proxies of disease severity.
Methods
A case-control study was conducted using the Danish National Hospital Discharge Registry (NHDR) between January 1996 to December 2011. Conditional logistics regression models were used to derive adjusted odds ratios (OR) risk of fractures in subjects with COPD stratified by intermittent high-dose, and proxies of disease severity.
Result
A total of 635,536 cases and the same number of controls were identified (mean age 67.5±13.8, 65% female). COPD patients with intermittent use of high average daily dose oral glucocorticoids did not have an increased risk of any, osteoporotic, hip or clinically symptomatic vertebral fracture compared to non-COPD patients (adj. OR 0.65; 95% CI: 0.50–0.86, 0.70; 95% CI: 0.70–0.99, 1.17; 95% CI: 0.59–2.32, 1.98; 95% CI: 0.59–6.65 respectively). We identified an elevated risk of osteoporotic fracture among patients who visited the emergency unit (adj. OR 1.47; 95% CI 1.20–1.79) or were hospitalised in the past year for COPD (adj. OR 1.76; 95% CI 1.66–1.85). Current GC use among COPD patients was associated with an increased risk of osteoporotic, hip and clinically symptomatic vertebral fractures compared to patients without COPD.
Conclusion
Intermittent high-dose GCs was not associated with an increased risk of any, osteoporotic, hip or clinically symptomatic vertebral fractures in patients with COPD. Current GC use was however associated with an increased risk of hip and clinically symptomatic vertebral fractures. Therefore, emphasis on prophylactic treatment of fractures may not be essential in patients with COPD receiving intermittent dose of GCs, whereas this should be considered for high-dose long-term users with advanced COPD disease stage, postmenopausal women and men over 40years.}
}
@article{LI2018366,
title = {A model for simulating schedule risks in prefabrication housing production: A case study of six-day cycle assembly activities in Hong Kong},
journal = {Journal of Cleaner Production},
volume = {185},
pages = {366-381},
year = {2018},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.02.308},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618306462},
author = {Clyde Zhengdao Li and Xiaoxiao Xu and Geoffrey Qiping Shen and Cheng Fan and Xiao Li and Jingke Hong},
keywords = {Prefabrication housing production, Schedule risks, System dynamics, Discrete event simulation, Six-day cycle assembly},
abstract = {The construction industry in Hong Kong has been exposed to serious housing production issues such as insufficient manpower, safety, environmental concerns and inefficient housing supply. Prefabrication housing production has shown as efficient construction model which enables to overcome these issues and it is applied in construction industry in Hong Kong. In this paper, hybrid modeling techniques that combine system dynamics and discrete event simulation are used to analyze the interrelationships of schedule risks within the six-day cycle assembly of prefabrication housing production. Moreover, a hybrid dynamic model is developed to simulate and evaluate the impact of schedule risks on the schedule performance of the six-day cycle assembly of PHP via the Anylogic software package. The resulting model is validated by data which is collected from a PHP project in Hong Kong. Based on the simulation results, the first most influential level contains five schedule risks, namely, inefficient verification of precast components because of ambiguous labels, misplacement on the storage site because of carelessness, owner crane breakdown and maintenance, slow quality inspection procedures, and inefficient design data transition that cause average schedule delays of more than 300 min. The second most influential level includes delay of the delivery of precast element to site, design information gap between designer and manufacturer, installation error of precast elements, and logistics information inconsistency because of human errors, with average schedule delays less than 300 min and greater than 200 min. Design change, low information interoperability between different enterprise resource planning systems, and inefficiency of design approval belong to the third level that imposes the least influence on the schedule delay of the assembly. This research contributes to the current knowledge of the management of prefabrication construction by developing an effective model that offers an in-depth understanding of how schedule performance of PHP is dynamically influenced by interrelationships of various risk variables. Also, it provides an experimental platform for simulating and analyzing schedule risks that significantly affect the schedule performance of the six-day cycle assembly of prefabrication housing production. Such critical schedule risks could be identified and managed prior to the implement of prefabrication housing production projects. Compared with traditional techniques, the hybrid dynamic model simultaneously considers macro and micro levels, thereby enabling project managers to gain a deeper insight into schedule management and acquire a multidimensional understanding of schedule delay.}
}
@article{WAHLEN20179,
title = {Managing variability in algal biomass production through drying and stabilization of feedstock blends},
journal = {Algal Research},
volume = {24},
pages = {9-18},
year = {2017},
issn = {2211-9264},
doi = {https://doi.org/10.1016/j.algal.2017.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211926416306348},
author = {Bradley D. Wahlen and Mohammad S. Roni and Kara G. Cafferty and Lynn M. Wendt and Tyler L. Westover and Dan M. Stevens and Deborah T. Newby},
keywords = {Algae biofuels, Hydrothermal liquefaction, Algae biomass storage, Blending, Economic feasibility, Sustainability},
abstract = {The uncertainty and variability of algal biomass production presents several challenges to the nascent algal biofuel industry, including equipment scaling and feedstock supply. Ideally, on-site processing equipment will be scaled to minimize overall biofuel production costs, which means at times biomass production could exceed down-stream processing capacity due to seasonal variation. Biomass produced in excess of conversion capacity during summer months must be stabilized by some method, such as drying, until needed later in the year. Because of algae's high moisture content and its cohesive nature, drying is challenging. Blending algae with terrestrial biomass may provide a cost-effective method to enable drying and stabilization of algae by reducing moisture content and improving rheological (i.e. flowability) properties. To test the technical feasibility of this approach, bench-scale rotary drum dyers were constructed and tested with blends of algae (Scenedesmus sp.), ground pine (2mm grind), sorghum, corn stover (6mm), sieved sand, and dried algae. In these studies, blends up to 40% algae exhibited drying behavior similar to that of pine alone, and reached dryness (2% moisture) in half of the time it took to dry algae alone. Thermogravimetric analyses performed on blends and neat blend materials provided drying curves consistent with the bench-scale dryers. Preliminary logistics analysis for production-scale operations were performed to determine cost and availability of feedstock materials for blending as compared to drying algae directly. This analysis indicates that revenue lost due to idle processing capacity had a significant impact on the per gallon gasoline equivalent feedstock cost. The blending approach, described herein, reduced feedstock-related costs, including procurement, drying, and storage by 35% relative to drying algae directly. Our results indicate that blending algae with terrestrial biomass enables the use of rotary dryers and has the potential to improve overall algal biofuel economics.}
}
@article{JIN201691,
title = {How users adopt healthcare information: An empirical study of an online Q&A community},
journal = {International Journal of Medical Informatics},
volume = {86},
pages = {91-103},
year = {2016},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2015.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S138650561530054X},
author = {Jiahua Jin and Xiangbin Yan and Yijun Li and Yumei Li},
keywords = {Online healthcare community, Healthcare information adoption, User-generated content, Emotional support},
abstract = {Objectives
The emergence of social media technology has led to the creation of many online healthcare communities, where patients can easily share and look for healthcare-related information from peers who have experienced a similar problem. However, with increased user-generated content, there is a need to constantly analyse which content should be trusted as one sifts through enormous amounts of healthcare information. This study aims to explore patients’ healthcare information seeking behavior in online communities.
Methods
Based on dual-process theory and the knowledge adoption model, we proposed a healthcare information adoption model for online communities. This model highlights that information quality, emotional support, and source credibility are antecedent variables of adoption likelihood of healthcare information, and competition among repliers and involvement of recipients moderate the relationship between the antecedent variables and adoption likelihood. Empirical data were collected from the healthcare module of China’s biggest Q&A community—Baidu Knows. Text mining techniques were adopted to calculate the information quality and emotional support contained in each reply text. A binary logistics regression model and hierarchical regression approach were employed to test the proposed conceptual model.
Results
Information quality, emotional support, and source credibility have significant and positive impact on healthcare information adoption likelihood, and among these factors, information quality has the biggest impact on a patient’s adoption decision. In addition, competition among repliers and involvement of recipients were tested as moderating effects between these antecedent factors and the adoption likelihood. Results indicate competition among repliers positively moderates the relationship between source credibility and adoption likelihood, and recipients’ involvement positively moderates the relationship between information quality, source credibility, and adoption decision.
Conclusions
In addition to information quality and source credibility, emotional support has significant positive impact on individuals’ healthcare information adoption decisions. Moreover, the relationships between information quality, source credibility, emotional support, and adoption decision are moderated by competition among repliers and involvement of recipients.}
}
@article{MARIOTTI201635,
title = {Seized cannabis seeds cultivated in greenhouse: A chemical study by gas chromatography–mass spectrometry and chemometric analysis},
journal = {Science & Justice},
volume = {56},
number = {1},
pages = {35-41},
year = {2016},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1355030615001112},
author = {Kristiane de Cássia Mariotti and Marcelo Caetano Alexandre Marcelo and Rafael S. Ortiz and Bruna Tassi Borille and Monique {dos Reis} and Mauro Sander Fett and Marco Flôres Ferrão and Renata Pereira Limberger},
keywords = { L., Chemical profile, Chemometric analysis},
abstract = {Cannabis sativa L. is cultivated in most regions of the world. In 2013, the Brazilian Federal Police (BFP) reported 220tons of marijuana seized and about 800,000 cannabis plants eradicated. Efforts to eradicate cannabis production may have contributed to the development of a new form of international drug trafficking in Brazil: the sending of cannabis seeds in small amounts to urban centers by logistics postal. This new and increasing panorama of cannabis trafficking in Brazil, encouraged the chemical study of cannabis seeds cultivated in greenhouses by gas-chromatography coupled with mass spectrometry (GC–MS) associated with exploratory and discriminant analysis. Fifty cannabis seeds of different varieties and brands, seized by the BFP were cultivated under predefined conditions for a period of 4.5weeks, 5.5weeks, 7.5weeks, 10weeks and 12weeks. Aerial parts were analyzed and cannabigerol, cannabinol, cannabidiol, cannabichromene Δ9-tetrahydrocannabinol (THC) and other terpenoids were detected. The chromatographic chemical profiles of the samples were significantly different, probably due to different variety, light exposition and age. THC content increased with the age of the plant, however, for other cannabinoids, this correlation was not observed. The chromatograms were plotted in a matrix with 50 rows (samples) and 3886 columns (abundance in a retention time) and submitted to PCA, HCA and PLS-DA after pretreatment (normalization, first derivative and autoscale). The PCA and HCA showed age separation between samples however it was not possible to verify the separation by varieties and brands. The PLS-DA classification provides a satisfactory prediction of plant age.}
}
@article{KIMBALL201684,
title = {A multicenter, longitudinal, interventional, double blind randomized clinical trial in hematopoietic cell transplant recipients residing in remote areas: Lessons learned from the late cytomegalovirus prevention trial},
journal = {Contemporary Clinical Trials Communications},
volume = {4},
pages = {84-89},
year = {2016},
issn = {2451-8654},
doi = {https://doi.org/10.1016/j.conctc.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2451865416300217},
author = {Louise E. Kimball and Terry Stevens-Ayers and Margaret L. Green and Hu Xie and Mary E.D. Flowers and Keith R. Jerome and Renee LeBlanc and Christi Dahlgren and W. Garrett Nichols and Roy F. Chemaly and G. Papanicolaou and Michael Boeckh},
keywords = {Cytomegalovirus, Good clinical practice, Anti-viral treatment},
abstract = {Purpose
The logistics of conducting double-blinded phase III clinical trials with participants residing in remote locations are complex. Here we describe the implementation of an interventional trial for the prevention of late cytomegalovirus (CMV) disease in hematopoietic cell transplantation (HCT) subjects in a long-term follow-up environment.
Methods
A total of 184 subjects at risk for late CMV disease surviving 80 days following allogeneic HCT were randomized to receive six months of valganciclovir or placebo. Subjects were followed through day 270 post-transplant at their local physician's office within the United States. Anti-viral treatment interventions were based on CMV DNAemia as measured by polymerase chain reaction (PCR) (>1000 copies/mL) and granulocyte colony stimulating factor (G-CSF) was prescribed for neutropenia (absolute neutrophil count (ANC < 1.0 × 109 cells/L). Blood samples for viral testing and safety monitoring were shipped to a central laboratory by overnight carrier. Real-time communication was established between the coordinating center and study sites, primary care physicians, and study participants to facilitate starting, stopping and dose adjustments of antiviral drugs and G-CSF. The time required to make these interventions was analyzed.
Results
Of the 4169 scheduled blood specimens, 3832 (92%) were received and analyzed; the majority (97%) arriving at the central site within 2 days. Among subjects with positive CMV DNAemia (N = 46), over 50% received open label antiviral medication within one day. The median time to start G-CSF for neutropenia was <1 day after posting of laboratory results (range 0–6; N = 38). Study drug dose adjustments for abnormal renal function were implemented 203 times; within one day for 48% of cases and within 2 days for 80% of cases.
Conclusion
Complex randomized, double-blind, multicenter interventional trials with treatment decisions made at a central coordinating site can be conducted safely and effectively according to Good Clinical Practice (GCP) guidelines over a large geographic area.}
}
@article{WANG2018822,
title = {The association between cooking oil fume exposure during pregnancy and birth weight: A prospective mother-child cohort study},
journal = {Science of The Total Environment},
volume = {612},
pages = {822-830},
year = {2018},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2017.08.031},
url = {https://www.sciencedirect.com/science/article/pii/S0048969717320296},
author = {Lingling Wang and Weiyue Hu and Quanquan Guan and Guizhen Du and Ting Chen and Wei Wu and Yun Wang and Xinru Wang and Yankai Xia},
keywords = {Cooking oil fumes, Pregnancy exposure, Birth weight, Large for gestational age, Mother-child cohort},
abstract = {Effects of indoor air pollution on neonatal birth weight has been studied for many years. In China, cooking oil fumes are important parts of indoor air pollution. However, whether cooking oil fume exposure during pregnancy affects birth weight in China remains poorly understood. The objective of this study was to examine the association between pregnancy exposure to cooking oil fumes and birth weight in a newly established prospective mother-child cohort in China. We finally included 1420 pregnant women from 2013 to 2015 and follow up for one year until the offspring was born. According to self-reported exposure status, we categorized mothers into non-exposure group and exposed group or three exposure time subgroups, including 0h/day, 0–1h/day and >1h/day respectively. By using multinomial logistics regression models, we found that pregnancy exposure to cooking oil fumes significantly increased the risk of large for gestational age (LGA, OR=1.58, 95% CI=1.15–2.18, P=4.88×10−3). Additionally, compared to pregnant women who were in non-exposure group, 0–1h/day exposure elevated the risk of LGA (OR=1.69, 95% CI=1.22–2.33, P=1.63×10−3), while >1h/day exposure elevated the risk of small for gestational age, but were not significant (SGA, OR=2.15, 95% CI=0.61–7.66, P=0.24). In the stratification analysis, women aged 25–29years and ≥30years were predisposed to the influence of cooking oil fumes and have LGA newborns (OR=1.73, 95% CI=1.09–2.75, P=0.02; OR=1.72, 95% CI=1.07–2.77, P=0.02, respectively). In conclusion, the present study suggests inverse U-shape dose response association between maternal exposure to cooking oil fumes during pregnancy and birth weight, and further studies are needed to verify the effect of cooking oil fumes on the birth weight.}
}
@article{MEDOFF2016634,
title = {The Need for Formal Surgical Global Health Programs and Improved Mission Trip Coordination},
journal = {Annals of Global Health},
volume = {82},
number = {4},
pages = {634-638},
year = {2016},
note = {New Directions in Global Surgery},
issn = {2214-9996},
doi = {https://doi.org/10.1016/j.aogh.2016.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2214999616307640},
author = {Sar Medoff and Jeffrey Freed},
keywords = {Global Health, Surgery, Humanitarian Aid, Mission Trip, Coordination},
abstract = {Background
There is a dire need for more surgical services as part of improving global health. Conditions treatable with surgery account for 11% of the global burden of disease, with a disproportionate burden affecting low- and middle-income countries (LMICs). Less than 6% of the world’s operations are performed in LMICs, with relief organizations performing nearly 250,000 operations annually in LMICs in addition to each country’s domestic surgical capacity. Currently, surgical needs are not adequately met by the existing patchwork of federal and nongovernmental organizations’ surgical services and surgical mission trips. Improving coordination between mission trips may have synergistic benefits for maximizing the efficacy of the individual trips and improving the overall quality of care.
Objectives
To establish whether cooperation between surgical mission trips can lead to operational efficiency and to identify obstacles to cooperation.
Methods
In order to establish the veracity of cooperation translating into efficiency and to identify obstacles that prevent cooperation, a 50-question survey was created (see Supplement 1). The survey was sent to surgical program directors of the 147 major surgical programs in the United States and Canada with a follow-up telephone survey of 18 randomly selected programs.
Findings
The survey response rate was 14%. Although 90% of respondent programs mount at least 1 mission trip per year, only one-third confirmed the existence of global health or surgical global health programs at their institution (33%). There was significant interest in cooperating with programs at other institutions (80%). When asked why they do not communicate with humanitarian aid organizations doing similar work, 53% of respondents reported a “lack of knowledge of how to find similar organizations to mine doing similar work.” An additional 21% of respondents were “unaware that coordination is possible.”
Conclusions
A minority of respondent surgery programs host formal, organized surgical global health programs with a structured leadership based at academic medical centers. Although most institutions have individuals leading international humanitarian missions to LMICs, these leaders do not function in an integrated fashion with their departments, institutions, or other academic medical programs. The majority of respondents were interested in coordinating their surgical trips with other groups. Respondents suggested the creation of a central database that would allow trip organizers to share information about upcoming trips, site logistics, and personnel or supply needs.}
}
@article{BATOOL2018S24,
title = {2386 - The Influence of Sleep Quality, Safety Culture and Cabin Ergonomics on Work-Related Stress and Burnout of Bus Drivers in Lahore},
journal = {Journal of Transport & Health},
volume = {9},
pages = {S24-S25},
year = {2018},
issn = {2214-1405},
doi = {https://doi.org/10.1016/j.jth.2018.05.081},
url = {https://www.sciencedirect.com/science/article/pii/S2214140518302664},
author = {Zahara Batool and Ammar Yasir},
abstract = {Background
Health and working environment of a professional bus driver is comprised in low income countries such as Pakistan which leads to work-related stress and burnout along with excessive involvement in Road Traffic Crashes. Urban bus drivers in Lahore, the second most populated city of Pakistan, are continuously struggling to safely meet travel needs of its ever growing population and are often regarded as stressed and aggressive. Thus, this study investigates factors affecting their safe operations from health and work environment perspectives (e.g. sleep quality, safety culture) and measures their associated stress and BO level.
Methods
Sample of four forty nine public and transit bus drivers of the city are interviewed. The questionnaire contained three sections and used different subjective rating different based upon their past reliability. Stress is measured using Siegrist's Effort/Reward imbalance model and Burnout is measured using Copenhagen Burnout Inventory. For predictors, Pittsburg Sleep Quality Index is used for sleep quality while Global Aviation Network scale is used for safety culture assessment. Ergonomic design of the driver's workstation is evaluated using five self-constructed questions. Information related to socio-demographic and health factors (i.e. BMI) is also collected. Descriptive and regression analyses (both simple linear and logistics regression) are performed for determination of significant determinants and their associations.
Results
Results show the traces of stress in both groups (i.e. public and transit) which is emerged as physical and psychological health damaging factor. As drastic increment in stress is boosting burnout syndrome which is suspected more in public bus drivers as compared to transit drivers. Poor sleep quality (i.e. PSQI >5) along with overweight problem (i.e. BMI>25) is also found in both groups. Regression analyses further confirms their joint effect in instigating stress and burnout. However, safety culture and bus ergonomics are found to moderately effecting both cases. Among socio-demographic factors, low income level is found to be a dominant factor causing stress and burnout.
Conclusions
This research concludes that less recognition and focus on health factors and safety culture at organization level are significantly contributing to increased stress and burnout levels of drivers. Specifically, factors such as fear of pay deduction in case of not meeting timelines, prolong sitting on overused buses with lot of vibrations, temperature rise due to engine heat and to drive in a dense noisy traffic during hot summer days are badly affecting health and driving performances of drivers in the city.}
}
@article{DANGELICO20171263,
title = {“Green Marketing”: An analysis of definitions, strategy steps, and tools through a systematic review of the literature},
journal = {Journal of Cleaner Production},
volume = {165},
pages = {1263-1279},
year = {2017},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2017.07.184},
url = {https://www.sciencedirect.com/science/article/pii/S0959652617316372},
author = {Rosa Maria Dangelico and Daniele Vocalelli},
keywords = {Green products, Sustainable products, Green marketing, Sustainable marketing, Environmental sustainability, Marketing mix},
abstract = {Over the past decades, environmental sustainability has raised at the top of the international political agenda and has been recognized as a key driver of innovation. As a result, the number of companies developing green products has been rapidly growing and consumers have shown an increasing interest for these products. Thus, understanding the main characteristics of green products, identifying factors affecting their price and consumers' willingness to pay more for them, sales channels and promotional tools (the 4Ps of Green Marketing) would be very useful for companies aiming at designing, developing and marketing green products. For this reason, deeply understanding Green Marketing would foster, on the one hand, cleaner production through the development of green products and, on the other hand, sustainable consumption through the successful marketing of them. To this aim, this study reviews the body of knowledge on the topic, through a systematic review of the literature. Specifically, this paper analyzes: 1) the dominant definitions of Green Marketing (and related concepts) and their evolution over time, 2) the different steps to build a Green Marketing Strategy, and 3) the characteristics of Green Marketing Mix elements. After searching for academic publications in three databases (EBSCO, Scopus, and Web of Science) and selecting publications based on their relevance for the stated aims, 114 studies have been included in the review. Results show that the definition of Green Marketing has changed over time according to the growing relevance of environmental sustainability. Regarding the Green Marketing Strategy, several ways of segmenting consumers have been identified; studies converge in giving greater relevance to green brand positioning rather than to green product positioning and many of them see it as a chance of differentiation. Referring to the Green Marketing Mix, results show that: many types of green products exist; consumers are willing to pay a premium price according to products' functional attributes or their responsibility towards the natural environment; closed-loop supply chain and reverse logistics play a key role; a careful definition of advertisement contents is essential and ecolabels can be important tools. This study provides an in-depth analysis and synthesis of the body of knowledge so far produced in the field of Green Marketing and, as such, it has important implications for managers, scholars, and students.}
}
@article{CHANG2018273,
title = {Polyunsaturated fatty acids and inflammatory markers in major depressive episodes during pregnancy},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {80},
pages = {273-278},
year = {2018},
note = {Peripheral markers of inflammation, oxidative & nitrosative stress pathways and memory functions as a new target of pharmacotherapy in depression},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2017.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0278584616303219},
author = {Jane Pei-Chen Chang and Chih-Ying Lin and Pan-Yen Lin and Yin-Hua Shih and Tsan-Hung Chiu and Ming Ho and Hui-Ting Yang and Shih-Yi Huang and Piotr Gałecki and Kuan-Pin Su},
keywords = {Perinatal depression (PND), Polyunsaturated fatty acids (PUFAs), Major depressive disorder, Inflammation},
abstract = {Introduction
Prenatal depression (PND) is a common psychiatric disorder in pregnant women and leads to psychosocial dysfunction, high suicidal rate, and adverse childcare. Patients with PND have omega-3 polyunsaturated fatty acid (omega-3 or n-3 PUFAs) deficits, which might link to chronic low-grade inflammatory process and the pathophysiological mechanisms of depression. In this case-control study, we examined the levels of PUFAs and inflammatory cytokines in PND.
Method
Blood samples were obtained and analyzed from 16 healthy controls and 17 depressed cases (PND group) diagnosed with Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition (DSM-IV). Independent sample t-test and correlation analysis were performed with Statistical Package for the Social Sciences (SPSS) logistics correlation analysis.
Results
PND group had significantly lower levels of total n-3 (p=0.026), docosahexaenoic acid (DHA) (p=0.020) and eicosapentaenoic (EPA) (p=0.019) but a higher omega-6 (n-6)/n-3 PUFAs ratio (p=0.007) and tumor necrosis factor alpha (TNF-α) (p=0.016) level. Moreover, the duration of current PND episodes were also significantly correlated with DHA, EPA, n-3 PUFAs, n-6/n-3 ratio and TNF-α. In terms of PUFAs and cytokine levels, only DHA was inversely correlated with TNF-α.
Conclusion
PND is significantly associated with lower DHA, EPA, and total n-3 PUFAs levels and an increased n-6/n-3 PUFAs ratio, while the duration of PND is associated with lower levels of n-3 PUFAs, including DHA and EPA. The correlation of PUFAs levels with depression and TNF-α level grant further investigation into the inflammatory process underlying PND, mediated by PUFAs.}
}
@article{BELTON2018384,
title = {The emerging quiet revolution in Myanmar's aquaculture value chain},
journal = {Aquaculture},
volume = {493},
pages = {384-394},
year = {2018},
issn = {0044-8486},
doi = {https://doi.org/10.1016/j.aquaculture.2017.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0044848616307943},
author = {Ben Belton and Aung Hein and Kyan Htoo and L Seng Kham and Aye Sandar Phyoe and Thomas Reardon},
keywords = {Myanmar, Value chain, Farm size, Land use policy, Land tenure, Small and medium enterprises},
abstract = {Myanmar is among the world's leading aquaculture producers. But less is known about its fish farm sector than any other major aquaculture-producing country in Asia. The literature has characterized aquaculture in Myanmar as strongly export oriented, and dominated by very large farms. Past literature had it that small-scale fish farms were almost non-existent due to land use regulations that were thought to have blocked the conversion of paddy land to ponds. The past literature had it that technologies of the big farms were ‘traditional’ and extensive. We tested the conventional wisdoms, treating them as hypotheses; we did so by undertaking the largest (and first survey-based) aquaculture value chain study ever conducted in Myanmar. Our findings are as follows. 1) The great majority of farmed fish produced in Myanmar is sold to the fast growing domestic market; only a small share is exported. 2) Although large fish farms dominate in terms of total pond area, a small/medium farm segment has emerged quickly. This has given rise to a “dualistic” fish farm sector, with many small/medium farmers and nurseries alongside large farms. 3) The take-off of small/medium farms has been helped by the “informal relaxation” of restrictions prohibiting the conversion of paddy land to ponds in the main fish farming zones. 4) The upstream segments (feed and seed) of the supply chain have grown fast as have the midstream segments (wholesale and logistics). Most of this growth is due to a “Quiet Revolution” driven by private investments of small and medium enterprises (SMEs). 5) Some farms (small as well as large) are intensifying their technologies, resulting in adoption of a mix of traditional more modern farm technologies.}
}
@article{HEINRICH2016269,
title = {The Impact of Product Failure on Innovation Diffusion: The Example of the Cargo Bike as Alternative Vehicle for Urban Transport},
journal = {Transportation Research Procedia},
volume = {19},
pages = {269-271},
year = {2016},
note = {Transforming Urban Mobility. mobil.TUM 2016. International Scientific Conference on Mobility and Transport. Conference Proceedings},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2016.12.086},
url = {https://www.sciencedirect.com/science/article/pii/S2352146516308729},
author = {Lea Heinrich and Wolfgang H. Schulz and Isabella Geis},
keywords = {innovation diffusion, early adopters, urban transport, technology deficits, cargo bicycles},
abstract = {Extended Abstract
Transport systems are marked by a strong path dependency due to habits, infrastructure, and market rigidities. This path dependency result is challenging for innovative solutions as they face unexpected barriers, but also abrupt acceleration once the barriers are overcome. In consequence, innovation diffusion needs special attention when transforming the transport system. From previous research, it is known that the success of innovation diffusion depends on factors, such as the early adopters or the spread of information within the social system under consideration of basic economic conditions. Research has shown the importance of information and information distribution in all phases of the innovation diffusion process. Therefore, current studies analyze the effect of information on innovation diffusion among private users as well as among industry actors in terms of buying and investment decisions. As a consequence, word of mouth is a decisive factor. Focusing on the transformation of urban transport networks, the European Commission decided to promote cycling and thus, to open the way for changes in mobility behavior and modal choice. Cycling is assumed to be a sustainable mode with high potentials for resources efficiency, minimization of the impact of the transport system on the environment and improving urban transport systems. E-bikes shall additionally improve the attractiveness of cycling and thereby foster the usage among a larger customer group. Bikes, however, are not only a potential mode for mobility but also play an important role in the transformation of urban logistics. Therefore, cargo bikes are a promising vehicle for innovative urban logistics concepts in terms of sustainable urban transport an improvement of efficiency and reliability of last mile deliveries. The vehicles allow the use of alternative driveways beside main traffic routes and those restricted to motorized vehicles, as well as an easement of parking space search. Consequently, cargo bicycles facilitate time savings and improved accessibility to destination addresses in urban agglomeration areas. Positive effects besides improved efficiency are economic benefits in terms of fuel savings and image effects, the contribution to employees’ health conditions and higher quality of life due to the reduction of harmful impacts on the environment caused by emissions, congestion, and noise. Especially for commercial use, cargo bicycles are equipped with electric power trains enabling the carriage of higher load volumes and the convenient passing of hilly areas. Nevertheless, in the field of passenger transport as well as for local small business, the main barriers are high initial costs which are for not expected to decrease due to high production costs for components such as capable battery systems. Cargo bikes lack acceptance among users as they are thought to be uncomfortable and cumbersome. Offering free trials and pointing out best practices, as well as positive user feedbacks is supposed to help overcoming these barriers and thus strengthening the demand for cargo bikes that in turn would have positive effects on the production costs. The technical and economic viability, ease of use and low complexity are decisive points for increasing the acceptance of the cargo bicycle as an alternative mode of transport for commercial use. The decision to substitute conventional motorized vehicles is based on the existence of a trustworthy, workable alternative. By now, the technology for electric cargo bicycles is still at the beginning and there is an urgent need for improving the performance of vehicles. Assuming the market potential manufacturers as well as component suppliers from across the transport industry are continuously developing new devices and applications to meet the demand. Technical failures in this context might result in high customer complaint rates and the spread of negative word of mouth and the likeliness to forfeit the customers’ goodwill accordingly. To foster the acceptance for cargo bicycles as alternative transport mode for both, private and commercial use, it has to be questioned to which extend technology failure has an impact on the early market phase of the new cargo bike generations, where the level of product information is rather low and the adoption by potential users is likely to be based on the reliability of the product and technology. Hereby it has to be analyzed, if technical deficits only affect the corresponding technology provider or if the effects are transferred to all market actors in terms of competitiveness, market success and further innovative activities and technology developments. Therefore, the main question is to what extend technical deficits of new technologies have an effect on overall market potentials with regard to the adoption on consumer as well as on industry level. This study explores the technological perspective of product adoption by enhancing the process of innovation diffusion picking up the case of product failure of electronic cargo bicycles. Considering lately published studies on innovation and technology diffusion models, decisive impact parameters are applied on product failures in the cargo bike industry. The focus is set on the importance of early adopters regarding their role and influence on the innovation diffusion process. For assessing significant impacts, the representative case of the cargo bike project in Herne (Germany) with the objective to contribute to energy transition in urban agglomeration areas in terms of sustainable urban logistics, is consulted. Seven local businesses tested electric cargo bike prototypes over a period of seven month to identify the actual usage potential of cargo bicycles as alternative mode of transport for commercial use. Due to technical deficits, the predicted usage potential could not be realized. The empirical findings allows the identification of major impact factors on user acceptance and adoption rates for cargo bikes by examining the application performance for the intended field of usage and the test users reaction in terms of usage intensity, complaint intensity and final adoption decision. The evaluation of the usage potential for each user based on the general attitude, business structure and field of application (usage intention) compared to the actual usage intensity of the cargo bike prototype under technical deficit occurrence, allows predicting the adoption likelihood for each user based on the gap between the expected usefulness and the actual vehicle performance. Additionally considering the likelihood to resist the technology adoption, based on the assessment of resistance factors that have been pointed out within various publications on innovation diffusion, the intensity of the perceived adoption barriers due to technical deficits is identified. By furthermore evaluating the coherence of complaint and usage intensity after technical deficit occurrence, the findings allow to classify the early adopters considering the final adoption decision. The authors hereby identify the expected impact on the spread of the technology and limitations on further market developments by analyzing the influences of technical deficits on the user-specific adoption process. Furthermore, the role of early adopter's as change agents and their importance for successful market deployment of new, premature technologies is pointed out. The Herne case has demonstrated that critical users play a crucial role. With high complaint intensity, the test users have revealed technical deficits that have a decisive impact on the user acceptance that otherwise would not have been recognized. With the identification of the decisive impact factors and the proven acceptance once the decisive barriers were overcome (potential vs. performance), the test pilots delivered valuable information not only for the industry in terms of technology adaption and development but also for later adopters to being aware of the vehicle dependent potentials and usage barriers. In this context, the early adopters can be seen as innovation drivers as the pressure on the industry to bring adequate cargo bike models to the market is increased and the technology failure likelihood hereby is lowered. Studying representative cases generates insights into the reason of failure and decisive adoption factors that allow creating a list of factors that may increase the opportunity for success due to the appropriate adoption of product innovation processes. The study points out the potential impacts of product and technology failure for gaining a better understanding of critical factors to prevent future failure. By using various knowledge from innovation diffusion, potentials for success and failure of market deployment, impacts on the industry and the transition towards sustainable urban transport are shown. The potential of efficient market deployment of cargo bicycles for contributing to the transformation of urban transport systems is critically discussed. Finally, the results build a basis for further discussions and research activities in the field of market deployment of transport alternatives such as electric vehicles that have not successfully established in markets yet but provide a high potential for contributing to sustainable development in the area of urban transport.}
}
@article{BEHMEL20161312,
title = {Water quality monitoring strategies — A review and future perspectives},
journal = {Science of The Total Environment},
volume = {571},
pages = {1312-1329},
year = {2016},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2016.06.235},
url = {https://www.sciencedirect.com/science/article/pii/S0048969716314243},
author = {S. Behmel and M. Damour and R. Ludwig and M.J. Rodriguez},
keywords = {Water quality monitoring programs, Intelligent decision support system, Participative approaches},
abstract = {The reliable assessment of water quality through water quality monitoring programs (WQMPs) is crucial in order for decision-makers to understand, interpret and use this information in support of their management activities aiming at protecting the resource. The challenge of water quality monitoring has been widely addressed in the literature since the 1940s. However, there is still no generally accepted, holistic and practical strategy to support all phases of WQMPs. The purpose of this paper is to report on the use cases a watershed manager has to address to plan or optimize a WQMP from the challenge of identifying monitoring objectives; selecting sampling sites and water quality parameters; identifying sampling frequencies; considering logistics and resources to the implementation of actions based on information acquired through the WQMP. An inventory and critique of the information, approaches and tools placed at the disposal of watershed managers was proposed to evaluate how the existing information could be integrated in a holistic, user-friendly and evolvable solution. Given the differences in regulatory requirements, water quality standards, geographical and geological differences, land-use variations, and other site specificities, a one-in-all solution is not possible. However, we advance that an intelligent decision support system (IDSS) based on expert knowledge that integrates existing approaches and past research can guide a watershed manager through the process according to his/her site-specific requirements. It is also necessary to tap into local knowledge and to identify the knowledge needs of all the stakeholders through participative approaches based on geographical information systems and adaptive survey-based questionnaires. We believe that future research should focus on developing such participative approaches and further investigate the benefits of IDSS's that can be updated quickly and make it possible for a watershed manager to obtain a timely, holistic view and support for every aspect of planning and optimizing a WQMP.}
}
@incollection{BATIDZIRAI201691,
title = {Chapter 5 - Biomass Supply and Trade Opportunities of Preprocessed Biomass for Power Generation},
editor = {Patrick Lamers and Erin Searcy and J. Richard Hess and Heinz Stichnothe},
booktitle = {Developing the Global Bioeconomy},
publisher = {Academic Press},
pages = {91-114},
year = {2016},
isbn = {978-0-12-805165-8},
doi = {https://doi.org/10.1016/B978-0-12-805165-8.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051658000057},
author = {B. Batidzirai and M. Junginger and M. Klemm and F. Schipfer and D. Thrän},
keywords = {International trade, supply chain logistics, pelletizing, torrefaction, biopower markets},
abstract = {International trade of solid biomass is expected to increase significantly given the global distribution of biomass resources and anticipated expansion of bioenergy deployment in key global power markets. Given the unique characteristics of biomass, its long-distance trade requires optimized logistics to facilitate competitive delivery value chains. Preprocessing biomass via pelletizing, torrefaction, and hydrothermal carbonization potentially improves bioenergy supply economics as illustrated by two case studies in this chapter. The case studies presented in this chapter compare woody and herbaceous biomass value chains and demonstrate that it is feasible and desirable in current conditions to establish large-scale conversion plants close to mature electricity markets and source preprocessed biomass from the international market. In the short term, conventional pellets are expected to play an important role as the internationally traded solid biomass commodity and feedstock in biopower production. In the near future, torrefied pellets may become the dominant and preferred internationally traded solid biomass commodity as the technology is commercialized. Hydrothermal carbonization technology is also still under development, but has the potential to unlock additional feedstock from wet biomass streams. Successful deployment of these technologies is expected to improve bioenergy supply chains in terms of costs and greenhouse gas impacts. Local bioenergy markets are also expected to develop, and provide localized opportunities for local biomass production and use. Utilization of herbaceous biomass and agricultural residues for power production is a promising option, but its application in cofiring is yet to be proven on a wide commercial scale. The analysis of agricultural residue mobilization in South Africa demonstrates that preprocessing also plays a major role in improving biomass delivery costs and subsequent electricity generation costs in local markets.}
}
@article{VIANNA2018162,
title = {Spatial analysis for site selection in marine aquaculture: An ecosystem approach applied to Baía Sul, Santa Catarina, Brazil},
journal = {Aquaculture},
volume = {489},
pages = {162-174},
year = {2018},
issn = {0044-8486},
doi = {https://doi.org/10.1016/j.aquaculture.2017.12.039},
url = {https://www.sciencedirect.com/science/article/pii/S0044848617325589},
author = {Luiz Fernando de Novaes Vianna and Jarbas Bonetti Filho},
keywords = {Site selection, Coastal zone management, GIS, Coastal zoning, Social carrying capacity},
abstract = {The aim of this research was to propose and evaluate a methodological approach to integration and spatial data analysis in order to generate information towards a participatory site selection for bivalve marine aquaculture in the Baía Sul, Florianópolis, Santa Catarina, Brazil. For this purpose, the Baía Sul was investigated considering an ecosystem approach for aquaculture leading to an assessment of its potential for marine aquaculture. The planning of the aquaculture parks was made through a participatory process to incorporate both environmental carrying capacity and social carrying capacity. Experts and modellers developed a GIS model to assess the potential for marine aquaculture in Baía Sul. Continuous (unclassified) maps were used to provide spatial information about the variation of the potential for marine aquaculture in the Baía Sul. The maps were used to plan 53 aquaculture parks over the Baía Sul. The site selection of the parks was made in six public hearings attended by 403 stakeholders from 38 institutions representing different sectors with diverse interests in coastal zone. The results showed that although the Baía Sul is suitable for the growth of bivalve molluscs, some hydrodynamic characteristics and the influence of urbanization constitute a sanitary risk for the activity. Experts, modellers and stakeholders had a different perception about the importance of criteria in the aquaculture parks site selection. While the experts and modellers considered the environmental criteria as the most important aspect to locate the aquaculture parks, the stakeholders took into account mainly the logistics. The final result of the aquaculture parks location, approved by the Brazilian Ministry of Fisheries and Aquaculture (MPA), adopted the site selection by the stakeholders, providing aquaculture parks in areas with sanitary risk for the bivalve cultivation. The main advantage of the adopted assessment strategy was to identify the divergence between experts, modellers and the stakeholders and the distance that still exist between scientist and decision makers in Brazil.
Statement of relevance
This is the first article about a participatory GIS for aquaculture in Brazil. The method was developed to be according to Ecological Approach to Aquaculture. The results highlight the importance of the participatory GIS in suitability study and site selection because the decision making process is different over the view of researchers, technicians and other social stakeholders.}
}
@article{JARVIS2018502,
title = {Influence of El Niño-Southern Oscillation and the Indian Ocean Dipole on winegrape maturity in Australia},
journal = {Agricultural and Forest Meteorology},
volume = {248},
pages = {502-510},
year = {2018},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2017.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0168192317303416},
author = {C. Jarvis and R. Darbyshire and R. Eckard and I. Goodwin and E. Barlow},
keywords = {La Niña, Large scale climate driver, Pacific Ocean, Sea surface temperatures, Viticulture, Seasonal forecasting},
abstract = {Seasonal timing of winegrape maturity is influenced by weather conditions. Significant changes to day-of-year-of-maturity (DOYM), both earlier and later than average, causes logistical problems during harvest, impacting on grape and wine quality. Shifts in climate circulation patterns resulting from atmospheric teleconnections to changes in sea surface temperature (SST) anomalies associated with El Niño-Southern Oscillation (ENSO) and Indian Ocean Dipole (IOD) events can alter seasonal weather across Australia. Events tend to peak in the austral spring (IOD) and summer (ENSO), when vine and berry development is susceptible to anomalous weather. To investigate the impacts of ENSO and IOD on the Australian winegrape growing sector, SST data and annual grape maturity data from a variety of wine growing regions were collected and analysed. Mean DOYM values during IOD events were significantly (P<0.05) different for the largest number of vineyard blocks, with IOD positive (IOD+) events linked to earliest mean DOYM and IOD negative (IOD−) events linked to latest mean DOYM. ENSO and IOD combined events (ENSOIOD) had the largest difference between earliest mean DOYM and latest mean DOYM (42 days). Results for ENSO only grouped events were mixed, with no clear pattern emerging. This finding suggests that the IOD had more impact on DOYM than ENSO and that the IOD superseded the ENSO signal in combined events for the regions included in this study. The results indicate that improved seasonal forecasting of IOD, ENSO, and combined events would allow the Australian winegrape sector to better plan for changes to timing of grape maturity and associated impacts on grape and wine quality, vineyard management, and harvest logistics.}
}
@article{KRIGSTIN201675,
title = {A review of mechanisms responsible for changes to stored woody biomass fuels},
journal = {Fuel},
volume = {175},
pages = {75-86},
year = {2016},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2016.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0016236116001356},
author = {Sally Krigstin and Suzanne Wetzel},
keywords = {Woody biomass, Storage, Degradation, Mass loss},
abstract = {Large scale bioenergy facilities require vast amounts of biomass materials and take advantage of a variety of woody materials in various forms including logs, hog fuel, bark, forest harvest residue, short-rotation hardwoods and whole tree chips. Development of the supply chain logistics necessary to deliver and utilize these material in a cost effective manner is well underway but is strongly dependent on forest type, regional and local harvesting practices as well as location, size and design of storage facilities available. Storage of woody biomass is necessary at various points along the supply chain but the effect of storage on woody biomass is complex and not fully understood. The key mechanisms responsible for major changes to woody biomass on storage are (i) living cell respiration, (ii) biological degradation, and (iii) thermo-chemical oxidative reaction. All three mechanisms involve mass to energy conversion and contribute to self-heating of piles and dry matter losses. Living cell respiration is a short term effect that lasts only several weeks while starch and sugar are readily available and adequate temperature and oxygen levels are present. Biological degradation is caused by a large variety of organisms from bacteria to wood degrading fungi and function best under specific moisture, temperature and oxygen conditions. Finally, thermo-chemical oxidative reactions can contribute to excessive dry matter loss once elevated temperatures have been attained in the pile as a consequence of the first two mechanisms. This review paper discusses the science behind the mechanisms of change to biomass on storage, and draws examples from experimental research to support the explanations.}
}
@article{BERNUZZI2017291,
title = {Steel storage pallet racks in seismic zones: Advanced vs. standard design strategies},
journal = {Thin-Walled Structures},
volume = {116},
pages = {291-306},
year = {2017},
issn = {0263-8231},
doi = {https://doi.org/10.1016/j.tws.2017.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0263823116307960},
author = {Claudio Bernuzzi and Marco Simoncelli},
keywords = {Steel storage pallet racks, Modal response spectrum analysis (MRSA), Non-linear time-history analysis (NLTH), Low-cycle fatigue (LCF), Load-carrying capacity, Cyclic joint behavior},
abstract = {Steel storage pallet racks are used worldwide to efficiently store goods and products in situations where only limited space is available. Their use has increased remarkably in recent years, owing to the growing importance of the logistics services in the context of the global economy. Despite the quite limited costs of storage racks, essentially due to the extensive use of cold-formed members characterized by high levels of standardization, their safety is of paramount importance. An eventual collapse could in fact result in considerable economic losses and/or loss of human life. The design rules currently adopted, derived from those proposed for more conventional steel buildings, are unable to capture satisfactorily the overall rack response and hence need further improvements, especially for applications in seismic zones. The paper reports the results of a study focussed on the development of more reliable approaches for designing racks against earthquakes. In particular, a wide range of cases of practical interest for routine design has been defined, which is comprised of racks that differ in terms of geometric layout and component performance. For each of them, the load carrying capacity corresponding to different values of the peak ground acceleration has been evaluated via two alternative design approaches: the well-known modal response spectrum analysis approach (MRSA) and an advanced strategy combining non-linear time-history analyses with the assessment of the damage in joints due to the cyclic excursions in plastic range (NLTH-LCF). Based on 56 design cases, requiring in total 1512 structural analyses, the proposed outcomes allow for a direct appraisal of the differences in load carrying capacity. At the same time, the influence of modelling the cyclic joint behavior is highlighted, with reference also to the change in key behavioural parameters, such as flexural strength and rotational stiffness.}
}
@article{GREEN2017S19,
title = {Perpetuating stigma or reducing risk? Perspectives from naloxone consumers and pharmacists on pharmacy-based naloxone in 2 states},
journal = {Journal of the American Pharmacists Association},
volume = {57},
number = {2, Supplement },
pages = {S19-S27.e4},
year = {2017},
note = {Naloxone Supplement},
issn = {1544-3191},
doi = {https://doi.org/10.1016/j.japh.2017.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S1544319117300134},
author = {Traci C. Green and Patricia Case and Haley Fiske and Janette Baird and Shachan Cabral and Dina Burstein and Victoriana Schwartz and Nathan Potter and Alexander Y. Walley and Jeffrey Bratberg},
abstract = {Objectives
Little is known about attitudes of pharmacists and consumers to pharmacy naloxone. We examined perceptions and experiences of pharmacy naloxone from people with opioid use disorder, patients taking chronic opioids for pain, caregivers of opioid users, and pharmacists from 2 early pharmacy naloxone adopter states: Massachusetts and Rhode Island.
Design
Eight focus groups (4 per state) were held in October to December 2015.
Setting and participants
Participants were recruited from pharmacies, health clinics, and community organizations; pharmacists were recruited from professional organizations and pharmacy colleges.
Outcome measures
Focus groups were led by trained qualitative researchers using a topic guide, and recorded and transcribed for analysis. Five analysts developed and applied a coding scheme to transcripts. Thematic analysis involved synthesis of coded data and connections between key themes, with comparisons across the groups.
Results
Sixty-one participants included patients with chronic pain (n = 15), people with opioid use disorders (n = 19), caregivers (n = 16), and pharmacists (n = 11). A majority of pharmacists had dispensed naloxone to patients; a minority of all consumer participants had obtained pharmacy naloxone. Four themes emerged: consumer fear of future consequences if requesting naloxone; pharmacists’ concerns about practice logistics related to naloxone; differing perceptions of how opioid safety is addressed in the pharmacy; and solutions to addressing these barriers. Whereas consumer groups differed in awareness of naloxone and availability at pharmacies, all groups expressed support for the pharmacist’s role and preferences for a universal offer of naloxone based on clear criteria.
Conclusion
Pharmacies complement community naloxone provision to patients and caregivers. To overcome stigma of naloxone receipt, increased public awareness of naloxone and pharmacist training about naloxone and addiction are required. Pharmacists should offer naloxone via universal opt-out strategies—where all patients meeting evidence-based criteria are offered naloxone—rather than targeted or opt-in strategies—where only patients perceived as high risk or patients who request it are offered naloxone.}
}
@article{SHAFIEE201612,
title = {Agent-based modeling and evolutionary computation for disseminating public advisories about hazardous material emergencies},
journal = {Computers, Environment and Urban Systems},
volume = {57},
pages = {12-25},
year = {2016},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516300011},
author = {M. Ehsan Shafiee and Emily Zechman Berglund},
keywords = {Variable-length genetic algorithm, Agent-based model, Water distribution network, Water contamination events, Vehicle routing for relief problem, Covering tour problem, Complex adaptive system, Route alert},
abstract = {In the event of a large-scale disaster, an important aspect of humanitarian logistics is the distribution of information or warnings to the affected population. This research develops the problem formulation and solution approach for a specific routing for relief problem, in which warnings should be disseminated to an affected community, using public announcement systems mounted on emergency vehicles. The problem statement is formulated to maximize the number of individuals of a community who are protected. An evolutionary algorithm framework is developed by coupling an agent-based model with a variable-length genetic algorithm to route emergency vehicles. The dynamics of interactions among consumers, emergency vehicles, and the spatiotemporal trajectory of the hazard are simulated using an agent-based modeling approach, and a variable-length genetic algorithm approach selects routes to warn a maximum number of consumers before they are affected by the emergency. The example that is explored in this research is contamination of a water distribution network. A fleet of emergency vehicles is equipped with public address systems and is deployed to warn consumers to stop using contaminated water. The framework is demonstrated for an illustrative virtual city, Mesopolis. The results of the evolutionary algorithm framework are compared with two conventional routing optimization approaches, including a covering tour problem approach and a manual routing approach, for four contamination scenarios. The evolutionary algorithm can be applied to route emergency service vehicles to broadcast information for other emergencies, such as flash flooding, hazardous materials incidents, and severe weather.}
}
@article{MEERSMAN2017316,
title = {The contribution of transport infrastructure to economic activity: The case of Belgium},
journal = {Case Studies on Transport Policy},
volume = {5},
number = {2},
pages = {316-324},
year = {2017},
issn = {2213-624X},
doi = {https://doi.org/10.1016/j.cstp.2017.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S2213624X17300871},
author = {Hilde Meersman and Marzieh Nazemzadeh},
keywords = {Transport infrastructure investment, Economic growth, Openness of economy},
abstract = {The role of the expansion of transport infrastructure in stimulating economic growth in developed countries is not straightforward. This can lead to debates concerning public investments in transport infrastructure especially when public funds are scarce and the demand for investments is high in social sectors such as education, health and social care. However, it is hard to generalise the potential growth impact of transport infrastructure as it can differ over regions and will be affected by the presence or absence of other drivers of economic growth. As a case the situation in Belgium is considered. It is a small, open economy which is highly integrated into the world economy and facing a considerable growth in passenger, but especially in freight transport. Its geographical position and the presence or proximity of important ports and airports in combination with a dense road and rail network makes it one of the gateways of Europe. The transport and logistics sector generates considerable employment and added value. However, the dense population, the concentration of public administration in Brussels and the large amount of transit freight flows result in a large pressure on the existing transportation infrastructure which becomes more and more congested. The large traffic flows generate negative external effects for people, planet and profit. Opponents of further expansion of especially ports, airports, and roads often focus on the negative external effects on people and the planet as they call into question the positive effects on profit and economic growth. Based on aggregate growth modelling and a causality test, some error-correction models are estimated using annual data for Belgium. They reveal that for Belgium GDP per capita is not only positively impacted by traditional indicators such as the openness of the Belgian economy, the rate of investment as a whole, and technological change, but also by the length of the motorways, the rail network and the investments in port infrastructure. As a consequence the evaluation of new transport infrastructure projects should take into account this contribution to economic growth.}
}
@article{KOUADIO20165175,
title = {Polio infrastructure strengthened disease outbreak preparedness and response in the WHO African Region},
journal = {Vaccine},
volume = {34},
number = {43},
pages = {5175-5180},
year = {2016},
note = {Polio Eradication Initiative Best Practices in the WHO African Region},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.05.070},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X16303966},
author = {Koffi Kouadio and Joseph Okeibunor and Peter Nsubuga and Richard Mihigo and Pascal Mkanda},
keywords = {Polio best practice, Outbreak, Diseases, Response, Preparedness},
abstract = {Introduction
The continuous deployments of polio resources, infrastructures and systems for responding to other disease outbreaks in many African countries has led to a number of lessons considered as best practice that need to be documented for strengthening preparedness and response activities in future outbreaks.
Methods
We reviewed and documented the influence of polio best practices in outbreak preparedness and response in Angola, Nigeria and Ethiopia. Data from relevant programmes of the WHO African Region were also analyzed to demonstrate clearly the relative contributions of PEI resources and infrastructure to effective disease outbreak preparedness and response.
Results
Polio resources including, human, financial, and logistic, tool and strategies have tremendously contributed to responding to diseases outbreaks across the African region. In Angola, Nigeria and Ethiopia, many disease epidemics including Marburg Hemorrhagic fever, Dengue fever, Ebola Virus Diseases (EVD), Measles, Anthrax and Shigella have been controlled using existing polio Eradication Initiatives resources. Polio staffs are usually deployed in occasions to supports outbreak response activities (coordination, surveillance, contact tracing, case investigation, finance, data management, etc.). Polio logistics such vehicles, laboratories were also used in the response activities to other infectious diseases. Many polio tools including micro planning, dashboard, guidelines, SOPs on preparedness and response have also benefited to other epidemic-prone diseases. The Countries’ preparedness and response plan to WPV importation as well as the Polio Emergency Operation Center models were successfully used to develop, strengthen and respond to many other diseases outbreak with the implication of partners and the strong leadership and ownership of governments. This review has important implications for WHO/AFRO initiative to strengthening and improving disease outbreak preparedness and responses in the African Region in respect to the international health regulations core capacities.}
}
@article{DIFELICE201838,
title = {Drone high resolution infrared imaging of the Lusi mud eruption},
journal = {Marine and Petroleum Geology},
volume = {90},
pages = {38-51},
year = {2018},
note = {10 years of Lusi eruption - lessons learned about modern and ancient piercement systems},
issn = {0264-8172},
doi = {https://doi.org/10.1016/j.marpetgeo.2017.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S0264817217304269},
author = {F. {Di Felice} and A. Mazzini and G. {Di Stefano} and G. Romeo},
keywords = {Lusi eruption, Indonesia, Drone survey, Thermal infrared, Volcanic monitoring, Sediment-hosted hydrothermal system, Convective cells},
abstract = {The use of low-cost hand-held infrared (IR) thermal cameras based on uncooled micro-bolometer detector arrays became more widespread during the recent years. Thermal cameras have the ability to estimate temperature values without contact and therefore can be used in conditions where targets are difficult or dangerous to reach such as volcanic eruptions. Since May 2006 the Indonesian Lusi mud eruption continues to spew boiling mud, water, aqueous vapour, CO2, CH4 and covers a surface of nearly 7 km2. Here we performed surveys above and around the erupting crater using a specifically equipped remote-controlled aerial vehicle (drone). Despite the harsh logistics and the continuously varying gas concentrations, we managed to collect IR images composing mosaics to estimate the crater zone spatial and temporal thermal variations as well as that in the surrounding regions. In this manuscript we provide a) a description of the main processes that affect and control the acquisition of IR images; b) an overview of still non disclosed physical model used by the thermal camera employed during our survey (i.e. Flir I7 IR); c) a method for capturing high resolution infrared images over an erupting clastic system; d) analysis and interpretation of the acquired data and scientific results. The results show that it is possible to obtain good quality mosaics also in inaccessible areas such as erupting craters where fixed reference points are not constant, and where the presence of IR attenuation factors introduce errors in terms of temperature estimates. However the IR camera radiative transfer model (based on Lowtran model) allows the control of only some of the parameters that affect the attenuation of the IR spectrum. This results in obtained crater temperature estimates up to ∼20% lower than those measured with hand held thermometers, providing, however, very important information about the thermal gradient and the potential radioactive absorption factors. The imaged Lusi vent thermal pattern suggests the presence of shallow convective chambers inside the caldera zone; these are activated by the rise of boiling mud breccia that suddenly cools and sinks. The thermal survey conducted on the dry mud region to the NE of the crater reveals temperatures matching with those measured directly on the field with a hand held thermometer. Here the presence of hot spot anomalies and colder circular features is consistent with the migration of deeper warm fluids along a faulted and fractured area and with widespread pools distribution.}
}
@article{CUCUNUBA2017187,
title = {How universal is coverage and access to diagnosis and treatment for Chagas disease in Colombia? A health systems analysis},
journal = {Social Science & Medicine},
volume = {175},
pages = {187-198},
year = {2017},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2017.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0277953617300023},
author = {Zulma M. Cucunubá and Jennifer M. Manne-Goehler and Diana Díaz and Pierre Nouvellet and Oscar Bernal and Andrea Marchiol and María-Gloria Basáñez and Lesong Conteh},
keywords = {Chagas disease, Access, Coverage, Mixed methods, Health system, Colombia},
abstract = {Limited access to Chagas disease diagnosis and treatment is a major obstacle to reaching the 2020 World Health Organization milestones of delivering care to all infected and ill patients. Colombia has been identified as a health system in transition, reporting one of the highest levels of health insurance coverage in Latin America. We explore if and how this high level of coverage extends to those with Chagas disease, a traditionally marginalised population. Using a mixed methods approach, we calculate coverage for screening, diagnosis and treatment of Chagas. We then identify supply-side constraints both quantitatively and qualitatively. A review of official registries of tests and treatments for Chagas disease delivered between 2008 and 2014 is compared to estimates of infected people. Using the Flagship Framework, we explore barriers limiting access to care. Screening coverage is estimated at 1.2% of the population at risk. Aetiological treatment with either benznidazol or nifurtimox covered 0.3–0.4% of the infected population. Barriers to accessing screening, diagnosis and treatment are identified for each of the Flagship Framework's five dimensions of interest: financing, payment, regulation, organization and persuasion. The main challenges identified were: a lack of clarity in terms of financial responsibilities in a segmented health system, claims of limited resources for undertaking activities particularly in primary care, non-inclusion of confirmatory test(s) in the basic package of diagnosis and care, poor logistics in the distribution and supply chain of medicines, and lack of awareness of medical personnel. Very low screening coverage emerges as a key obstacle hindering access to care for Chagas disease. Findings suggest serious shortcomings in this health system for Chagas disease, despite the success of universal health insurance scale-up in Colombia. Whether these shortcomings exist in relation to other neglected tropical diseases needs investigating. We identify opportunities for improvement that can inform additional planned health reforms.}
}
@article{SANCHEZGARCIA2017201,
title = {A GIS methodology for optimal location of a wood-fired power plant: Quantification of available woodfuel, supply chain costs and GHG emissions},
journal = {Journal of Cleaner Production},
volume = {157},
pages = {201-212},
year = {2017},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2017.04.058},
url = {https://www.sciencedirect.com/science/article/pii/S0959652617307667},
author = {S. Sánchez-García and D. Athanassiadis and C. Martínez-Alonso and E. Tolosana and J. Majada and E. Canga},
keywords = {Woodfuel, WISDOM, Accessibility, GIS analysis, Harvesting costs, Life cycle assessment},
abstract = {The objective of this study was to establish a Geographical Information System (GIS) based methodology to analyze the viability and optimal location of a new hypothetical wood-fired power plant in a specific region. The available woodfuel of Eucalyptus globulus suitable for energy use was calculated based on a WISDOM database (Woodfuel Integrated Supply/Demand Overview Mapping) which takes into account physical and legal accessibility of the resource. Available woodfuel is defined as the material remaining on the ground (crown and bark) after harvesting Eucalyptus stems, discounting the volume required to meet the current energy demand. Various spatial analyses were performed using ArcGIS 10.2.1, particularly the Network Analyst tool, to identify the optimized location of the new power plant. Then, considering the most common biomass harvesting system in a specified region, the costs and GHG emissions of the supply chain for this demand point were calculated. Total costs were calculated using machine productivity data and minimized distance calculation and GHG emissions by the amount of CO2e emitted, based on the Life Cycle Analysis methodology using productivity and fuel consumption data. A sensitivity analysis was also carried out to test the influence of moisture content and transport distances on the total cost and the GHG emissions. The results show that bundling was the highest cost (63.67% of total costs), followed by trucking (26.80%) and forwarding (9.53%). The GHG emissions for the whole system were 9.17 Kg CO2e/MWh, with the trucking being the greatest contributor, and bundling the second. The energy balance ratio (energy required as a percentage of energy produced by the system) was slightly over 2%, demonstrating high efficiency. The methodology presented here will help policy makers to evaluate possible locations for any future wood-fired power plants in terms of the lowest economic costs of supplying woodfuel and its environmental impact. This study extends on the scope of prior research, providing a realistic and detailed methodology for planning and logistics decision making in relation to the dynamization and sustainability of woodfuel for energy use.}
}
@article{ALI201670,
title = {Efficacy of two hydrogen peroxide vapour aerial decontamination systems for enhanced disinfection of meticillin-resistant Staphylococcus aureus, Klebsiella pneumoniae and Clostridium difficile in single isolation rooms},
journal = {Journal of Hospital Infection},
volume = {93},
number = {1},
pages = {70-77},
year = {2016},
issn = {0195-6701},
doi = {https://doi.org/10.1016/j.jhin.2016.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0195670116000839},
author = {S. Ali and M. Muzslay and M. Bruce and A. Jeanes and G. Moore and A.P.R. Wilson},
keywords = {Hydrogen peroxide, Whole-room aerial decontamination, Infection control, , MRSA, },
abstract = {Summary
Background
Hydrogen peroxide vapour (HPV) disinfection systems are being used to reduce patients' exposure to hospital pathogens in the environment. HPV whole-room aerial disinfection systems may vary in terms of operating concentration and mode of delivery.
Aim
To assess the efficacy of two HPV systems (HPS1 and HPS2) for whole-room aerial disinfection of single isolation rooms (SIRs).
Methods
Ten SIRs were selected for manual terminal disinfection after patient discharge. Test coupons seeded with biological indicator (BI) organisms [∼106 colony-forming units (cfu) of meticillin-resistant Staphylococcus aureus (MRSA) or Klebsiella pneumoniae, or ∼105cfu Clostridium difficile 027 spores] prepared in a soil challenge were placed at five locations per room. For each cycle, 22 high-frequency-touch surfaces in SIRs were sampled with contact plates (∼25cm2) before and after HPV decontamination, and BIs were assayed for the persistence of pathogens.
Findings
Approximately 95% of 214 sites were contaminated with bacteria after manual terminal disinfection, with high numbers present on the SIR floor (238.0–352.5cfu), bed control panel (24.0–33.5cfu), and nurse call button (21.5–7.0cfu). Enhanced disinfection using HPV reduced surface contamination to low levels: HPS1 [0.25cfu, interquartile range (IQR) 0–1.13] and HPS2 (0.5cfu, IQR 0–2.0). Both systems demonstrated similar turnaround times (∼2–2.5h), and no differences were observed in the efficacy of the two systems against BIs (C. difficile ∼5.1log10 reduction; MRSA/K. pneumoniae ∼6.3log10 reduction). Despite different operating concentrations of hydrogen peroxide, MRSA persisted on 27% of coupons after HPV decontamination.
Conclusion
Enhanced disinfection with HPV reduces surface contamination left by manual terminal cleaning, minimizing the risks of cross-contamination. The starting concentration and mode of delivery of hydrogen peroxide may not improve the efficacy of decontamination in practice, and therefore the choice of HPV system may be based upon other considerations such as cost, convenience and logistics.}
}
@article{SEYYEDHASANI2017142,
title = {Using the Vehicle Routing Problem to reduce field completion times with multiple machines},
journal = {Computers and Electronics in Agriculture},
volume = {134},
pages = {142-150},
year = {2017},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2016.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168169916310286},
author = {Hasan Seyyedhasani and Joseph S. Dvorak},
keywords = {Vehicle Routing Problem, Effective field capacity, Field efficiency, Agricultural machinery, Tabu Search, Simulation},
abstract = {The Vehicle Routing Problem (VRP) is a powerful tool used to express many logistics problems, yet unlike other vehicle routing challenges, agricultural field work consists of machine paths that completely cover a field. In this work, the allocation and ordering of field paths among a number of available machines has been transformed into a VRP that enables optimization of completion time for the entire field. A basic heuristic algorithm (a modified form of the common Clarke-Wright algorithm) and a meta-heuristic algorithm, Tabu Search, were employed for optimization. Both techniques were evaluated through computer simulations in two fields: a hypothetical basic rectangular field and a more complex, real-world field. Field completion times and effective field capacity were calculated for cases when 1, 2, 3, 5, and 10 vehicles were used simultaneously. Although the Tabu Search method required more than two hours to produce its solution on an Intel i7 processor compared to less than one second for the method based on Clarke-Wright, Tabu Search provided better solutions that resulted in reduced field completion times and increased effective field capacity. The benefit provided by Tabu Search was larger in the more complex field and as the number of vehicles increased. With ten vehicles in the real-world field, the benefit provided by Tabu Search over the modified Clarke-Wright resulted in reduced completion time of 32%, but even with only three vehicles a 15% reduction was obtained. While ten vehicles may only be applicable with future autonomous machines, simultaneous usage of three machines is not uncommon in current production. As producers consider using multiple machines to improve field completion times and effective field capacity, optimization of the vehicle routing will play an important role in ensuring those improvements are fully realized.}
}
@article{SHORTALL20181,
title = {The effect of dairy cow breed on milk production, cow traffic and milking characteristics in a pasture-based automatic milking system},
journal = {Livestock Science},
volume = {209},
pages = {1-7},
year = {2018},
issn = {1871-1413},
doi = {https://doi.org/10.1016/j.livsci.2018.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871141318300027},
author = {J. Shortall and C. Foley and R.D. Sleator and B. O’Brien},
keywords = {Milking frequency, Milking distribution, Holstein-Friesian, Norwegian Red, Jersey},
abstract = {Despite the increasing frequency of integrated automatic milking (AM) and pasture-based systems, there is limited knowledge available on the suitability of different dairy cow breeds to these systems. Thus, the objective of this experiment was to establish the performance of three breeds in a pasture-based AM system with respect to milk production, cow traffic and milking characteristics. The breeds examined were Holstein Friesian (HF), Jersey x HF (JEX) and Norwegian Red x HF (NRX), all of which have been previously identified as being compatible with conventional milking pasture-based systems. The experiment was conducted in mid-lactation and variables measured included milking frequency, -interval, -outcome and -characteristics, milk yield/milking and per day, wait time/visit and per day, return time/visit and the daily distribution of milking events. Data were statistically analysed using least squares means mixed procedure models, while the proportion of different milking events were analysed using the logistics procedure. While there were no significant differences between breeds for milking frequency, or milk production, significant differences did exist for proportion of successful and failed milkings events, with NRX cows recording the highest and lowest proportions, respectively. JEX also recorded a significantly shorter dead time/quarter at 17.6s/milking compared to the HF and NRX breeds at 28.5 and 27.7s/milking, respectively. Significant differences also existed with regard to cow traffic, with the NRX breed returning from pasture more quickly and waiting a shorter time both per visit and per day in the pre-milking yard. The distribution of milking events differed between the breeds examined, with the JEX cows recording less milkings in the hour after the pre-selection gate changes of 0000h and 1600h. JEX also recorded a significantly greater proportion of milkings than the NRX and HF cows during the hours at which the lowest proportion of total milking events were recorded (0400–0600h). For the optimisation of the AM system it is important to have an even distribution of milkings throughout the day. Based on the evidence from the current experiment, this may be best achieved by a mixed breed herd rather than a single breed herd. However, the performance of the examined breeds should also be analysed in the context of the whole AM farm system, over an entire lactation, taking into consideration the range of variables that contribute to a profitable farm system.}
}
@article{ESPANAFUENTE2017108,
title = {Uso del videolaringoscopio King Vision® en una vía aérea difícil no esperada por un quiste vallecular gigante en un adulto, a propósito de un caso},
journal = {Revista Española de Anestesiología y Reanimación},
volume = {64},
number = {2},
pages = {108-111},
year = {2017},
issn = {0034-9356},
doi = {https://doi.org/10.1016/j.redar.2016.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0034935616301013},
author = {L. {España Fuente} and P. {de la Rica Fernández} and J.L. {González González}},
keywords = {Quiste vallecular, Videolaringoscopio, Inducción, Cirugía urgente, Laringoscopia, Vallecular cyst, Videolaryngoscope, Induction, Urgent surgery, Laryngoscopy},
abstract = {Resumen
Los quistes laríngeos suelen ser asintomáticos y normalmente son un hallazgo casual durante una exploración laríngea rutinaria. Estos quistes, en adultos son raros y pueden tener consecuencias catastróficas en el paciente anestesiado si el manejo de la vía aérea no es el adecuado. A continuación, se describe el caso de una intubación difícil y el manejo de la misma, en un paciente adulto con un quiste de vallécula gigante, asintomático que se descubrió durante la inducción de secuencia rápida de una anestesia general en cirugía de urgencia. En conclusión, los quistes de vallécula pueden dificultar el manejo de la vía aérea. Es importante evitar las complicaciones asociadas a los repetidos intentos de intubación que pueden provocar edema de la vía aérea, sangrado y rotura del quiste con la consiguiente aspiración de su contenido, siendo el videolaringoscopio King Vision® una buena alternativa en estos casos. La disponibilidad de un otorrinolaringólogo es fundamental.
Laryngeal cysts are largely asymptomatic and typically described in the context of incidental discovery on routine laryngoscopy. These cysts, in adults are even rarer and can have catastrophic consequences in an anaesthetized patient if airway management is inappropriate. We describe a case of difficult endotracheal intubation and the treatment of an adult patient with an asymptomatic, giant vallecular cyst that was discovered during rapid-sequence induction of general anesthesia in urgent surgery. In conclusion, vallecular cysts can cause extreme problems in securing the airway. It is important to avoid complications associated with repeated attempts at intubation, airway loss, or cyst rupture causing difficulty visualizing vocal cords and aspiration. The use of King Vision® videolaryngoscope is a good alternative in these cases. Close attention to logistics and the immediate availability of an otolaryngologist is vital.}
}
@article{MYERS20163942,
title = {Predictors of maternal vaccination in the United States: An integrative review of the literature},
journal = {Vaccine},
volume = {34},
number = {34},
pages = {3942-3949},
year = {2016},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.06.042},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X16304662},
author = {Kristen L. Myers},
keywords = {Maternal vaccination, Influenza, Pertussis, Health Belief Model, Implementation science},
abstract = {Objectives
The purpose of this literature review was to identify, analyze, and synthesize existing research related to patient, provider, and health system predictors of maternal vaccination in the United States, strategies used to increase maternal vaccination rates, and major theoretical frameworks used to guide maternal vaccination research.
Methods
A search for evidence was conducted in CINAHL, PubMed, PsychINFO, Cochrane Systematic Reviews, and Google Scholar. Twenty-two articles were identified as best evidence for inclusion in this review: five randomized control trials, one cluster randomized trial, one mixed methods study, 12 observational studies, and three qualitative studies.
Results
Patient-focused predictors of maternal vaccination included provider recommendation; knowledge, attitudes, and beliefs; cues to action; and race and ethnicity. Provider-focused predictors included knowledge, attitudes, and beliefs; and multi-component intervention packages. Health system predictors included standing order protocols and practice site logistics. The major theoretical frameworks that emerged were the Health Belief Model, Theory of Reasoned Action/Theory of Planned Behavior, and Message Framing/Prospect Theory. Provider recommendation was the single most important predictor of vaccine acceptance among pregnant women.
Conclusions
An abundance of theoretically-supported, patient-focused research was found in the literature. A minimal number of U.S.-based, provider-focused research was found and none of these used a theoretical framework. Minimal research examining health system barriers to maternal vaccination was found. Additional research into the logistical barriers to maternal vaccination programs within obstetrical practice locations in other geographical locations within the U.S. is warranted. Future provider- and health system-focused research needs to be grounded in theory. The field of implementation science may offer the theoretical guidance necessary to better understand problems in obstetrical practice work flow and streamlining of vaccinations.}
}
@article{LUZZE20172141,
title = {Understanding the policy environment for immunization supply chains: Lessons learned from landscape analyses in Uganda and Senegal},
journal = {Vaccine},
volume = {35},
number = {17},
pages = {2141-2147},
year = {2017},
note = {Building Next Generation Immunization Supply Chains},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.10.089},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X16311070},
author = {Henry Luzze and Ousseynou Badiane and El Hadji {Mamadou Ndiaye} and Annette Seck Ndiaye and Brian Atuhaire and Phionah Atuhebwe and Phillippe Guinot and Erin {Fry Sosne} and Abdoulaye Gueye},
keywords = {Immunization supply chain, Policy, Advocacy, Uganda, Senegal},
abstract = {As immunization programs around the world undergo rapid change and expansion, supply chain and logistics systems have become strained, making it increasingly challenging for national public health systems to provide reliable, safe, and efficient access to vaccines. Governments and immunization partners have been aware of this problem for several years, and in 2010, the World Health Organization (WHO) launched the Effective Vaccine Management (EVM) process to help countries identify shortcomings in their immunization supply chains and develop plans for systematic improvement. EVM improvement plans now exist in all Gavi-eligible countries plus many middle- and upper-income countries; however, implementation has been slow and in many cases fraught with financial, managerial, structural, and political roadblocks. Recognizing that significant change of any kind requires a supportive policy environment and strong leadership, PATH began working in Uganda and Senegal to landscape the policy environment around immunization and identify relevant policies, administrative and technical roles and responsibilities, and other issues that may be affecting the supply chain for immunization. The policy landscape assessments included a desk review and a series of structured, in-depth interviews with key international, national, and local stakeholders. The findings highlighted a number of critical issues and challenges in both countries that may be preventing supply chains from functioning optimally. These challenges include a need for better coordination and planning between immunization programs and supply chain managers; the need for sufficient, timely and reliable financing for all aspects of immunization programs; the need for high-level managers trained in immunization supply chain management; and an urgent need for better, more timely data for decision-making. Overcoming these challenges will require the involvement of high-level political actors—including ministers of health and finance, parliamentarians, and other officials who have the ability to approve and influence policy, personnel, and structural changes; ensure work plans are backed with adequate resources for implementation; and hold program managers accountable for achieving agreed indicators.}
}
@article{CAMPANIELLO2016242,
title = {Returns to education in criminal organizations: Did going to college help Michael Corleone?},
journal = {Economics of Education Review},
volume = {54},
pages = {242-258},
year = {2016},
issn = {0272-7757},
doi = {https://doi.org/10.1016/j.econedurev.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0272775716301303},
author = {Nadia Campaniello and Rowena Gray and Giovanni Mastrobuoni},
keywords = {Returns to education, Organized crime, Mafia, Italian–American immigration, Federal Bureau of Narcotics, 1940 Census},
abstract = {Is there any return to education in criminal activities? This paper is one of the first to investigate whether education has not only a positive impact on legitimate, but also on illegitimate activities. We use as a case study one of the longest running criminal corporations in history: the Italian-American mafia. Its most successful members were capable businessmen, orchestrating crimes that required abilities that might be learned at school: extracting the optimal rent when setting up a racket, weighting interests against default risk when starting a loan sharking business or organizing supply chains, logistics and distribution when setting up a drug dealing system. We address this question by comparing mobsters to a variety of samples drawn from the United States 1940 Population Census, including a sample of their closest (non-mobster) neighbors. We document that mobsters have one year less education than their neighbors on average. We find that mobsters have significant returns to education of 7.5–8.5% , which is only slightly smaller than their neighbors and 2–5 percentage points smaller than for U.S.-born men or male citizens. Mobster returns were consistently about twice as large as a sample of Italian immigrants or immigrants from all origin countries. Within that, those charged with complex crimes including embezzlement and bookmaking have the highest returns. We conclude that private returns to education exist even in the illegal activities characterized by a certain degree of complexity as in the case of organized crime in mid-twentieth century United States.}
}
@article{KIM2016139,
title = {Development of environmental impact monitoring protocol for offshore carbon capture and storage (CCS): A biological perspective},
journal = {Environmental Impact Assessment Review},
volume = {57},
pages = {139-150},
year = {2016},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0195925515001201},
author = {Hyewon Kim and Yong Hoon Kim and Seong-Gil Kang and Young-Gyu Park},
keywords = {Offshore carbon capture and sequestration (CCS), CO leakage, Environmental risk assessment, Ocean acidification, Hypercapnia},
abstract = {Offshore geologic storage of carbon dioxide (CO2), known as offshore carbon capture and sequestration (CCS), has been under active investigation as a safe, effective mitigation option for reducing CO2 levels from anthropogenic fossil fuel burning and climate change. Along with increasing trends in implementation plans and related logistics on offshore CCS, thorough risk assessment (i.e. environmental impact monitoring) needs to be conducted to evaluate potential risks, such as CO2 gas leakage at injection sites. Gas leaks from offshore CCS may affect the physiology of marine organisms and disrupt certain ecosystem functions, thereby posing an environmental risk. Here, we synthesize current knowledge on environmental impact monitoring of offshore CCS with an emphasis on biological aspects and provide suggestions for better practice. Based on our critical review of preexisting literatures, this paper: 1) discusses key variables sensitive to or indicative of gas leakage by summarizing physico-chemical and ecological variables measured from previous monitoring cruises on offshore CCS; 2) lists ecosystem and organism responses to a similar environmental condition to CO2 leakage and associated impacts, such as ocean acidification and hypercapnia, to predict how they serve as responsive indicators of short- and long-term gas exposure, and 3) discusses the designs of the artificial gas release experiments in fields and the best model simulation to produce realistic leakage scenarios in marine ecosystems. Based on our analysis, we suggest that proper incorporation of biological aspects will provide successful and robust long-term monitoring strategies with earlier detection of gas leakage, thus reducing the risks associated with offshore CCS.}
}
@article{SARKAR2017148,
title = {Environmental and economic assessment of closed-loop supply chain with remanufacturing and returnable transport items},
journal = {Computers & Industrial Engineering},
volume = {111},
pages = {148-163},
year = {2017},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2017.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360835217302930},
author = {Biswajit Sarkar and Mehran Ullah and Namhun Kim},
keywords = {Closed-loop supply chain, Remanufacturing, Carbon emission, Returnable transport items, Transportation},
abstract = {Devastating environmental impacts of supply chain(s) (SC) have resulted in government legislation, customer awareness, and pressure from various stakeholders to implement environmentally sustainable strategies in SC. The most important objectives of the sustainable supply chain management (SCM) are enhancement of value creation over product life-cycle by reuse and considerations of environmental impacts. Environmental issues arising from manufacturing and logistic operations affect the economic growth as well as sustainability of the SC which must be considered during policy making. To achieve the economic goals and to improve the sustainability of SC, this paper proposes a multi-echelon closed-loop supply chain (CLSC) model with a third party logistics (3PL) that provides transportation and collection services. The proposed model investigates environmental impacts from production and transportation in a hybrid manufacturing-remanufacturing system which uses returnable transport items (RTI) for product transportation. Objectives of the model are to study the impacts of transportation and carbon emission costs in a hybrid CLSC, and to devise best RTI management policies under the influence of these costs. The developed mathematical model falls under the category of mixed-integer non-linear programming (MINLP) problems, for which an improved solution methodology has been proposed. The total cost is minimized with simultaneous optimization of container capacity, required number of containers, shipment sequence of retailers, cycle time, and remanufacturing rate. Robustness of the model is illustrated through a numerical example with five different cases, graphical representations, and sensitivity analysis. Results prove that ignoring these factors not only produce negative environmental impacts but also lead to non-optimal solutions and ultimately cause huge economic loss.}
}
@article{VAVROVA2018853,
title = {Model for evaluation of locally available biomass competitiveness for decentralized space heating in villages and small towns},
journal = {Renewable Energy},
volume = {129},
pages = {853-865},
year = {2018},
note = {1st International Conference on Bioresource Technology for Bioenergy, Bioproducts & Environmental Sustainability},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2017.05.079},
url = {https://www.sciencedirect.com/science/article/pii/S0960148117304731},
author = {Kamila Vávrová and Jaroslav Knápek and Jan Weger and Tomáš Králík and Jiří Beranovský},
keywords = {Biomass potential, Energy crops, Residual biomass, Solid biofuels, Biomass price, Space heating},
abstract = {The paper presents the methodology and the case studies for condition of the Czech Republic of BICOM - BIomass COmpetitiveness Model. The model consists of the following modules: (1) the identification of a biomass potential in a given area using GIS modelling (based on climate and soil conditions), (2) modelling the biomass price (using the methodology of the minimum price from the producer's point of view and evaluating the opportunity cost of conventional agriculture production), (3) modelling the biomass processing and logistics, (4) modelling economic competitiveness of the biomass and coal utilization. Typical price range (without VAT) is 6.9–9.8 EUR/GJ for pellets produced from residual biomass and 7.6–12.4 EUR/GJ for pellets produced from energy crops based on our calculations. Typical price range of coal suitable for local heating is 4.8–5.5 EUR/GJ (without VAT). To reach competitiveness of locally produced solid biofuels introduction would be needed of combination of measures aimed at reduction of minimum price of produced pellets (e.g. subsidies for pelleting technology, improved yields and lower losses) and some measures aimed at restrictions imposed on brown coal (e.g. increase of ecological tax). Saved carbon is calculated for replacement of brown coal by pellets from local biomass, which could be used as argument and benchmark for subsidies targeted on the solid biofuels production from local biomass.}
}
@article{WATSON2018379,
title = {Health-based ingestion exposure guidelines for Vibrio cholerae: Technical basis for water reuse applications},
journal = {Science of The Total Environment},
volume = {613-614},
pages = {379-387},
year = {2018},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2017.08.297},
url = {https://www.sciencedirect.com/science/article/pii/S0048969717323197},
author = {Annetta P. Watson and Anthony Q. Armstrong and George H. White and Brandolyn H. Thran},
keywords = {Graywater, Water security, , Microbial risk},
abstract = {U.S. military and allied contingency operations are increasingly occurring in locations with limited, unstable or compromised fresh water supplies. Non-potable graywater reuse is currently under assessment as a viable means to increase mission sustainability while significantly reducing the resources, logistics and attack vulnerabilities posed by transport of fresh water. Development of health-based (non-potable) exposure guidelines for the potential microbial components of graywater would provide a logical and consistent human-health basis for water reuse strategies. Such health-based strategies will support not only improved water security for contingency operations, but also sustainable military operations. Dose-response assessment of Vibrio cholerae based on adult human oral exposure data were coupled with operational water exposure scenario parameters common to numerous military activities, and then used to derive health risk-based water concentrations. The microbial risk assessment approach utilized oral human exposure V. cholerae dose studies in open literature. Selected studies focused on gastrointestinal illness associated with experimental infection by specific V. cholerae serogroups most often associated with epidemics and pandemics (O1 and O139). Nonlinear dose-response model analyses estimated V. cholerae effective doses (EDs) aligned with gastrointestinal illness severity categories characterized by diarrheal purge volume. The EDs and water exposure assumptions were used to derive Risk-Based Water Concentrations (CFU/100mL) for mission-critical illness severity levels over a range of water use activities common to military operations. Human dose-response studies, data and analyses indicate that ingestion exposures at the estimated ED1 (50CFU) are unlikely to be associated with diarrheal illness while ingestion exposures at the lower limit (200CFU) of the estimated ED10 are not expected to result in a level of diarrheal illness associated with degraded individual capability. The current analysis indicates that the estimated ED20 (approximately 1000CFU) represents initiation of a more advanced stage of diarrheal illness associated with clinical care.}
}
@article{SCHIEMAN20181106,
title = {Developing a National, Simulation-Based, Surgical Skills Bootcamp in General Thoracic Surgery},
journal = {Journal of Surgical Education},
volume = {75},
number = {4},
pages = {1106-1112},
year = {2018},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2017.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1931720417307377},
author = {Colin Schieman and Hideki Ujiie and Laura Donahoe and Waël Hanna and Richard Malthaner and Simon Turner and Kasia Czarnecka and Kazuhiro Yasufuku},
keywords = {thoracic surgery, surgical simulation, lobectomy simulation, laparoscopic simulation, Patient Care, Professionalism},
abstract = {Background
The use surgical simulation across all subspecialties has gained widespread adoption in the last decade. A number of factors, including the small number of trainees, identified gaps in surgical skill training from cross-sectional surveys, increased national collaboration, and support from the national specialty committee identified a need to construct a surgical skills “bootcamp” in thoracic surgery in Canada.
Objective
The goals of the surgical skills bootcamp, as identified by the residency training program directors and the national specialty committee were to create a national, centralized, simulation-based skills workshop that focused on key foundational procedures within thoracic surgery, particularly those identified as areas of weakness by former residents; to smooth the transition to intraoperative teaching; to provide exposure to important but not necessarily universally available procedures such as advanced endoscopy; to teach non-medical expert competencies, and lastly to provide a venue for networking for residents across the country.
Design
The curriculum committee has constructed a 3.5 day curriculum, with a focus on hands-on skills simulation, as well as lectures, on a breadth of topics including benign esophageal disorders, lung cancer staging, minimally invasive lung surgery, crisis management and advanced bronchoscopy and endoscopy. All residents across the country attend as well as faculty from a variety of institutions.
Setting
The course is hosted centrally at the University of Toronto, Ontario over 3.5 days. A combination of auditorium and both animal and human operating room facilities are utilized.
Methods
A needs-assessment based on a formal meeting of the program directors, as well feedback from surveys identified the target areas for curriculum development. A committee of interested faculty developed the content as well as the local construct and logistics required. Iterative feedback has evolved the duration and content over the initial 3 years.
Results
Through formal resident feedback, national subspecialty committee review, and program director meetings the support for the bootcamp has been overwhelmingly positive. Specific resident feedback for structure, content and specific simulations has been favorable, but has also been used to modify the program.
Conclusion
In response to identified weaknesses in training, with the support of the national specialty committee, the residency program directors, and the faculty at the University of Toronto, an intensive simulation based thoracic surgery bootcamp has successfully been created for Canadian thoracic surgery residents.}
}
@article{HAO201737,
title = {A tale of two countries: International comparison of online doctor reviews between China and the United States},
journal = {International Journal of Medical Informatics},
volume = {99},
pages = {37-44},
year = {2017},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2016.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1386505616302751},
author = {Haijing Hao and Kunpeng Zhang and Weiguang Wang and Gordon Gao},
abstract = {Background
Worldwide, patients have posted millions of online reviews for their doctors. The rich textual information in the online reviews holds the potential to generate insights into how patients’ experience with their doctors differ across nations and how should we use them to improve our health service.
Objective
We apply customized text mining techniques to compare online doctor reviews from China and the United States, in order to measure the systematic differences in patient reviews between the two countries, and assess the potential insights that can be derived from this large volume of online text data.
Methods
We compare the textual reviews of obstetrics and gynecology (OBGYN) doctors from the two most popular online doctor rating websites in the U.S. and China, respectively: RateMDs.com and Haodf.com. We apply a customized text mining technique, Latent Dirichlet Allocation (LDA) topic modeling to identify the major topics in positive and negative reviews of those two countries. We then compare their similarities and differences.
Results
Among the positive reviews, both Chinese and American patients talked about medical treatment, bedside manner, and appreciation/recommendation, but Chinese patients commented more about medical treatment while American patients focused more on recommendation. Also, reviews about bedside manner from Chinese patients were more related to doctors while on the American side, they were more about staff. This reflects the difference between the two countries’ health systems. Further, among the negative reviews, both countries’ patients talked about medical treatment, bedside manner, and logistics. However, Chinese patients focus more on the registration process, while American patients are more related to the staff, wait time, and insurance, which further shows the differences between the two nations’ health systems.
Conclusions
Online doctor reviews contain valuable information that can generate insights on the similarities and differences of patient experience across nations. They are useful assets to assist healthcare consumers, providers, and administrators in moving toward a patient-centered care. In this age of big data, online doctor reviews can be a valuable source for international perspectives on healthcare systems.}
}
@article{YE2017585,
title = {Building and verifying a severity prediction model of acute pancreatitis (AP) based on BISAP, MEWS and routine test indexes},
journal = {Clinics and Research in Hepatology and Gastroenterology},
volume = {41},
number = {5},
pages = {585-591},
year = {2017},
issn = {2210-7401},
doi = {https://doi.org/10.1016/j.clinre.2016.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S2210740116302066},
author = {Jiang-Feng Ye and Yu-Xin Zhao and Jian Ju and Wei Wang},
keywords = {Pancreatitis, BISAP, MEWS Ca2+},
abstract = {Summary
Purpose
To discuss the value of the Bedside Index for Severity in Acute Pancreatitis (BISAP), Modified Early Warning Score (MEWS), serum Ca2+, similarly hereinafter, and red cell distribution width (RDW) for predicting the severity grade of acute pancreatitis and to develop and verify a more accurate scoring system to predict the severity of AP.
Methods
In 302 patients with AP, we calculated BISAP and MEWS scores and conducted regression analyses on the relationships of BISAP scoring, RDW, MEWS, and serum Ca2+ with the severity of AP using single-factor logistics. The variables with statistical significance in the single-factor logistic regression were used in a multi-factor logistic regression model; forward stepwise regression was used to screen variables and build a multi-factor prediction model. A receiver operating characteristic curve (ROC curve) was constructed, and the significance of multi- and single-factor prediction models in predicting the severity of AP using the area under the ROC curve (AUC) was evaluated. The internal validity of the model was verified through bootstrapping.
Results
Among 302 patients with AP, 209 had mild acute pancreatitis (MAP) and 93 had severe acute pancreatitis (SAP). According to single-factor logistic regression analysis, we found that BISAP, MEWS and serum Ca2+ are prediction indexes of the severity of AP (P-value<0.001), whereas RDW is not a prediction index of AP severity (P-value>0.05). The multi-factor logistic regression analysis showed that BISAP and serum Ca2+ are independent prediction indexes of AP severity (P-value<0.001), and MEWS is not an independent prediction index of AP severity (P-value>0.05); BISAP is negatively related to serum Ca2+ (r=−0.330, P-value<0.001). The constructed model is as follows: ln()=7.306+1.151*BISAP-4.516*serum Ca2+. The predictive ability of each model for SAP follows the order of the combined BISAP and serum Ca2+ prediction model>Ca2+>BISAP. There is no statistical significance for the predictive ability of BISAP and serum Ca2+ (P-value>0.05); however, there is remarkable statistical significance for the predictive ability using the newly built prediction model as well as BISAP and serum Ca2+ individually (P-value<0.01). Verification of the internal validity of the models by bootstrapping is favorable.
Conclusion
BISAP and serum Ca2+ have high predictive value for the severity of AP. However, the model built by combining BISAP and serum Ca2+ is remarkably superior to those of BISAP and serum Ca2+ individually. Furthermore, this model is simple, practical and appropriate for clinical use.}
}
@article{AKKERMANS2017125,
title = {Optimal design of experiments for excipient compatibility studies},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {171},
pages = {125-139},
year = {2017},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2017.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0169743917300175},
author = {Wannes G.M. Akkermans and Hans Coppenolle and Peter Goos},
keywords = {D-optimal design, I-optimal design, Mixture-process variable experiment, Randomization restriction, Split-plot design, Strip-plot design},
abstract = {A crucial stage in the development of medical drugs is to study which additives, usually called excipients, impact the active ingredient stability. This type of study is generally named an excipient compatibility study and requires a mixture experiment. Subsequently, the effect of the storage conditions, more specifically the relative humidity and temperature, on the stability is investigated. This so-called accelerated life test involves a factorial type of experiment. It has become, however, customary to include the storage conditions in the compatibility study. This provides valuable information concerning potential interactions between excipient combinations and storage conditions. Experiments that combine a mixture experiment with a factorial experiment are generally named mixture-process variable experiments. A limited number of designs for mixture-process variable experiments are available in the literature. One problem is that the proposed designs offer little flexibility. Another is that the required number of runs becomes prohibitively large for large numbers of mixture components. In this paper, we examine flexible, optimal designs for realistic mixture-process variable experiments. Our motivation is to provide guidance to pharmaceutical formulation scientists concerning state-of-the art models and designs for excipient compatibility studies. Using several proof-of-concept examples, we demonstrate that I-optimal designs offer both flexibility and small variances of prediction. We also discuss a real-life example, which could be used as a blueprint for future studies. Because many excipient compatibility studies are not completely randomized, we pay special attention to their logistics and to the resulting randomization restrictions, which lead to split-plot and strip-plot experiments.}
}
@article{BOGATAJ2017113,
title = {Reprint of “Mitigating risks of perishable products in the cyber-physical systems based on the extended MRP model”},
journal = {International Journal of Production Economics},
volume = {194},
pages = {113-125},
year = {2017},
note = {Special Issue: Innovations in Production Economics},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S092552731730350X},
author = {David Bogataj and Marija Bogataj and Domen Hudoklin},
keywords = {Cyber-physical systems, Smart home, Smart container, Food delivery, Post-harvest loss prevention, IoT, Material requirements planning theory, Collaborative cities},
abstract = {In the supply chain of fresh fruit and vegetables, large losses may incurred throughout the whole farm to fork route. Food supply chain management is faced with challenges of minimizing the post-harvest loss, while delivering the items directly to the refrigerators in smart homes (i.e. domotics). A substantial value can therefore be added to the criterion function by an immediate, real-time detection of changes in perishability dynamics, including a real-time calculation and communication of the remaining shelf life during transportation from one chain node to another. The changes in the estimated remaining shelf life can, therefore, be matched with the expected remaining transportation time, and so the critical moment can be avoided with a given probability. This can be done by dynamic rerouting in real time, based on previous net present value (NPV) criteria. Such criteria could then we include in the contractually stipulated remaining shelf life requirements at the delivery point. This paper focuses on a novel concept of moving activity cells which represent the moving cargo between the fixed activity cells in the extended material requirements planning (EMRP) model. The changes in NPV are calculated dynamically from the expected shelf life changes. Such real-time calculations and early reports are enabled by the Internet of Things (IoT) infrastructure, where there is a smart device that tracks ambient conditions like temperature, humidity, and gas concentrations. These early estimations allow a better decision making based on first-expired-first-out (FEFO) cold chain management strategies for perishable products. Therefore, the model includes the possibility to deliver the items to the local market if the expected contractually stipulated shelf-life losses become too high. The paper does not intend to discuss the details of IoT or analyse different sensors, but it wishes to show how the EMRP theory can be used to estimate the changes in NPV when moving activity cells are included in the model. The smart measurement devices embedded in moving activity cells of cyber-physical system measure the ambient data and broadcast decay acceleration factors and postharvest loss of cargo to the decision support system. The numerical example shows how smart measurement devices embedded in moving activity cells of cyber-physical system help to reduce the post-harvest loss in a supply chain by rerouting when necessary. The paper additionally shows how much such a cyber-physical system improves NPV by the development of decision-making processes in the real-time, using the IoT as infrastructure, including automatic rerouting in postharvest logistics.}
}
@article{GAS2016e71,
title = {Objective Assessment of General Surgery Residents Followed by Remediation},
journal = {Journal of Surgical Education},
volume = {73},
number = {6},
pages = {e71-e76},
year = {2016},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2016.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S193172041630109X},
author = {Becca L. Gas and EeeLN H. Buckarma and Monali Mohan and T.K. Pandian and David R. Farley},
keywords = {simulation, surgical education, remediation, assessment, general surgery, Patient Care, Medical Knowledge, Interpersonal and Communication Skills},
abstract = {Objective
Surgical training programs often lack objective assessment strategies. Complicated scheduling characteristics frequently make it difficult for surgical residents to undergo formal assessment; actually having the time and opportunity to remediate poor performance is an even greater problem. We developed a novel methodology of assessment for residents and created an efficient remediation system using a combination of simulation, online learning, and self-assessment options.
Design
Postgraduate year (PGY) 2 to 5 general surgery (GS) residents were tested in a 5 station, objective structured clinical examination style event called the Surgical X-Games. Stations were 15 minutes in length and tested both surgical knowledge and technical skills. Stations were scored on a scale of 1 to 5 (1 = Fail, 2 = Mediocre, 3 = Pass, 4 = Good, and 5 = Stellar). Station scores ≤ 2 were considered subpar and required remediation to a score ≥ 4. Five remediation sessions allowed residents the opportunity to practice the stations with staff surgeons. Videos of each skill or test of knowledge with clear instructions on how to perform at a stellar level were offered. Trainees also had the opportunity to checkout take-home task trainers to practice specific skills. Residents requiring remediation were then tested again in-person or sent in self-made videos of their performance.
Setting
Academic medical center.
Participants
PGY2, 3, 4, and 5 GS residents at Mayo Clinic in Rochester, MN.
Results
A total of, 35 residents participated in the Surgical X-Games in the spring of 2015. Among all, 31 (89%) had scores that were deemed subpar on at least 1 station. Overall, 18 (58%) residents attempted remediation. All 18 (100%) achieved a score ≥ 4 on the respective stations during a makeup attempt. Overall X-Games scores and those of PGY2s, 3s, and 4s were higher after remediation (p < 0.05). No PGY5s attempted remediation.
Conclusions
Despite difficulties with training logistics and busy resident schedules, it is feasible to objectively assess most GS trainees and offer opportunities to remediate if performance is poor. Our multifaceted remediation methodology allowed 18 residents to achieve good or stellar performance on each station after deliberate practice. Enticing chief residents to participate in remediation efforts in the spring of their final year of training remains a work in progress.}
}
@article{HAIDARI20164062,
title = {The economic and operational value of using drones to transport vaccines},
journal = {Vaccine},
volume = {34},
number = {34},
pages = {4062-4067},
year = {2016},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2016.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X16304352},
author = {Leila A. Haidari and Shawn T. Brown and Marie Ferguson and Emily Bancroft and Marie Spiker and Allen Wilcox and Ramya Ambikapathi and Vidya Sampath and Diana L. Connor and Bruce Y. Lee},
keywords = {Immunization, UAV, Simulation modeling},
abstract = {Background
Immunization programs in low and middle income countries (LMICs) face numerous challenges in getting life-saving vaccines to the people who need them. As unmanned aerial vehicle (UAV) technology has progressed in recent years, potential use cases for UAVs have proliferated due to their ability to traverse difficult terrains, reduce labor, and replace fleets of vehicles that require costly maintenance.
Methods
Using a HERMES-generated simulation model, we performed sensitivity analyses to assess the impact of using an unmanned aerial system (UAS) for routine vaccine distribution under a range of circumstances reflecting variations in geography, population, road conditions, and vaccine schedules. We also identified the UAV payload and UAS costs necessary for a UAS to be favorable over a traditional multi-tiered land transport system (TMLTS).
Results
Implementing the UAS in the baseline scenario improved vaccine availability (96% versus 94%) and produced logistics cost savings of $0.08 per dose administered as compared to the TMLTS. The UAS maintained cost savings in all sensitivity analyses, ranging from $0.05 to $0.21 per dose administered. The minimum UAV payloads necessary to achieve cost savings over the TMLTS, for the various vaccine schedules and UAS costs and lifetimes tested, were substantially smaller (up to 0.40L) than the currently assumed UAV payload of 1.5L. Similarly, the maximum UAS costs that could achieve savings over the TMLTS were greater than the currently assumed costs under realistic flight conditions.
Conclusion
Implementing a UAS could increase vaccine availability and decrease costs in a wide range of settings and circumstances if the drones are used frequently enough to overcome the capital costs of installing and maintaining the system. Our computational model showed that major drivers of costs savings from using UAS are road speed of traditional land vehicles, the number of people needing to be vaccinated, and the distance that needs to be traveled.}
}
@article{KANYILMAZ2016138,
title = {Assessment of the seismic behaviour of braced steel storage racking systems by means of full scale push over tests},
journal = {Thin-Walled Structures},
volume = {107},
pages = {138-155},
year = {2016},
issn = {0263-8231},
doi = {https://doi.org/10.1016/j.tws.2016.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0263823116303226},
author = {Alper Kanyilmaz and Giovanni Brambilla and Gian Paolo Chiarelli and Carlo Andrea Castiglioni},
keywords = {Steel storage racks, Full scale tests, Spine bracings, Braced racks},
abstract = {Pallet racking systems, made of thin-walled cold formed steel profiles, are commonly used to store valuable goods and products in the logistics industry. In service conditions, longitudinal (down-aisle) stability of the racks is provided by the flexural stiffness of the demountable beam-upright column connections and base joints. Rack designers usually prefer to avoid bracings for a full accessibility of shelves from both aisles. However, under seismic conditions, typical rack connections cannot often provide sufficient flexural performance in terms of stiffness and strength, which deems necessary to introduce spine (longitudinal) bracings in the down-aisle direction. Yet the racks can only be braced at one of their two longitudinal planes to allow pallet loading from the aisle, which results in an asymmetric horizontal bearing configuration. This combined with their perforated upright columns, and non-standard beam-upright and base connections make it even more difficult to estimate their complex global seismic performance. Therefore, full scale experimental investigations are strongly needed in order to understand and quantify the global performance of the braced storage racks, and improve their design for seismic actions. This paper presents the experimental results of the Europe's largest full-scale push-over testing program that has been carried out on racking systems. In particular, experimental global capacity curves of 6 fully-loaded pallet racking specimens with spine bracings, provided by 5 different international rack producers, are presented, discussing the key factors influencing the racks’ response, as well as the failure mechanisms of the different rack typologies. Furthermore, behaviour factor (q) values of each specimen are derived from re-analysis of test results. Vulnerability of braced racks to bracing connection failure is demonstrated, highlighting its causes. Design indications are provided in order to guarantee a globally homogenous ductility under seismic actions.}
}
@article{LAUSSELET2016191,
title = {Life-cycle assessment of a Waste-to-Energy plant in central Norway: Current situation and effects of changes in waste fraction composition},
journal = {Waste Management},
volume = {58},
pages = {191-201},
year = {2016},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2016.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X16305177},
author = {Carine Lausselet and Francesco Cherubini and Gonzalo {del Alamo Serrano} and Michael Becidan and Anders Hammer Strømman},
keywords = {WtE, LCA, Challenging new waste fraction, Car fluff, Clinical waste, Wood waste},
abstract = {Waste-to-Energy (WtE) plants constitute one of the most common waste management options to deal with municipal solid waste. WtE plants have the dual objective to reduce the amount of waste sent to landfills and simultaneously to produce useful energy (heat and/or power). Energy from WtE is gaining steadily increasing importance in the energy mix of several countries. Norway is no exception, as energy recovered from waste currently represents the main energy source of the Norwegian district heating system. Life-cycle assessments (LCA) of WtE systems in a Norwegian context are quasi-nonexistent, and this study assesses the environmental performance of a WtE plant located in central Norway by combining detailed LCA methodology with primary data from plant operations. Mass transfer coefficients and leaching coefficients are used to trace emissions over the various life-cycle stages from waste logistics to final disposal of the ashes. We consider different fractions of input waste (current waste mix, insertion of 10% car fluff, 5% clinical waste and 10% and 50% wood waste), and find a total contribution to Climate Change Impact Potential ranging from 265 to 637gCO2eq/kg of waste and 25 to 61gCO2eq/MJ of heat. The key drivers of the environmental performances of the WtE system being assessed are the carbon biogenic fraction and the lower heating value of the incoming waste, the direct emissions at the WtE plant, the leaching of the heavy metals at the landfill sites and to a lesser extent the use of consumables. We benchmark the environmental performances of our WtE systems against those of fossil energy systems, and we find better performance for the majority of environmental impact categories, including Climate Change Impact Potential, although some trade-offs exist (e.g. higher impacts on Human Toxicity Potential than natural gas, but lower than coal). Also, the insertion of challenging new waste fractions is demonstrated to be an option both to cope with the excess capacity of the Norwegian WtE sector and to reach Norway’s ambitious political goals for environmentally friendly energy systems.}
}
@article{GHOUSSOUB2017e55,
title = {Musculoskeletal disorders in hairdressers: Survey of a group of hairdressers in Lebanon},
journal = {Annals of Physical and Rehabilitation Medicine},
volume = {60},
pages = {e55-e56},
year = {2017},
note = {32nd Annual Congress of the French Society of Physical and Rehabilitation Medicine},
issn = {1877-0657},
doi = {https://doi.org/10.1016/j.rehab.2017.07.208},
url = {https://www.sciencedirect.com/science/article/pii/S1877065717303317},
author = {Khalil Ghoussoub and Joan Shehadeh and Ghassan Sleilati and Mona sayegh Ghoussoub and Gaby Kreichati},
keywords = {Hairstylists, Postures, Musculoskeletal disorders},
abstract = {Objective
Our study aims to assess the prevalence and risk factors for musculoskeletal disorders (MSD) in a group of hairdressers in Lebanon, to establish a correlation between these symptoms and factors related to the professional practice in hairdressers, and compare the results to the data of the literature.
Material/patients and methods
Descriptive study. Target population: hairdressers in an area of Beirut. Data collection is carried out using a grid containing demographic logistics data of the show, data concerning the hairdressing profession and others on MSDs. The statistical analysis was done by SPSS 22 software. The statistical tests used were: Student, Mann-Whitney for quantitative variables, Pearson's Chi2, Fisher's exact test for qualitative variables.
Results
The descriptive study involved 65 hairdressers. Male predominance: 62%. Average age: 39 years±13. Body mass index (BMI): 24±3.5. Weight gain during the last twelve months: 33.3%. Average number of acts per day: 9. Number of working days per week: 5.5. Breaks: 2 per day <60min. Standing position without breaks: 5.5h. Sports activities: 52.5%. Height of the bins adapted: 81% and adjustable: 63%. TMS last month: 70% (44 hairdressers). Pain during work: 46% and continuous pain: 29%. Especially, dorso-lumbar pain: 55% and neck pain: 10%. Work stoppage: 25%. TMS in the last 12months: 63%, with work stoppage 30%. Half consulted a physician and 32.5% consulted a physiotherapist. A variable univariate study shows significant correlation with 1-month musculoskeletal disorders (P<0.05), age>42years (P=0.012), weight gain during the last 12 months (P=0.003), salaried (P=0.003), high number of clients per day (P=0.012), high number of acts per day (P=0.012), high standing time>5.5h/day (P=0.040).
Discussion/conclusion
Musculoskeletal pathologies are common among hairdressers in Lebanon, in relation to vicious postures at work, repetition of movements, and poorly adapted work equipment. It would be interesting to introduce the notion of ergonomics in the curriculum of hairdressers.}
}
@article{CEREB201624,
title = {OR29 Prediction of abo rh serotypes by molecular typing of abo rh genes is highly concordant with serological typing: experience with typing 1000,000 samples},
journal = {Human Immunology},
volume = {77},
pages = {24},
year = {2016},
note = {The American Society for Histocompatibility and Immunogenetics: 42nd Annual Meeting Abstracts September 26 – 30, 2016 Hyatt Regency St. Louis at the Arch, St. Louis, Missouri},
issn = {0198-8859},
doi = {https://doi.org/10.1016/j.humimm.2016.07.041},
url = {https://www.sciencedirect.com/science/article/pii/S019888591630194X},
author = {Nezih Cereb and Sang Yeol Seo and Amaralingeswara Rao and Gail Flickinger and Jangyoung Kwon and JeongOk Jeon and DongYong Kim and HwaRan Kim and Romy Kronstein and Torsten Tonn and Soo Young Yang},
abstract = {Aim
One of the factors that needs to be considered for a successful hematopoietic stem cell transplantation is the ABO Rh compatibility between patient and donor. Until recently, most donor registries did not have ABO Rh typing data on donors due to logistics and expenses that are involved. Furthermore, most donor recruitments are currently done using buccal swabs or saliva samples that precludes serotyping for ABO Rh groups. However, these specimen types are suitable for DNA typing of ABO Rh genes. We have developed a method based on Illumina MiSeq platform to genotype ABO Rh genes and build an algorithm to predict the phonotypes. This additional information on donors could speed up the search process for the patients who need hematopoietic stem cell transplant. Methods: We designed 9 Exon-based primer pairs for the 7 exons for the glycosyltransferase gene. Exon 7 required 3 overlapping amplicons for full coverage. For Rh genes, we designed 10 primer sets to amplify all 10 exons. Previously, 1000 serotyped DNA samples of Caucasian ethnicity were genotyped to predict genotype-phenotype correlation. We applied a phenotyping algorithm based on all the exon sequences, incorporating known serological motif sequences in exons 6 and 7. This algorithm predicted ABO type with 99.9% accuracy and Rh with 100%.
Results
We blindly tested 1376 samples of diverse ethnic origin. We found that 12 (0.87%) samples for ABO and 31 (2.23%) samples for Rh had discordant results with serotyping. We typed close to 1 million individuals as of today, and we have discovered many novel sequences for each exon as shown in the table below: We have found 144 cases with new motifs in exon 7 that changed B blood group genotype to O. Thirteen had a point substitution, and 131 had a 1 bp deletion.
Conclusion
Large scale molecular typing for ABO and Rh is now feasible. Molecular basis for some ambiguous serotyped could be identified with this approach. ABO and Rh information in donor files will help accelerate the donor search process .}
}
@article{BIRKEGARD201783,
title = {Sampling pig farms at the abattoir in a cross-sectional study − Evaluation of a sampling method},
journal = {Preventive Veterinary Medicine},
volume = {145},
pages = {83-90},
year = {2017},
issn = {0167-5877},
doi = {https://doi.org/10.1016/j.prevetmed.2017.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167587716304172},
author = {Anna Camilla Birkegård and Tariq Halasa and Nils Toft},
keywords = {Sampling procedure, Pig farm, Cross-Sectional study, Slaughterhouse, Abattoir},
abstract = {A cross-sectional study design is relatively inexpensive, fast and easy to conduct when compared to other study designs. Careful planning is essential to obtaining a representative sample of the population, and the recommended approach is to use simple random sampling from an exhaustive list of units in the target population. This approach is rarely feasible in practice, and other sampling procedures must often be adopted. For example, when slaughter pigs are the target population, sampling the pigs on the slaughter line may be an alternative to on-site sampling at a list of farms. However, it is difficult to sample a large number of farms from an exact predefined list, due to the logistics and workflow of an abattoir. Therefore, it is necessary to have a systematic sampling procedure and to evaluate the obtained sample with respect to the study objective. We propose a method for 1) planning, 2) conducting, and 3) evaluating the representativeness and reproducibility of a cross-sectional study when simple random sampling is not possible. We used an example of a cross-sectional study with the aim of quantifying the association of antimicrobial resistance and antimicrobial consumption in Danish slaughter pigs. It was not possible to visit farms within the designated timeframe. Therefore, it was decided to use convenience sampling at the abattoir. Our approach was carried out in three steps: 1) planning: using data from meat inspection to plan at which abattoirs and how many farms to sample; 2) conducting: sampling was carried out at five abattoirs; 3) evaluation: representativeness was evaluated by comparing sampled and non-sampled farms, and the reproducibility of the study was assessed through simulated sampling based on meat inspection data from the period where the actual data collection was carried out. In the cross-sectional study samples were taken from 681 Danish pig farms, during five weeks from February to March 2015. The evaluation showed that the sampling procedure was reproducible with results comparable to the collected sample. However, the sampling procedure favoured sampling of large farms. Furthermore, both under-sampled and over-sampled areas were found using scan statistics. In conclusion, sampling conducted at abattoirs can provide a spatially representative sample. Hence it is a possible cost-effective alternative to simple random sampling. However, it is important to assess the properties of the resulting sample so that any potential selection bias can be addressed when reporting the findings.}
}
@article{SARANGI20181,
title = {Evaluation of a specialized filter-paper matrix for transportation of extended bovine semen to screen for bovine herpesvirus-1 by real-time PCR},
journal = {Journal of Virological Methods},
volume = {257},
pages = {1-6},
year = {2018},
issn = {0166-0934},
doi = {https://doi.org/10.1016/j.jviromet.2018.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S016609341730592X},
author = {Laxmi Narayan Sarangi and Thodangala Naveena and Samir Kumar Rana and Kota Sri Naga Leela Surendra and Rachamreddy Venkata Chandrasekhar Reddy and Putla Bajibabu and Nadikerianda Muthappa Ponnanna and Girish Kumar Sharma and Villuppanoor Alwar Srinivasan},
keywords = {Infectious bovine rhinotracheitis, Bovine herpesvirus-1, FTA, Real-time PCR, Extended bovine semen},
abstract = {The extended frozen semen (EFS) batches produced from infectious bovine rhinotracheitis (IBR) sero-positive cattle and buffalo bulls housed in various semen stations in India are transported to the testing laboratory in liquid nitrogen (LN2) for screening bovine herpesvirus-1 (BoHV-1). This procedure is laborious and poses LN2 related hazards. An alternative logistics for transportation of samples was investigated. Use of Flinders Technology Associates (FTA®) elute card was evaluated for transportation of extended bovine semen to screen BoHV-1 DNA by real-time PCR targeting gB gene and the method was compared with the OIE approved Chelex resin based method. A protocol for extraction of BoHV-1 DNA from FTA® card spotted with extended semen was optimized. The viral DNA was found to be stable on FTA® card for at least 28 days when the cards are stored at 4°–37 °C. The analytical sensitivity for the assay was determined using variable dilutions of BoHV-1 spiked semen and positive plasmid harbouring gB gene (97bp) spotted onto FTA® card and it was found to be 100.8 TCID50/ml or 100 copies respectively in real-time PCR. The test could detect as low as 100.008 TCID50/ml or 1 copy of positive plasmid when more number of replicates (n = 6) of the same sample were tested. This sensitivity was found to be comparable to Chelex method and both the methods demonstrated a very strong correlation (r = 0.9774; 95% CI: 0.9620–0.9860) in terms of Ct value (p < 0.0001). The diagnostic sensitivity and specificity of the FTA method in comparison to the Chelex method was 83.08% (95% CI: 71.73%–91.24%) and 93.23% (95% CI: 89.38%–96.01%) respectively when 316 samples were screened by both the methods. The degree of agreement between these two tests was good (Kappa value: 0.738; 95% CI: 0.646–0.829). The method was found to be robust and highly repeatable in inter-assay and intra-assay precision testing. The result suggests that the FTA® card holds promise as an alternative system for transportation of EFS for downstream screening of BoHV-1 DNA.}
}
@article{CALVET201693,
title = {Combining statistical learning with metaheuristics for the Multi-Depot Vehicle Routing Problem with market segmentation},
journal = {Computers & Industrial Engineering},
volume = {94},
pages = {93-104},
year = {2016},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2016.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0360835216300092},
author = {Laura Calvet and Albert Ferrer and M. Isabel Gomes and Angel A. Juan and David Masip},
keywords = {Multi-Depot Vehicle Routing Problem, Market segmentation applications, Hybrid algorithms, Statistical learning},
abstract = {In real-life logistics and distribution activities it is usual to face situations in which the distribution of goods has to be made from multiple warehouses or depots to the final customers. This problem is known as the Multi-Depot Vehicle Routing Problem (MDVRP), and it typically includes two sequential and correlated stages: (a) the assignment map of customers to depots, and (b) the corresponding design of the distribution routes. Most of the existing work in the literature has focused on minimizing distance-based distribution costs while satisfying a number of capacity constraints. However, no attention has been given so far to potential variations in demands due to the fitness of the customer-depot mapping in the case of heterogeneous depots. In this paper, we consider this realistic version of the problem in which the depots are heterogeneous in terms of their commercial offer and customers show different willingness to consume depending on how well the assigned depot fits their preferences. Thus, we assume that different customer-depot assignment maps will lead to different customer-expenditure levels. As a consequence, market-segmentation strategies need to be considered in order to increase sales and total income while accounting for the distribution costs. To solve this extension of the MDVRP, we propose a hybrid approach that combines statistical learning techniques with a metaheuristic framework. First, a set of predictive models is generated from historical data. These statistical models allow estimating the demand of any customer depending on the assigned depot. Then, the estimated expenditure of each customer is included as part of an enriched objective function as a way to better guide the stochastic local search inside the metaheuristic framework. A set of computational experiments contribute to illustrate our approach and how the extended MDVRP considered here differs in terms of the proposed solutions from the traditional one.}
}
@article{DIAZRAMIREZ2017258,
title = {Eco-driving key factors that influence fuel consumption in heavy-truck fleets: A Colombian case},
journal = {Transportation Research Part D: Transport and Environment},
volume = {56},
pages = {258-270},
year = {2017},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2017.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1361920916308689},
author = {Jenny Díaz-Ramirez and Nicolas Giraldo-Peralta and Daniela Flórez-Ceron and Vivian Rangel and Christopher Mejía-Argueta and José Ignacio Huertas and Mario Bernal},
keywords = {Fuel consumption, Eco-driving training, Freight transportation, Statistical analyses, Driver behavior, Driving errors},
abstract = {This research identifies key variables that influence fuel consumption that might be improved through eco-driving training programs under three circumstances that have been scarcely studied before: (a) heavy- and medium-duty truck fleets, (b) long-distance freight transport, and (c) the Latin American region. Based on statistical analyses that include multivariate regression of operational variables on fuel consumption, the impacts of an eco-driving training campaign were measured by comparing ex ante and ex post data. Operational variables are grouped into driving errors, trip conditions, driver behavior, driver profile, and vehicle attributes. The methodology is applied in a freight fleet with nationwide transport operations located in Colombia, where the steepness of its roads plays an important role in fuel consumption. The fleet, composed of 18 trucks, is equipped with state-of-the-art real-time data logger systems. During four months, 517 trips traveling a total distance of 292,512km and carrying a total of 10,034 tons were analyzed. The results show a baseline average fuel consumption (FC) of 1.716 liters per ton-100km. A different logistics performance indicator, which measures FC in liters per ton transported each 100km, shows an average of 3.115. After the eco-driving campaign, reductions of 6.8% and 5.5% were obtained. Drivers’ experience, driving errors, average speed, and weight-capacity ratio, among others, were found to be highly relevant to FC. In particular, driving errors such as acceleration, braking and speed excesses are the most sensitive to eco-driving training, showing reductions of up to 96% on the average number of events per trip.}
}
@article{LIXANDRU2017482,
title = {Identification and recovery of rare-earth permanent magnets from waste electrical and electronic equipment},
journal = {Waste Management},
volume = {68},
pages = {482-489},
year = {2017},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2017.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X17305214},
author = {A. Lixandru and P. Venkatesan and C. Jönsson and I. Poenaru and B. Hall and Y. Yang and A. Walton and K. Güth and R. Gauß and O. Gutfleisch},
keywords = {Rare-earth scrap permanent magnets, Nd-Fe-B, Waste streams selection, WEEE, Recovery, Recycling},
abstract = {Nd-Fe-B permanent magnets are a strategic material for a number of emerging technologies. They are a key component in the most energy efficient electric motors and generators, thus, they are vital for energy technologies, industrial applications and automation, and future forms of mobility. Rare earth elements (REEs) such as neodymium, dysprosium and praseodymium are also found in waste electrical and electronic equipment (WEEE) in volumes that grow with the technological evolution, and are marked as critical elements by the European Commission due to their high economic importance combined with significant supply risks. Recycling could be a good approach to compensate for the lack of rare earths (REs) on the market. However, less than 1% of REs are currently being recycled, mainly because of non-existing collection logistics, lack of information about the quantity of RE materials available for recycling and recycling-unfriendly product designs. To improve these lack of information, different waste streams of electrical and electronic equipment from an industrial recycling plant were analyzed in order to localize, identify and collect RE permanent magnets of the Nd-Fe-B type. This particular type of magnets were mainly found in hard disk drives (HDDs) from laptops and desktop computers, as well as in loudspeakers from compact products such as flat screen TVs, PC screens, and laptops. Since HDDs have been investigated thoroughly by many authors, this study focusses on other potential Nd-Fe-B resources in electronic waste. The study includes a systematic survey of the chemical composition of the Nd-Fe-B magnets found in the selected waste streams, which illustrates the evolution of the Nd-Fe-B alloys over the years. The study also provides an overview over the types of magnets integrated in different waste electric and electronic equipment.}
}
@article{HIRSHBARGAI20183505,
title = {Evaluating scenarios of locations and capacities for vaccine storage in Nigeria},
journal = {Vaccine},
volume = {36},
number = {24},
pages = {3505-3512},
year = {2018},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2018.04.072},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X18305796},
author = {Dor {Hirsh Bar Gai} and Zachary Graybill and Paule Voevodsky and Ekundayo Shittu},
keywords = {Cost, Capacity, Supply chain, Shortest-path, Fill rate, Hubs, Vaccine},
abstract = {Many developing countries still face the prevalence of preventable childhood diseases because their vaccine supply chain systems are inadequate by design or structure to meet the needs of their populations. Currently, Nigeria is evaluating options in the redesign of the country’s vaccine supply chain. Using Nigeria as a case study, the objective is to evaluate different regional supply chain scenarios to identify the cost minimizing optimal hub locations and storage capacities for doses of different vaccines to achieve a 100% fill rate. First, we employ a shortest-path optimization routine to determine hub locations. Second, we develop a total cost minimizing routine based on stochastic optimization to determine the optimal capacities at the hubs. This model uses vaccine supply data between 2011 and 2014 provided by Nigeria’s National Primary Health Care Development Agency (NPHCDA) on Tuberculosis, Polio, Yellow Fever, Tetanus Toxoid, and Hepatitis B. We find that a two-regional system with no central hub (NC2) cut costs by 23% to achieve a 100% fill rate when compared to optimizing the existing chain of six regions with a central hub (EC6). While the government’s leading redesign alternative – no central three-hub system (Gov NC3) – reduces costs by 21% compared with the current EC6, it is more expensive than our NC2 system by 3%. In terms of capacity increases, optimizing the current system requires 42% more capacity than our NC2 system. Although the proposed Gov NC3 system requires the least increase in storage capacity, it requires the most distance to achieve a 100% coverage and about 15% more than our NC2. Overall, we find that improving the current system with a central hub and all its variants, even with optimal regional hub locations, require more storage capacities and are costlier than systems without a central hub. While this analysis prescribes the no central hub with two regions (NC2) as the least cost scenario, it is imperative to note that other configurations have benefits and comparative tradeoffs. Our approach and results offer some guidance for future vaccine supply chain redesigns in countries with similar layouts to Nigeria’s.}
}
@article{ANDERSON201862,
title = {Grey areas: New Zealand ambulance personnel’s experiences of challenging resuscitation decision-making},
journal = {International Emergency Nursing},
volume = {39},
pages = {62-67},
year = {2018},
note = {Special Issue: Emergency personnel - mental health},
issn = {1755-599X},
doi = {https://doi.org/10.1016/j.ienj.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1755599X17301325},
author = {Natalie Elizabeth Anderson and Merryn Gott and Julia Slark},
keywords = {Cardiac arrest, Emergency medical services, Cardiopulmonary resuscitation, Clinical decision-making, Paramedics, Prehospital care, Qualitative research, Intepretative phenomenological analysis},
abstract = {Introduction
When faced with a patient in cardiac arrest, ambulance personnel must rapidly make complex decisions with limited information. Much of the research examining decisions to commence, continue, withhold or terminate resuscitation has used retrospective audits of registry data and clinical documentation. This study offers a provider-perspective which characterises uncertainty and highlights clinical, cognitive, emotional and physical demands associated with decision-making in the cardiac arrest context.
Method
Semi-structured interviews with a purposive sample of sixteen demographically diverse ambulance personnel, currently employed in a variety of emergency ambulance response roles across New Zealand.
Results
All participants readily identified clinical, cognitive, emotional and ethical challenges associated with resuscitation decision-making. Four main themes were identified: grey areas; exceptional cases; scene challenges; and personal responses. A lack of information or a mix of favourable and unfavourable prognostic factors created decision-making uncertainty or “grey areas”. Exceptional cases such as first-encounters also increased uncertainty and presented emotional, ethical and clinical challenges. Cardiac arrest scenes were often challenging, and participants described managing bystander expectations and responses and logistical limitations including adverse environmental conditions, fatigue and task-overload, and crew resource management.
Conclusion
This unique research presents a provider-perspective on the challenges faced by ambulance personnel deciding to commence, continue, withhold or terminate resuscitation efforts. Knowledge of personal values and strategies for managing personal responses appear to be central to certainty and coping. Simulated training should move beyond resuscitation task performance, to incorporate challenging elements and encourage ambulance personnel to explore their personal values, stressors and coping strategies.}
}
@article{FAED2016614,
title = {Intelligent customer complaint handling utilising principal component and data envelopment analysis (PDA)},
journal = {Applied Soft Computing},
volume = {47},
pages = {614-630},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615001192},
author = {Alireza Faed and Elizabeth Chang and Morteza Saberi and Omar Khadeer Hussain and Ali Azadeh},
keywords = {Customer relationship management, Customer satisfaction, Principal component analysis, Data envelopment analysis, Customer complaint},
abstract = {In this study, we consider customer to be a company's crucial asset. In order to have a fast, efficient decision-making process, it is vital that a customer relationship management (CRM) decision-maker condenses and abstracts the existing information. A questionnaire survey was conducted among respondents in order to obtain the required data. The questionnaire contains nine categories of satisfaction variables. To perform the analysis, we used principal component analysis (PCA) and data envelopment analysis (DEA). PDA has been utilised as an abbreviation for the integration of these two methods. To effectively analyse the procedure, PCA was utilised to assign a number to each category of questions related to each satisfaction variable. To achieve optimal precision, DEA was applied to the three categories of customers (‘most important’, ‘important’ and ‘ordinary’ customers) in order to determine the strengths and weaknesses of customer services from these customers’ perspectives. Customers were clustered and then DEA was used to determine their viewpoints. Using DEA, we have optimised our recognition of customers’ complaints and then provided recommendations and remedial actions to resolve the current issues in logistics and transport industry in general, and at Fremantle port in particular.
Significance
The current study integrates soft computing and optimisation technique in order to build the CRM recommender system. It demonstrates the hybrid soft computing strengthens in area of CRM as the relevance solution. The significance of the proposed algorithm is three fold. First, it integrates soft computing and optimisation technique in order to build the CRM recommender system. Second, it utilises the most standard CRM variables in its decision making process. Third, it is an optimising algorithm because it integrates DEA with PCA technique.}
}